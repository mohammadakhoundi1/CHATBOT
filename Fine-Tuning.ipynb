{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZBY_8Cm1Tm0"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8daoUhh51Tm7"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv_-ohpC1Tm7"
      },
      "source": [
        "**Read our [blog post](https://unsloth.ai/blog/r1-reasoning) for guidance on how to train reasoning models.**\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L79rwk421Tm8"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RsdmVOGk1Tm9"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab and Kaggle notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n",
        "    !pip install --no-deps cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZD3_CCC1Tm-"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267,
          "referenced_widgets": [
            "2d9d62f0a7364ac0b40e1da1b78ac10c",
            "25bb2faf4fa146df9a71ae6c3c6b4604",
            "436c48d27ff1454eba0c38c97b774869",
            "5ffbb9bba9114150badd4c0c5162782b",
            "d4c0e0a75fbd481ea6848f8e1ae02d34",
            "ca55a3978e994541a0f2e890272ee54d",
            "c91f3d90122c4ec19c79342fb62babf7",
            "cc729da6499f4293b76989e3ab5279d7",
            "668606025e4743d2bf1791f029190e0a",
            "13778ee9448c45aab93b08eba085c1d2",
            "4ff4458dcd8240bfaa60a8e1bbe52f5a"
          ]
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "a351a51b-ff8e-4480-f1fc-a9ff3534eb94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "Unsloth: If you want to finetune Gemma 2, install flash-attn to make it faster!\n",
            "To install flash-attn, do the below:\n",
            "\n",
            "pip install --no-deps --upgrade \"flash-attn>=2.6.3\"\n",
            "==((====))==  Unsloth 2025.3.18: Fast Gemma2 patching. Transformers: 4.49.0.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d9d62f0a7364ac0b40e1da1b78ac10c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = (\n",
        "    None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        ")\n",
        "load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",  # Llama-3.1 15 trillion tokens model 2x faster!\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",  # We also uploaded 4bit for 405b!\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\",  # New Mistral 12b 2x faster!\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",  # Mistral v3 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",  # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",  # Gemma 2x faster!\n",
        "]  # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/gemma-2-27b-bnb-4bit\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "068c90ff-61f3-411d-93d0-2eb4f2fb713a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.3.18 patched 46 layers with 46 QKV layers, 46 O layers and 46 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the Alpaca dataset from [yahma](https://huggingface.co/datasets/yahma/alpaca-cleaned), which is a filtered version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html). You can replace this code section with your own data prep.\n",
        "\n",
        "**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n",
        "\n",
        "**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!\n",
        "\n",
        "If you want to use the `llama-3` template for ShareGPT datasets, try our conversational [notebook](https://colab.research.google.com/drive/1XamvWYinY6FOSX9GLvnqSjjsNflxdhNc?usp=sharing).\n",
        "\n",
        "For text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p0cehDqwcAFT"
      },
      "outputs": [],
      "source": [
        "# alpaca_prompt = \"\"\"Below is an instruction that describes a response, paired with a context field that provides further context. Write a response that appropriately answers the request.\n",
        "\n",
        "# ### Question:\n",
        "# {}\n",
        "\n",
        "# ### Context:\n",
        "# {}\n",
        "\n",
        "# ### Answer:\n",
        "# {}\"\"\"\n",
        "\n",
        "# EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "# def formatting_prompts_func(examples):\n",
        "#     instructions = examples[\"question\"]\n",
        "#     inputs       = examples[\"context\"]\n",
        "#     outputs      = examples[\"answers\"]\n",
        "#     texts = []\n",
        "#     for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "#         text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "#         texts.append(text)\n",
        "#     return {\"text\": texts}\n",
        "\n",
        "\n",
        "# from datasets import load_dataset\n",
        "# dataset = load_dataset(\"SajjadAyoubi/persian_qa\", split = \"train\")\n",
        "# train_test_dataset = dataset.train_test_split(test_size=0.2) #splits the train split into train and test.\n",
        "\n",
        "# train_dataset = train_test_dataset[\"train\"]\n",
        "# test_dataset = train_test_dataset[\"test\"]\n",
        "# train_dataset = train_dataset.map(formatting_prompts_func, batched = True,)\n",
        "# test_dataset = test_dataset.map(formatting_prompts_func, batched = True,)\n",
        "\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a response,\n",
        "paired with a context field that provides further context.\n",
        "Write a response that appropriately answers the request.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Context:\n",
        "{}\n",
        "\n",
        "### Answer:\n",
        "{}\"\"\"\n",
        "\n",
        "# if \"answers\" in item and \"text\" in item[\"answers\"] and len(item[\"answers\"][\"text\"]) > 0:\n",
        "#         reference = item[\"answers\"][\"text\"][0]  # Assuming a list of answers\n",
        "#       else:\n",
        "#           reference = \"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"question\"]\n",
        "    inputs       = examples[\"context\"]\n",
        "    outputs      = examples[\"answers\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        answer_text = output['text'][0] if output.get('text', []) else ''\n",
        "        text = alpaca_prompt.format(instruction, input, answer_text) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return {\"text\": texts}\n",
        "pass\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset_train = load_dataset(\"SajjadAyoubi/persian_qa\", split = \"train\")\n",
        "dataset_test = load_dataset(\"SajjadAyoubi/persian_qa\", split = \"validation\")\n",
        "dataset = dataset_train.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SNEgZxGthas",
        "outputId": "cd2b22c4-6e86-4a89-e8ff-63d5bac8f4e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': 51, 'title': '⁄©ÿ™ÿßÿ®', 'context': '⁄©ÿ™ÿßÿ® (ŸàÿßŸÖ\\u200cŸàÿß⁄òŸá ÿßÿ≤ ÿ≤ÿ®ÿßŸÜ ÿπÿ±ÿ®€åÿå ÿ¨ŸÖÿπ: ⁄©Ÿèÿ™Ÿèÿ®) ŸÖÿ¨ŸÖŸàÿπŸá\\u200cÿß€å ÿßÿ≤ ÿµŸÅÿ≠ÿßÿ™Ÿê ŸÜŸàÿ¥ÿ™Ÿá\\u200cÿ¥ÿØŸáÿå ŸÖÿµŸàŸëÿ±ÿå ⁄ÜÿßŸæ\\u200cÿ¥ÿØŸá €åÿß ÿµŸÅÿ≠ÿßÿ™ ÿÆÿßŸÑ€å (ÿµŸÅÿ≠Ÿá ÿ≥ŸÅ€åÿØ Ÿà ŸÜÿßŸÜŸàÿ¥ÿ™Ÿá)ÿõ ÿ≥ÿßÿÆÿ™Ÿá\\u200cÿ¥ÿØŸá ÿßÿ≥ÿ™. ÿßÿ≤ ŸÑŸàÿ≠\\u200cŸáÿß€å ⁄ØŸêŸÑ€åÿå ÿØÿ± ŸÖŸÜÿ∑ŸÇŸáŸî ÿ®€åŸÜ\\u200cÿßŸÑŸÜŸáÿ±€åŸÜ ÿ®ÿ±ÿß€å ŸÜŸàÿ¥ÿ™ŸÜ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å\\u200cÿ¥ÿØ. ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿß€åŸÜ ÿ±Ÿàÿ¥ ÿØÿ± €≤€µ€∞€∞ ÿ≥ÿßŸÑ ŸÇÿ®ŸÑ ÿßÿ≤ ŸÖ€åŸÑÿßÿØÿå ÿ™Ÿàÿ≥ÿ∑ ÿ™ŸÖÿØŸÜ ÿ≥ŸàŸÖÿ± ÿßÿ®ÿØÿßÿπ ÿ¥ÿØ Ÿà ÿ®Ÿá ÿ™⁄©ÿßŸÖŸÑ ÿ±ÿ≥€åÿØ. ÿßŸÖÿß ÿ®ÿß ⁄Øÿ∞ÿ¥ÿ™ ÿ≤ŸÖÿßŸÜÿå ÿ®ÿßÿ®ŸÑ€å\\u200cŸáÿß Ÿà ÿ¢ÿ¥Ÿàÿ±€å\\u200cŸáÿß ŸÜ€åÿ≤ ŸáŸÖ€åŸÜ ÿ±Ÿàÿ¥ ÿ±ÿß ÿ®Ÿá\\u200c⁄©ÿßÿ± ⁄Øÿ±ŸÅÿ™ŸÜÿØ. ÿß€åŸÜ ŸÑŸàÿ≠\\u200cŸáÿß ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿÆÿß⁄©Ÿê ÿ±ÿ≥ Ÿà ÿ¢ÿ® ÿ≥ÿßÿÆÿ™Ÿá ŸÖ€å\\u200cÿ¥ÿØŸÜÿØ Ÿà ŸÇÿ®ŸÑ ÿßÿ≤ ÿÆÿ¥⁄© ÿ¥ÿØŸÜÿå ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿßÿ®ÿ≤ÿßÿ±Ÿáÿß€å ŸÜŸà⁄©\\u200cÿ™€åÿ≤ ÿ®ÿ± ÿ±Ÿà€å ÿ¢ŸÜ\\u200cŸáÿß ŸÜŸàÿ¥ÿ™Ÿá ŸÖ€å\\u200cÿ¥ÿØ. ŸÜŸàÿ¥ÿ™Ÿá\\u200cŸáÿß€å ÿ®€åÿ¥ÿ™ÿ± ÿß€åŸÜ ŸÑŸàÿ≠\\u200cŸáÿßÿå ÿ®€åÿ¥ÿ™ÿ± ŸÖÿ±ÿ™ÿ®ÿ∑ ÿ®ÿß ÿßŸÖÿ± ÿ®ÿßÿ≤ÿ±⁄ØÿßŸÜ€åÿå ÿßÿØÿßÿ±€å Ÿà ÿ≠⁄©ŸàŸÖÿ™€å ÿ®ŸàÿØ.[€≥] ⁄©ÿØ⁄©ÿ≥ ÿ¥⁄©ŸÑ ÿßŸÖÿ±Ÿàÿ≤€å ⁄©ÿ™ÿßÿ® ÿßÿ≥ÿ™ÿõ €åÿπŸÜ€å ÿµŸÅÿ≠ÿßÿ™ ŸæŸàÿ≥ÿ™ÿå ŸæÿßŸæ€åÿ±Ÿàÿ≥ Ÿà ÿ∫€åÿ±Ÿá ⁄©Ÿá ÿ™ÿß ÿÆŸàÿ±ÿØŸá Ÿà ÿßÿ≤ €å⁄© ŸÖÿ≠ŸÑ ÿ®Ÿá €å⁄©ÿØ€å⁄Øÿ± ÿØŸàÿÆÿ™Ÿá ÿ¥ÿØŸá ÿ®ÿßÿ¥ŸÜÿØ. Ÿæ€åÿØÿß€åÿ¥ ⁄©ÿØ⁄©ÿ≥ ÿ®Ÿá ŸÇÿ±ŸÜŸê ÿØŸàŸÖ ŸÖ€åŸÑÿßÿØ€å ÿ®ÿ± ŸÖ€å\\u200c⁄Øÿ±ÿØÿØ ⁄©Ÿá ŸÖÿ≥€åÿ≠€åÿßŸÜ ÿßÿ≤ ÿ¢ŸÜ ÿ®ÿ±ÿß€å ŸÜ⁄Øÿßÿ±ÿ¥ ŸÖÿ™ŸàŸÜ ŸÖÿ∞Ÿáÿ®€å ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å\\u200c⁄©ÿ±ÿØŸÜÿØ. ÿß€åŸÜ ŸÅÿ±ŸÖ ÿßÿ≤ ⁄©ÿ™ÿßÿ®Ÿí ÿ®Ÿá\\u200cÿØŸÑ€åŸÑ ŸÖÿ≤€åÿ™\\u200cŸáÿß€å€å ⁄©Ÿá ÿØÿßÿ¥ÿ™ÿå ÿßÿ≤ ŸÇÿ±ŸÜ ⁄ÜŸáÿßÿ±ŸÖ ŸÖ€åŸÑÿßÿØ€å ÿ±Ÿàÿßÿ¨ Ÿæ€åÿØÿß ⁄©ÿ±ÿØ.', 'question': '⁄©ÿ™ÿßÿ® ⁄Ü€åŸáÿü', 'answers': {'text': ['ŸÖÿ¨ŸÖŸàÿπŸá\\u200cÿß€å ÿßÿ≤ ÿµŸÅÿ≠ÿßÿ™Ÿê ŸÜŸàÿ¥ÿ™Ÿá\\u200cÿ¥ÿØŸáÿå ŸÖÿµŸàŸëÿ±ÿå ⁄ÜÿßŸæ\\u200cÿ¥ÿØŸá €åÿß ÿµŸÅÿ≠ÿßÿ™ ÿÆÿßŸÑ€å (ÿµŸÅÿ≠Ÿá ÿ≥ŸÅ€åÿØ Ÿà ŸÜÿßŸÜŸàÿ¥ÿ™Ÿá)ÿõ ÿ≥ÿßÿÆÿ™Ÿá\\u200cÿ¥ÿØŸá'], 'answer_start': [41]}, 'text': 'Below is an instruction that describes a response, \\npaired with a context field that provides further context.\\nWrite a response that appropriately answers the request.\\n\\n### Question:\\n⁄©ÿ™ÿßÿ® ⁄Ü€åŸáÿü\\n\\n### Context:\\n⁄©ÿ™ÿßÿ® (ŸàÿßŸÖ\\u200cŸàÿß⁄òŸá ÿßÿ≤ ÿ≤ÿ®ÿßŸÜ ÿπÿ±ÿ®€åÿå ÿ¨ŸÖÿπ: ⁄©Ÿèÿ™Ÿèÿ®) ŸÖÿ¨ŸÖŸàÿπŸá\\u200cÿß€å ÿßÿ≤ ÿµŸÅÿ≠ÿßÿ™Ÿê ŸÜŸàÿ¥ÿ™Ÿá\\u200cÿ¥ÿØŸáÿå ŸÖÿµŸàŸëÿ±ÿå ⁄ÜÿßŸæ\\u200cÿ¥ÿØŸá €åÿß ÿµŸÅÿ≠ÿßÿ™ ÿÆÿßŸÑ€å (ÿµŸÅÿ≠Ÿá ÿ≥ŸÅ€åÿØ Ÿà ŸÜÿßŸÜŸàÿ¥ÿ™Ÿá)ÿõ ÿ≥ÿßÿÆÿ™Ÿá\\u200cÿ¥ÿØŸá ÿßÿ≥ÿ™. ÿßÿ≤ ŸÑŸàÿ≠\\u200cŸáÿß€å ⁄ØŸêŸÑ€åÿå ÿØÿ± ŸÖŸÜÿ∑ŸÇŸáŸî ÿ®€åŸÜ\\u200cÿßŸÑŸÜŸáÿ±€åŸÜ ÿ®ÿ±ÿß€å ŸÜŸàÿ¥ÿ™ŸÜ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å\\u200cÿ¥ÿØ. ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿß€åŸÜ ÿ±Ÿàÿ¥ ÿØÿ± €≤€µ€∞€∞ ÿ≥ÿßŸÑ ŸÇÿ®ŸÑ ÿßÿ≤ ŸÖ€åŸÑÿßÿØÿå ÿ™Ÿàÿ≥ÿ∑ ÿ™ŸÖÿØŸÜ ÿ≥ŸàŸÖÿ± ÿßÿ®ÿØÿßÿπ ÿ¥ÿØ Ÿà ÿ®Ÿá ÿ™⁄©ÿßŸÖŸÑ ÿ±ÿ≥€åÿØ. ÿßŸÖÿß ÿ®ÿß ⁄Øÿ∞ÿ¥ÿ™ ÿ≤ŸÖÿßŸÜÿå ÿ®ÿßÿ®ŸÑ€å\\u200cŸáÿß Ÿà ÿ¢ÿ¥Ÿàÿ±€å\\u200cŸáÿß ŸÜ€åÿ≤ ŸáŸÖ€åŸÜ ÿ±Ÿàÿ¥ ÿ±ÿß ÿ®Ÿá\\u200c⁄©ÿßÿ± ⁄Øÿ±ŸÅÿ™ŸÜÿØ. ÿß€åŸÜ ŸÑŸàÿ≠\\u200cŸáÿß ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿÆÿß⁄©Ÿê ÿ±ÿ≥ Ÿà ÿ¢ÿ® ÿ≥ÿßÿÆÿ™Ÿá ŸÖ€å\\u200cÿ¥ÿØŸÜÿØ Ÿà ŸÇÿ®ŸÑ ÿßÿ≤ ÿÆÿ¥⁄© ÿ¥ÿØŸÜÿå ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿßÿ®ÿ≤ÿßÿ±Ÿáÿß€å ŸÜŸà⁄©\\u200cÿ™€åÿ≤ ÿ®ÿ± ÿ±Ÿà€å ÿ¢ŸÜ\\u200cŸáÿß ŸÜŸàÿ¥ÿ™Ÿá ŸÖ€å\\u200cÿ¥ÿØ. ŸÜŸàÿ¥ÿ™Ÿá\\u200cŸáÿß€å ÿ®€åÿ¥ÿ™ÿ± ÿß€åŸÜ ŸÑŸàÿ≠\\u200cŸáÿßÿå ÿ®€åÿ¥ÿ™ÿ± ŸÖÿ±ÿ™ÿ®ÿ∑ ÿ®ÿß ÿßŸÖÿ± ÿ®ÿßÿ≤ÿ±⁄ØÿßŸÜ€åÿå ÿßÿØÿßÿ±€å Ÿà ÿ≠⁄©ŸàŸÖÿ™€å ÿ®ŸàÿØ.[€≥] ⁄©ÿØ⁄©ÿ≥ ÿ¥⁄©ŸÑ ÿßŸÖÿ±Ÿàÿ≤€å ⁄©ÿ™ÿßÿ® ÿßÿ≥ÿ™ÿõ €åÿπŸÜ€å ÿµŸÅÿ≠ÿßÿ™ ŸæŸàÿ≥ÿ™ÿå ŸæÿßŸæ€åÿ±Ÿàÿ≥ Ÿà ÿ∫€åÿ±Ÿá ⁄©Ÿá ÿ™ÿß ÿÆŸàÿ±ÿØŸá Ÿà ÿßÿ≤ €å⁄© ŸÖÿ≠ŸÑ ÿ®Ÿá €å⁄©ÿØ€å⁄Øÿ± ÿØŸàÿÆÿ™Ÿá ÿ¥ÿØŸá ÿ®ÿßÿ¥ŸÜÿØ. Ÿæ€åÿØÿß€åÿ¥ ⁄©ÿØ⁄©ÿ≥ ÿ®Ÿá ŸÇÿ±ŸÜŸê ÿØŸàŸÖ ŸÖ€åŸÑÿßÿØ€å ÿ®ÿ± ŸÖ€å\\u200c⁄Øÿ±ÿØÿØ ⁄©Ÿá ŸÖÿ≥€åÿ≠€åÿßŸÜ ÿßÿ≤ ÿ¢ŸÜ ÿ®ÿ±ÿß€å ŸÜ⁄Øÿßÿ±ÿ¥ ŸÖÿ™ŸàŸÜ ŸÖÿ∞Ÿáÿ®€å ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å\\u200c⁄©ÿ±ÿØŸÜÿØ. ÿß€åŸÜ ŸÅÿ±ŸÖ ÿßÿ≤ ⁄©ÿ™ÿßÿ®Ÿí ÿ®Ÿá\\u200cÿØŸÑ€åŸÑ ŸÖÿ≤€åÿ™\\u200cŸáÿß€å€å ⁄©Ÿá ÿØÿßÿ¥ÿ™ÿå ÿßÿ≤ ŸÇÿ±ŸÜ ⁄ÜŸáÿßÿ±ŸÖ ŸÖ€åŸÑÿßÿØ€å ÿ±Ÿàÿßÿ¨ Ÿæ€åÿØÿß ⁄©ÿ±ÿØ.\\n\\n### Answer:\\nŸÖÿ¨ŸÖŸàÿπŸá\\u200cÿß€å ÿßÿ≤ ÿµŸÅÿ≠ÿßÿ™Ÿê ŸÜŸàÿ¥ÿ™Ÿá\\u200cÿ¥ÿØŸáÿå ŸÖÿµŸàŸëÿ±ÿå ⁄ÜÿßŸæ\\u200cÿ¥ÿØŸá €åÿß ÿµŸÅÿ≠ÿßÿ™ ÿÆÿßŸÑ€å (ÿµŸÅÿ≠Ÿá ÿ≥ŸÅ€åÿØ Ÿà ŸÜÿßŸÜŸàÿ¥ÿ™Ÿá)ÿõ ÿ≥ÿßÿÆÿ™Ÿá\\u200cÿ¥ÿØŸá<eos>'}\n"
          ]
        }
      ],
      "source": [
        "print(dataset[40])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q-MoYlJcrPnL"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 8,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 90,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"qw\",\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "8ba8ab9c-f12a-403a-c039-f7239aee2160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "11.684 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "c67324ec-b3c0-48b4-ae87-d590c42248ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 9,008 | Num Epochs = 1 | Total steps = 90\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n",
            " \"-____-\"     Trainable parameters = 114,180,096/27,000,000,000 (0.42% trained)\n",
            "AUTOTUNE bmm(256x456x128, 256x128x456)\n",
            "  bmm 0.2253 ms 100.0% \n",
            "  triton_bmm_14 0.4219 ms 53.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_10 0.4690 ms 48.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_5 0.4844 ms 46.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_13 0.4946 ms 45.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_6 0.5325 ms 42.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_18 0.5499 ms 41.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_3 0.5519 ms 40.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_15 0.5540 ms 40.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=8\n",
            "  triton_bmm_9 0.6103 ms 36.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "SingleProcess AUTOTUNE benchmarking takes 2.5631 seconds and 0.0089 seconds precompiling\n",
            "AUTOTUNE bmm(256x456x456, 256x456x128)\n",
            "  bmm 0.1464 ms 100.0% \n",
            "  triton_bmm_33 0.3328 ms 44.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_29 0.3840 ms 38.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_32 0.3963 ms 37.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_37 0.4127 ms 35.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_24 0.4178 ms 35.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_25 0.4291 ms 34.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_34 0.4424 ms 33.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=8\n",
            "  triton_bmm_22 0.4639 ms 31.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_28 0.5028 ms 29.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "SingleProcess AUTOTUNE benchmarking takes 2.5335 seconds and 0.0024 seconds precompiling\n",
            "AUTOTUNE bmm(256x456x456, 256x456x128)\n",
            "  bmm 0.1454 ms 100.0% \n",
            "  triton_bmm_81 0.3645 ms 39.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_78 0.4659 ms 31.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_79 0.4925 ms 29.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_76 0.4956 ms 29.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=2\n",
            "  triton_bmm_82 0.5612 ms 25.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_85 0.6308 ms 23.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_89 0.6461 ms 22.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_92 0.7127 ms 20.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_83 0.7322 ms 19.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=8\n",
            "SingleProcess AUTOTUNE benchmarking takes 2.5871 seconds and 0.0024 seconds precompiling\n",
            "AUTOTUNE bmm(256x456x128, 256x128x456)\n",
            "  bmm 0.1843 ms 100.0% \n",
            "  triton_bmm_105 0.3820 ms 48.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_108 0.3901 ms 47.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_104 0.3942 ms 46.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_100 0.4147 ms 44.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_101 0.4219 ms 43.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_109 0.4239 ms 43.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_110 0.4495 ms 41.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=8\n",
            "  triton_bmm_113 0.5243 ms 35.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_95 0.5560 ms 33.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=2\n",
            "SingleProcess AUTOTUNE benchmarking takes 2.5326 seconds and 0.0025 seconds precompiling\n",
            "AUTOTUNE bmm(256x128x456, 256x456x456)\n",
            "  bmm 0.1464 ms 100.0% \n",
            "  triton_bmm_119 0.3676 ms 39.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_117 0.4741 ms 30.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_116 0.5038 ms 29.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_114 0.5069 ms 28.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=2\n",
            "  triton_bmm_120 0.5857 ms 25.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_123 0.6431 ms 22.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_127 0.6461 ms 22.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_128 0.7465 ms 19.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_124 0.7578 ms 19.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "SingleProcess AUTOTUNE benchmarking takes 2.5833 seconds and 0.0026 seconds precompiling\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [90/90 21:55, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.957700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.031700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.103200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.961700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.891400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.848300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.769400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.606900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.679700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.662000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.602800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.664000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.660900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.618200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.560400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.591400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.523600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.532200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.530300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.590700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.438000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.541500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.455900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.501800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.614000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.539600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.569900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.489300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.536200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.582800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.503100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.489800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.577200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.523400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.541000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.516000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.482400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.389200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.487100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.493200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.426000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.465900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.397200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.494200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.476400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.421900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.386600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.353600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.421500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.423000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.421900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.369600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.410100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.469400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.389600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.512700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.439100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.409800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.386800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>1.315300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.379200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>1.295400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.410300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1.376600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1.391900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>1.357300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.324800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1.449600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.366300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>1.307800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.285600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>1.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>1.310500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.312300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.354400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>1.322300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>1.329000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>1.248600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.252700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>1.298200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>1.441600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>1.283100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>1.307100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>1.298400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>1.285200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>1.330900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>1.374600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>1.335400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.335200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCqnaKmlO1U9"
      },
      "outputs": [],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "07a06471-4fd5-4e7f-8128-ad9cba47dbac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "AUTOTUNE bmm(16x55x256, 16x256x55)\n",
            "  triton_bmm_153 0.0133 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_166 0.0143 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_155 0.0154 ms 86.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_159 0.0154 ms 86.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=8\n",
            "  triton_bmm_158 0.0164 ms 81.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_161 0.0164 ms 81.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  bmm 0.0174 ms 76.5% \n",
            "  triton_bmm_154 0.0174 ms 76.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_163 0.0174 ms 76.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_162 0.0195 ms 68.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "SingleProcess AUTOTUNE benchmarking takes 1.8075 seconds and 0.0086 seconds precompiling for 16 choices\n",
            "AUTOTUNE bmm(16x55x55, 16x55x256)\n",
            "  bmm 0.0102 ms 100.0% \n",
            "  triton_bmm_168 0.0102 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_169 0.0102 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_170 0.0102 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_174 0.0102 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=8\n",
            "  triton_bmm_181 0.0102 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_171 0.0113 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4\n",
            "  triton_bmm_173 0.0113 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_175 0.0113 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4\n",
            "  triton_bmm_180 0.0113 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "SingleProcess AUTOTUNE benchmarking takes 2.0411 seconds and 0.0023 seconds precompiling for 18 choices\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['<bos>Below is an instruction that describes a response,\\npaired with a context field that provides further context.\\nWrite a response that appropriately answers the request.\\n\\n### Question:\\nfdsfsdfdsfÿü\\n\\n### Context:\\nddsddsÿü\\n\\n### Answer:\\n<eos>']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"fdsfsdfdsfÿü\", # instruction\n",
        "        \"ddsddsÿü\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2pEuRb1r2Vg",
        "outputId": "d507298f-93f9-4e70-8d9e-689280975ce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bos>Below is an instruction that describes a response,\n",
            "paired with a context field that provides further context.\n",
            "Write a response that appropriately answers the request.\n",
            "\n",
            "### Question:\n",
            "ÿ™ÿπÿØÿßÿØ ÿØÿ±ÿÆÿ™ÿßŸÜ ÿ≥€åÿ® ⁄©ÿ¥ŸÅ ÿ¥ÿØŸáÿü\n",
            "\n",
            "### Context:\n",
            "\n",
            "\n",
            "### Answer:\n",
            "ÿ™ÿπÿØÿßÿØ ÿØÿ±ÿÆÿ™ÿßŸÜ ÿ≥€åÿ® ⁄©ÿ¥ŸÅ ÿ¥ÿØŸá: 10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n"
          ]
        }
      ],
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"ÿ™ÿπÿØÿßÿØ ÿØÿ±ÿÆÿ™ÿßŸÜ ÿ≥€åÿ® ⁄©ÿ¥ŸÅ ÿ¥ÿØŸáÿü\", # instruction\n",
        "        \"\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upcOlWe7A1vc"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"lora_model\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WGctFj4tFRxj"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login #writing to huggingface\n",
        "login(token=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227,
          "referenced_widgets": [
            "e6b53e073e8c4ba28ab19bf4611bce9d",
            "f75076bcb82f4f6d8aabc5c21666f3f7",
            "82cc8530ac004692a0189b1d677c93a3",
            "2733c3d8322f4f5d9db036a737e1c7d6",
            "61453f5ff35d445f8570ef1692423224",
            "82877abdcec240f5b7e31441cb56224d",
            "17fe36d10b024205a711741b4aaf8cfe",
            "61a584d55ffe4e99a5068ef0055b2cca",
            "0c79cd4bf6da4fed8c461138bbeb7520",
            "8aa451cb830b42878747a15411e7ed59",
            "b9aad5dc41104e91b5642b21f3bf647e",
            "d43b95c3fc254361abac8d0817d3b833",
            "e7041dc9a8374b89bf750c3aeca6b322",
            "792ce938302841e3b3218e84546e05cb",
            "158c186cdd9b48e2b07a013abd7b7a28",
            "b5c49c409bc24535a1f86f16e2d8752b",
            "83dfae177c234ee98e0652ad2d461a8f",
            "35889ba2cf394ff990a4dc4852608d1e",
            "8e758be310de44e997ca38a52213d675",
            "61fe6e7dca64435786a4aeb795c36648",
            "10169a2c15f2428ab6803a2820cc8c65",
            "1f9efc99625d497689e2ca55b36089be",
            "bad661e3c0524b46aa2815b216c00036",
            "ec44a47e266b40e4b5e1a72dabcf8e94",
            "cf0ee4d68cc5437abc21b5b5a93ee91f",
            "361c01b66c824ed59c297727820ea5b6",
            "1061e8b4991048f7a981a665d87f4fdb",
            "2d00f2ba25f14c4f892b58eb7fcf587b",
            "3cfc822d63a948a3820ae71283e33746",
            "59b948620f8347d1be13af37fd78e2e1",
            "0b36d079b4f64d24bfa6a97d60423edd",
            "1285896f5b874909b8f2e2cb762ca033",
            "521c4538cb8b44338f39f8ac872c4d93",
            "43044c9f547a495090a58148db1bf60c",
            "c0480e4a196e45b0acb0fb9284c4bce8",
            "8fbb7e2cb8624651911397cc0d556806",
            "460a8f5665df40f18c4d066c88f07e08",
            "f62c43a078e54c96b80f581f977835ae",
            "cb8f98359c62471b8ec20bbf9ae62789",
            "375e6e53751f48cb864448ec390571d8",
            "7c4c5af53f0b4e9e9c02a63ca341f7e2",
            "d3d634abf142465d9e21d85d1f62f108",
            "1ced9679ab9947e3b778626b574abc44",
            "f0a2d28c719d4b79bf067e5be4c9c581",
            "6c8a1d47ef9244b88568baeb13b6add9",
            "4bcf868feb614558b776334c5f792ebc",
            "d005ceec96574da9be57cd0a91168a01",
            "11091850396a44bba5a04727fa57470a",
            "dd9436e158db47e2a1fc96e35c428092",
            "12bbd0219b1f4e078d2d2240d4eec486",
            "76163832d5a948b7b440ba5b4d027701",
            "4d846ab6a7fb43ecbe157a5e4dfc6ba2",
            "bbd07c7ed04148ccbabeb1c270d2b1f6",
            "fd92faf02f5847648ce94f95915ffe12",
            "affa13203281457b8373ff6003f6e2f6",
            "77db02d6b4e640c797064bfec1412be1",
            "c7ef5b86365a469499ce8fb761fbbfaf",
            "740c00974eca4dd3b198e4e88c29df80",
            "bb4c5073c68143608ccab403c451ed4e",
            "78f93cc2a57548b7aa3069945ac6df52",
            "75e60310dc474864b353a4a6a286281b",
            "5c147e3d90154497887bfdf26c7c75bc",
            "dedb39f2d6bb48b7830cb00a7e94cf1a",
            "e42a1958313043de9f3b1f70b88e20b4",
            "4917b0fc680345c297a0c9bc0371db0d",
            "0ab5c5043d8244679d6e985c45aaf94a"
          ]
        },
        "id": "enVXWEqbL65b",
        "outputId": "24ff9e11-ab39-4eba-f32d-d96520d46843"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6b53e073e8c4ba28ab19bf4611bce9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/575 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d43b95c3fc254361abac8d0817d3b833",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bad661e3c0524b46aa2815b216c00036",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/457M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model to https://huggingface.co/regd/gemma227b90step2e-4\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43044c9f547a495090a58148db1bf60c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c8a1d47ef9244b88568baeb13b6add9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77db02d6b4e640c797064bfec1412be1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.push_to_hub(\"regd/gemma227b90step2e-4\")\n",
        "trainer.create_model_card(\"regd/gemma227b90step2e-4\")\n",
        "tokenizer.push_to_hub(\"regd/gemma227b90step2e-4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rwbWiXSX0Sz8"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login #reading from huggingface\n",
        "login(token=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKivnsvP5e1v"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zi82gbFK0YQE"
      },
      "outputs": [],
      "source": [
        "%pip install -U bitsandbytes --quiet\n",
        "%pip install datasets --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GQ3T7rMILQz_"
      },
      "outputs": [],
      "source": [
        "%pip install tqdm --quiet\n",
        "%pip install unsloth --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vExX6xerfTVS"
      },
      "outputs": [],
      "source": [
        "%pip install bert-score --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "1ae3e1179efe426bb5cc5f401be97c7f",
            "907deca0fe2b47c4a9cd24fc8ce7533e",
            "1ca7bf5538d3485ca4d9c1ffb77d8756",
            "3ac1325106b14741b81038fa79361bd5",
            "ebac52b9cf0f47479d6eacc4b3d1214f",
            "793f1509f09840e5bab348a0cd01aa44",
            "4afa549de0a64312bf964a10567e39d1",
            "1fab2f0843ba459da42e8c3daa37e3fa",
            "a38f77856ffa4c98be9cbd023cf40fd5",
            "72da54debc634cdba81b9fc97fa9afa6",
            "49ce160cf5e0461fb20e6e63721c9b8b"
          ]
        },
        "id": "12TyVMgEDm4x",
        "outputId": "f2bb82a1-6e7a-4246-9875-1ef1cd01d5d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ae3e1179efe426bb5cc5f401be97c7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM  # Import the AutoModel class\n",
        "model_name = \"regd/gemma227b90step2e-4\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name) # Now AutoModel should be defined\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JKrT3Osc5ySq"
      },
      "outputs": [],
      "source": [
        "# dataset_test\n",
        "def format_prompt(question, context=None):\n",
        "         if context:\n",
        "             prompt = f\"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
        "         else:\n",
        "             prompt = f\"Question: {question}\\n\\nAnswer:\"\n",
        "         return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TR32FbWU6UKF"
      },
      "outputs": [],
      "source": [
        "def generate_answer(model, tokenizer, prompt, max_new_tokens=20, max_seq_length=2048):\n",
        "         inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "         with torch.no_grad():\n",
        "             outputs = model.generate(\n",
        "                 **inputs,\n",
        "                 max_new_tokens=max_new_tokens,\n",
        "                 temperature=0.7, # Adjust as needed\n",
        "                 top_p=0.9,      # Adjust as needed\n",
        "                 do_sample=False,\n",
        "                 max_length = 20,\n",
        "                 eos_token_id=tokenizer.eos_token_id,\n",
        "                 use_cache=False,\n",
        "                #  num_beams=5,\n",
        "                #  early_stopping=True\n",
        "             )\n",
        "         answer = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
        "         return answer.strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TIo9Xjt-6t76"
      },
      "outputs": [],
      "source": [
        "def evaluate_f1_token(prediction, reference):\n",
        "          pred_tokens = prediction.lower().split()\n",
        "          ref_tokens = reference.lower().split()\n",
        "          common = set(pred_tokens) & set(ref_tokens)\n",
        "          if len(pred_tokens) == 0 or len(ref_tokens) == 0:\n",
        "              return 0.0\n",
        "          precision = len(common) / len(pred_tokens)\n",
        "          recall = len(common) / len(ref_tokens)\n",
        "          if precision + recall == 0:\n",
        "              return 0.0\n",
        "          f1 = 2 * precision * recall / (precision + recall)\n",
        "          return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yXKEar5QZf_Z"
      },
      "outputs": [],
      "source": [
        "def evaluate_exact_match(prediction, reference):\n",
        "    \"\"\"\n",
        "    Calculates the Exact Match (EM) score between a prediction and a reference.\n",
        "\n",
        "    Args:\n",
        "        prediction (str): The predicted answer.\n",
        "        reference (str): The reference answer.\n",
        "\n",
        "    Returns:\n",
        "        float: 1.0 if the prediction exactly matches the reference, 0.0 otherwise.\n",
        "    \"\"\"\n",
        "    if prediction.strip().lower() == reference.strip().lower():\n",
        "        return 1.0\n",
        "    else:\n",
        "        return 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8MH0Q97Be3Wz"
      },
      "outputs": [],
      "source": [
        "from bert_score import score\n",
        "\n",
        "def evaluate_bert_score(prediction, reference, lang=\"en\", model_type=None, num_layers=None, verbose=False):\n",
        "    \"\"\"\n",
        "    Calculates BERTScore for a single prediction and reference.\n",
        "\n",
        "    Args:\n",
        "        prediction (str): The predicted sentence.\n",
        "        reference (str): The reference sentence.\n",
        "        lang (str): Language of the sentences (e.g., \"en\", \"es\").\n",
        "        model_type (str, optional): BERT model to use (e.g., \"bert-base-uncased\"). If None, it will be automatically inferred from lang.\n",
        "        num_layers (int, optional): Number of BERT layers to use.\n",
        "        verbose (bool, optional): Print progress.\n",
        "\n",
        "    Returns:\n",
        "        float: The F1-score from BERTScore, or 0.0 if there is an error.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        P, R, F1 = score([prediction], [reference], lang=lang, model_type=model_type, num_layers=num_layers, verbose=verbose)\n",
        "        return F1.item()  # Return the F1 score as a float\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating BERTScore: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "# Example usage (replace your existing evaluate_f1_token calls):\n",
        "# ... (your existing code) ...\n",
        "\n",
        "# Replace calls to evaluate_f1_token with evaluate_bert_score\n",
        "# f1_score = evaluate_f1_token(prediction, reference)\n",
        "# f1_score = evaluate_bert_score(prediction, reference)\n",
        "\n",
        "# ... (rest of your code) ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGE-nfSKX73q",
        "outputId": "b9c32df7-09f5-4ecb-8942-1228717c5862"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.\n",
            "Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:   1%|          | 1/100 [00:08<14:11,  8.60s/it]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:   2%|‚ñè         | 2/100 [00:15<11:59,  7.34s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:   3%|‚ñé         | 3/100 [00:21<11:11,  6.92s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:   4%|‚ñç         | 4/100 [00:27<10:43,  6.70s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:   5%|‚ñå         | 5/100 [00:34<10:25,  6.59s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:   6%|‚ñå         | 6/100 [00:40<10:14,  6.54s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:   7%|‚ñã         | 7/100 [00:47<10:07,  6.53s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:   8%|‚ñä         | 8/100 [00:53<10:07,  6.60s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:   9%|‚ñâ         | 9/100 [01:00<09:56,  6.55s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  10%|‚ñà         | 10/100 [01:06<09:47,  6.53s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  11%|‚ñà         | 11/100 [01:13<09:33,  6.45s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  12%|‚ñà‚ñè        | 12/100 [01:19<09:30,  6.48s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  13%|‚ñà‚ñé        | 13/100 [01:26<09:42,  6.70s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  14%|‚ñà‚ñç        | 14/100 [01:33<09:25,  6.57s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  15%|‚ñà‚ñå        | 15/100 [01:39<09:13,  6.51s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  16%|‚ñà‚ñå        | 16/100 [01:45<09:02,  6.45s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  17%|‚ñà‚ñã        | 17/100 [01:54<10:00,  7.23s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  18%|‚ñà‚ñä        | 18/100 [02:01<09:30,  6.96s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  19%|‚ñà‚ñâ        | 19/100 [02:07<09:10,  6.80s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  20%|‚ñà‚ñà        | 20/100 [02:13<08:52,  6.65s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  21%|‚ñà‚ñà        | 21/100 [02:20<08:54,  6.76s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  22%|‚ñà‚ñà‚ñè       | 22/100 [02:27<08:36,  6.62s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  23%|‚ñà‚ñà‚ñé       | 23/100 [02:33<08:21,  6.52s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  24%|‚ñà‚ñà‚ñç       | 24/100 [02:39<08:09,  6.44s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  25%|‚ñà‚ñà‚ñå       | 25/100 [02:46<08:01,  6.42s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  26%|‚ñà‚ñà‚ñå       | 26/100 [02:52<08:00,  6.49s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  27%|‚ñà‚ñà‚ñã       | 27/100 [02:59<07:49,  6.42s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  28%|‚ñà‚ñà‚ñä       | 28/100 [03:05<07:39,  6.38s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  29%|‚ñà‚ñà‚ñâ       | 29/100 [03:11<07:31,  6.35s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  30%|‚ñà‚ñà‚ñà       | 30/100 [03:17<07:21,  6.31s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  31%|‚ñà‚ñà‚ñà       | 31/100 [03:24<07:17,  6.34s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [03:30<07:12,  6.36s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [03:37<07:08,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  34%|‚ñà‚ñà‚ñà‚ñç      | 34/100 [03:43<07:05,  6.44s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [03:50<06:58,  6.44s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [03:56<06:55,  6.49s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [04:03<06:50,  6.52s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [04:09<06:42,  6.49s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [04:16<06:35,  6.48s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [04:22<06:28,  6.47s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [04:29<06:24,  6.52s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [04:35<06:15,  6.47s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [04:42<06:06,  6.44s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [04:48<05:59,  6.42s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [04:54<05:52,  6.40s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [05:01<05:45,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [05:07<05:38,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [05:14<05:34,  6.44s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [05:20<05:27,  6.41s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [05:26<05:19,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [05:33<05:11,  6.35s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [05:39<05:03,  6.32s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 53/100 [05:45<04:56,  6.31s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54/100 [05:51<04:49,  6.30s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [05:58<04:43,  6.30s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/100 [06:04<04:42,  6.42s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [06:11<04:35,  6.41s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 58/100 [06:17<04:27,  6.38s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [06:23<04:20,  6.35s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [06:30<04:14,  6.36s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [06:37<04:14,  6.52s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [06:47<04:49,  7.63s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [06:54<04:34,  7.43s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64/100 [07:00<04:17,  7.16s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [07:07<04:04,  6.99s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [07:13<03:52,  6.84s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 67/100 [07:20<03:44,  6.80s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [07:27<03:41,  6.92s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [07:34<03:30,  6.79s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [07:40<03:20,  6.70s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [07:47<03:10,  6.57s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [07:53<03:01,  6.49s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [07:59<02:53,  6.43s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 74/100 [08:07<03:01,  6.97s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [08:14<02:50,  6.82s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [08:20<02:39,  6.65s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [08:26<02:30,  6.54s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [08:33<02:21,  6.45s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [08:39<02:14,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [08:45<02:06,  6.35s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [08:51<02:00,  6.33s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [08:58<01:53,  6.31s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [09:04<01:48,  6.37s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [09:10<01:41,  6.34s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [09:17<01:35,  6.33s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [09:23<01:28,  6.31s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [09:30<01:23,  6.42s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 88/100 [09:36<01:16,  6.36s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [09:42<01:09,  6.33s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [09:48<01:03,  6.31s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [09:55<00:56,  6.33s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [10:01<00:50,  6.36s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [10:08<00:45,  6.45s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [10:14<00:38,  6.42s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [10:21<00:32,  6.41s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [10:27<00:25,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [10:33<00:19,  6.38s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [10:40<00:12,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [10:46<00:06,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [10:53<00:00,  6.53s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'question': 'Ÿæÿß€åÿ™ÿÆÿ™ ÿßÿ≥ŸæÿßŸÜ€åÿß ⁄©ÿ¨ÿßÿ≥ÿ™ÿü',\n",
              "  'reference': 'ŸÖÿßÿØÿ±€åÿØ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ®ÿ± ⁄ÜŸá ÿßÿ≥ÿßÿ≥€å ÿ±ÿ¶ÿßŸÑ ŸÖŸàŸÅŸÇ ÿ™ÿ±€åŸÜ ÿ™€åŸÖ ÿØÿ± ÿ™ÿßÿ±€åÿÆ ŸÅŸàÿ™ÿ®ÿßŸÑ ÿßÿ±ŸàŸæÿß ÿßÿ≥ÿ™ÿü',\n",
              "  'reference': 'ŸÅ€åŸÅÿß',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ±ÿ¶ÿßŸÑ ŸÖÿßÿØÿ±€åÿØ ⁄ÜŸÜÿØ ÿ®ÿßÿ± ÿØÿ± ŸÑ€å⁄Ø ŸÇŸáÿ±ŸÖÿßŸÜÿßŸÜ ÿßÿ±ŸàŸæÿß ÿ®Ÿá ÿπŸÜŸàÿßŸÜ ŸÇŸáÿ±ŸÖÿßŸÜ€å ÿ±ÿ≥€åÿØŸáÿü',\n",
              "  'reference': '€±€≥',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÖÿπŸÜ€å Ÿàÿß⁄òŸá ÿ±ÿ¶ÿßŸÑ ÿ®Ÿá ÿßÿ≥ŸæÿßŸÜ€åÿß€å€å ⁄Ü€åÿ≥ÿ™ÿü',\n",
              "  'reference': 'ÿ≥ŸÑÿ∑ŸÜÿ™€å',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ™€åŸÖ ÿ±ÿ¶ÿßŸÑ ŸÖÿßÿØÿ±€åÿØ ÿ®ÿ±ÿß€å ⁄©ÿ¨ÿßÿ≥ÿ™ÿü',\n",
              "  'reference': 'ŸÖÿßÿØÿ±€åÿØÿå Ÿæÿß€åÿ™ÿÆÿ™ ÿßÿ≥ŸæÿßŸÜ€åÿß',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÑŸÇÿ® ÿ®ÿßÿ¥⁄ØÿßŸá ÿ±ÿ¶ÿßŸÑ ŸÖÿßÿØÿ±€åÿØ ÿßÿ≤ ⁄©ÿ¨ÿß ŸÖ€åÿßÿØÿü',\n",
              "  'reference': 'ÿ¥ÿßŸá ÿ¢ŸÑŸÅŸàŸÜÿ≥Ÿà ÿ≥€åÿ≤ÿØŸáŸÖ ÿØÿ± ÿ≥ÿßŸÑ €±€π€≤€∞ ÿ®ÿ± ÿß€åŸÜ ÿ™€åŸÖ ŸÜŸáÿßÿØ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿØÿ¥ŸÖŸÜ ÿßÿµŸÑ€å ÿ®ÿßÿ¥⁄ØÿßŸá ŸÅŸàÿ™ÿ®ÿßŸÑ ÿ±ÿ¶ÿßŸÑ ŸÖÿßÿØÿ±€åÿØ ⁄©ÿØÿßŸÖ ÿ™€åŸÖ ÿßÿ≥ÿ™ÿü',\n",
              "  'reference': 'ÿ±ŸÇ€åÿ® ÿßÿµŸÑ€å ÿß€åŸÜ ÿ™€åŸÖ ŸÜ€åÿ≤ÿå ÿ®ÿßÿ±ÿ≥ŸÑŸàŸÜÿß ÿßÿ≥ÿ™',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ®ÿßÿ±ÿ≥ŸÑŸàŸÜÿß ⁄ÜŸÜÿØ ÿ®ÿßÿ± ŸÇŸáÿ±ŸÖÿßŸÜ ŸÑ€å⁄Ø ŸÇŸáÿ±ŸÖÿßŸÜÿßŸÜ ÿßÿ±ŸàŸæÿß ÿ¥ÿØŸáÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ®ÿßÿ¥⁄ØÿßŸá ŸÅŸàÿ™ÿ®ÿßŸÑ ÿ±ÿ¶ÿßŸÑ ŸÖÿßÿØÿ±€åÿØ ÿØÿ± ⁄ÜŸá ÿ≥ÿßŸÑ€å ÿ™ÿßÿ≥€åÿ≥ ÿ¥ÿØŸáÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ±⁄©Ÿàÿ±ÿØÿØÿßÿ± ÿ®€åÿ¥ÿ™ÿ±€åŸÜ ŸÇŸáÿ±ŸÖÿßŸÜ€å ÿØÿ± ŸÑ€å⁄Ø ŸÇŸáÿ±ŸÖÿßŸÜÿßŸÜ ÿ¢ÿ≥€åÿß ⁄©ÿØÿßŸÖ ÿ™€åŸÖ ÿßÿ≥ÿ™ÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ®ÿßÿ±ÿ≥ÿß ŸÖÿÆŸÅŸÅ ⁄Ü€åŸáÿü',\n",
              "  'reference': 'ÿ®ÿßÿ±ÿ≥ŸÑŸàŸÜÿß',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ™€åŸÖ ÿ®ÿßÿ±ÿ≥ŸÑŸàŸÜÿß ÿ®ÿ±ÿß€å ⁄©ÿØÿßŸÖ ⁄©ÿ¥Ÿàÿ± ÿßÿ≥ÿ™ÿü',\n",
              "  'reference': 'ÿßÿ≥ŸæÿßŸÜ€åÿß',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ¥Ÿáÿ± ÿ®ÿßÿ±ÿ≥ŸÑŸàŸÜ ÿØÿ± ⁄©ÿ¨ÿß€å ⁄©ÿ¥Ÿàÿ± ÿßÿ≥ŸæÿßŸÜ€åÿß ŸàÿßŸÇÿπ ÿ¥ÿØŸáÿü',\n",
              "  'reference': 'ŸÖŸÜÿ∑ŸÇŸáŸî ⁄©ÿßÿ™ÿßŸÑŸàŸÜ€åÿß€å',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄Üÿ±ÿß ÿ¥ÿπÿßÿ± ÿ™€åŸÖ ÿ®ÿßÿ±ÿ≥ÿß ŸÅÿ±ÿßÿ™ÿ± ÿßÿ≤ €å⁄© ÿ®ÿßÿ¥⁄ØÿßŸá ÿßÿ≥ÿ™ÿü',\n",
              "  'reference': 'ÿ®Ÿá ŸÜŸàÿπ€åÿå ŸÜŸáÿßÿØ€å ÿ®ÿ±ÿß€å ÿ™ÿ±Ÿà€åÿ¨ ŸÅÿ±ŸáŸÜ⁄Ø ⁄©ÿßÿ™ÿßŸÑÿßŸÜ Ÿà ⁄©ÿßÿ™ÿßŸÑÿßŸÜ€åÿ≥ŸÖ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ¢ŸáŸÜ⁄Ø ÿ±ÿ≥ŸÖ€å ÿ™€åŸÖ ÿ®ÿßÿ±ÿ≥ÿß ÿ±ÿß ⁄ÜŸá ⁄©ÿ≥€å ÿ≥ÿßÿÆÿ™Ÿáÿü',\n",
              "  'reference': 'ÿ¨Ÿàÿ≤Ÿæ ŸÖÿßÿ±€åÿß ÿßÿ≥Ÿæ€åŸÜÿßÿ≥',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ™€åŸÖ ÿ®ÿßÿ±ÿ≥ÿß ÿ®Ÿá ⁄ÜŸá ÿµŸàÿ±ÿ™ ÿßÿØÿßÿ±Ÿá ŸÖ€å ÿ¥ŸàÿØÿü',\n",
              "  'reference': 'ÿ™Ÿàÿ≥ÿ∑ ŸáŸàÿßÿØÿßÿ±ÿßŸÜÿ¥',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿπŸÖÿØŸá ÿπŸÑÿ™ ÿ¥Ÿáÿ±ÿ™ ÿ™€åŸÖ ÿ®ÿßÿ±ÿ≥ÿß ÿ®ÿ±ÿß€å ⁄Ü€åÿ≥ÿ™ÿü',\n",
              "  'reference': 'ÿ¥€åŸàŸá ÿ≠ŸÖŸÑŸá\\u200cÿß€å ŸÖÿßŸáÿ±ÿßŸÜŸá Ÿà ÿ¨ÿ∞ÿßÿ®ÿ¥',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ™€åŸÖ ÿ®ÿßÿ±ÿ≥ÿß ÿØÿ± ⁄ÜŸá ÿ≥ÿßŸÑ€å ÿßŸàŸÑ€åŸÜ ÿ®ÿßÿ± ŸÇŸáÿ±ŸÖÿßŸÜ ŸÑÿßŸÑ€å⁄Øÿß ÿ¥ÿØÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿßŸàŸÑ€åŸÜ ÿ®ÿßÿ¥⁄ØÿßŸá ÿ´ÿ±Ÿàÿ™ŸÖŸÜÿØ ÿØŸÜ€åÿß',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄ÜŸá ⁄©ÿ≥€å ŸÑŸÇÿ® ÿ®ÿßÿ±ÿ≥ÿß ÿ±ÿß ŸÅÿ±ÿßÿ™ÿ± ÿßÿ≤ €å⁄© ÿ®ÿßÿ¥⁄ØÿßŸá ŸÇÿ±ÿßÿ± ÿØÿßÿØÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÅÿ±ŸáÿßÿØ ŸÖÿ¨€åÿØ€å ÿØÿ± ŸÑ€å⁄Ø ÿßŸÖÿßÿ±ÿßÿ™ ÿ®ÿ±ÿß€å ⁄ÜŸá ÿ®ÿßÿ¥⁄ØÿßŸá Ÿáÿß€å ÿ®ÿßÿ≤€å ⁄©ÿ±ÿØŸáÿü',\n",
              "  'reference': 'ÿßŸÑŸàÿµŸÑÿå ÿßŸÑÿπ€åŸÜÿå ÿßŸÑÿßŸáŸÑ€å Ÿà ÿßŸÑŸÜÿµÿ±',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÖÿ¨€åÿØ€å ŸàŸÇÿ™€å ÿßÿ≤ ŸÅŸàÿ™ÿ®ÿßŸÑ ÿÆÿØÿßÿ≠ÿßŸÅÿ∏€å  ⁄©ÿ±ÿØ ÿØÿ± ⁄ÜŸá ÿ™€åŸÖ€å ÿ®ŸàÿØÿü',\n",
              "  'reference': 'ÿ®ÿßÿ¥⁄ØÿßŸá ÿßÿ≥ÿ™ŸÇŸÑÿßŸÑ ÿ™Ÿáÿ±ÿßŸÜ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÅÿ±ŸáÿßÿØ ŸÖÿ¨€åÿØ€å ⁄ÜŸÜÿØ ⁄ØŸÑ ŸÖŸÑ€å ÿØÿ± ⁄©ÿßÿ±ŸÜÿßŸÖŸá ÿØÿßÿ±ÿØÿü',\n",
              "  'reference': '€±€∞ ⁄ØŸÑ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÅÿ±ŸáÿßÿØ ŸÖÿ¨€åÿØ€å ÿØÿ± ⁄©ÿ¨ÿß ÿ®Ÿá ÿØŸÜ€åÿß ÿ¢ŸÖÿØŸá ÿßÿ≥ÿ™ÿü',\n",
              "  'reference': 'ÿ™Ÿáÿ±ÿßŸÜ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿØÿ± ÿÆÿßŸÜŸàÿßÿØŸá ŸÖÿ¨€åÿØ€å ÿ®Ÿá ÿ¨ÿ≤ ŸÅÿ±ŸáÿßÿØ ⁄ÜŸá ⁄©ÿ≥€å ŸÅŸàÿ™ÿ®ÿßŸÑ€åÿ≥ÿ™ ÿ®ŸàÿØŸáÿü',\n",
              "  'reference': 'ÿ®ÿ±ÿßÿØÿ±ÿ¥ ŸÅÿ±ÿ≤ÿßÿØ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿßÿ≥ŸÖ ÿ®⁄ÜŸá Ÿáÿß€å ŸÅÿ±ŸáÿßÿØ ŸÖÿ¨€åÿØ€å ⁄Ü€åŸáÿü',\n",
              "  'reference': 'ÿ™€åÿßŸÖ Ÿà ÿßŸÖ€åÿ± ÿ®ÿ±ÿØ€åÿß',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÅÿ±ŸáÿßÿØ ŸÖÿ¨€åÿØ€å ÿ®ÿπÿØ ÿßÿ≤ ÿ®ÿßÿ≤€å ÿ®ÿ±ÿß€å ÿ¨ŸàÿßŸÜÿßŸÜ ⁄©ÿ¥ÿßŸàÿ±ÿ≤ ÿ®Ÿá ⁄ÜŸá ÿ™€åŸÖ€å ÿ±ŸÅÿ™ÿü',\n",
              "  'reference': 'ÿ¨ŸàÿßŸÜÿßŸÜ ÿ®ŸáŸÖŸÜ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿßÿ≥ŸÖ ŸÖÿßÿØÿ± ŸÅÿ±ŸáÿßÿØ ŸÖÿ¨€åÿØ€å ⁄Ü€åÿ≥ÿ™ÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÅÿ±ÿ≤ÿßÿØ ŸÖÿ¨€åÿØ€å ÿØÿ± ⁄ÜŸá ÿ™€åŸÖ Ÿáÿß€å ÿ®ÿßÿ≤€å ⁄©ÿ±ÿØŸáÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÅÿ±ŸáÿßÿØ ŸÖÿ¨€åÿØ€å ⁄ÜŸÜÿØ ÿ≥ÿßŸÑÿ¥ ÿßÿ≥ÿ™ÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄ØÿßŸÜÿØ€å ⁄ÜŸá ⁄©ÿ≥€å ÿ®ŸàÿØÿü',\n",
              "  'reference': 'ÿ±Ÿáÿ®ÿ± ÿ≥€åÿßÿ≥€å Ÿà ŸÖÿπŸÜŸà€å ŸáŸÜÿØ€å\\u200cŸáÿß',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ≥ÿßÿ™€åÿß⁄Øÿ±ÿßŸáÿß ÿßÿ¥ÿßÿ±Ÿá ÿ®Ÿá ⁄ÜŸá ⁄Ü€åÿ≤€å ÿØÿßÿ±ÿØÿü',\n",
              "  'reference': 'ŸÅŸÑÿ≥ŸÅŸáŸî ÿ®€å\\u200cÿÆÿ¥ŸàŸÜÿ™€å ⁄ØÿßŸÜÿØ€å',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ≤ŸÖÿßŸÜ€å ⁄©Ÿá ⁄ØÿßŸÜÿØ€å ÿ±Ÿáÿ®ÿ± ŸÖÿ®ÿßÿ±ÿ≤Ÿá ÿ®ÿ±ÿß€å ÿ¢ÿ≤ÿßÿØ€å ŸáŸÜÿØ ÿ¥ÿØ ŸÖÿ±ÿØŸÖ ÿ®Ÿá ÿßŸà ⁄ÜŸá ŸÖ€å ⁄ØŸÅÿ™ŸÜÿØÿü',\n",
              "  'reference': 'ŸÖŸáÿßÿ™ŸÖÿß €åÿß ÿ±Ÿàÿ≠ ÿ®ÿ≤ÿ±⁄Ø',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿßÿ≤ ⁄ÜŸá ÿ≥ÿßŸÑ€å ⁄ØÿßŸÜÿØ€å ÿ®ÿß ŸÑŸÇÿ® ŸÖŸáÿßÿ™ŸÖÿß ÿ¥ŸÜÿßÿÆÿ™Ÿá ÿ¥ÿØÿü',\n",
              "  'reference': 'ÿØÿ± ÿ≥ÿßŸÑ €±€π€±€∏',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÅŸÑÿ≥ŸÅŸáŸî ÿ®€å ÿÆÿ¥ŸàŸÜÿ™€å ⁄ØÿßŸÜÿØ€å ÿ±Ÿà€å ⁄ÜŸá ÿßŸÅÿ±ÿßÿØ ÿ¢ÿ≤ÿßÿØ€å ÿÆŸàÿßŸá€å ÿßÿ´ÿ± ⁄Øÿ∞ÿßÿ¥ÿ™Ÿá ÿ®ŸàÿØÿü',\n",
              "  'reference': 'ÿØ⁄©ÿ™ÿ± ŸÖÿßÿ±ÿ™€åŸÜ ŸÑŸàÿ™ÿ±⁄©€åŸÜ⁄Øÿå ÿ™ŸÜÿ≤€åŸÜ ⁄Ø€åÿßÿ™ÿ≥Ÿàÿå ŸÑÿÆ ŸàÿßŸÑÿ≥ÿßÿå ÿßÿ≥ÿ™ŸÅÿßŸÜ ÿ®€å⁄©Ÿàÿå ÿ¢ŸÜ⁄Ø ÿ≥ÿßŸÜ ÿ≥Ÿà ⁄Ü€å Ÿà ŸÜŸÑÿ≥ŸàŸÜ ŸÖÿßŸÜÿØŸÑÿß',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄ØÿßŸÜÿØ€å ⁄Ü⁄ØŸàŸÜŸá ÿ™ŸàÿßŸÜÿ≥ÿ™ ÿßŸÖŸæÿ±ÿßÿ™Ÿàÿ±€å ÿ®ÿ±€åÿ™ÿßŸÜ€åÿß ÿ±ÿß ÿßÿ≤ ŸáŸÜÿØ ÿ®€åÿ±ŸàŸÜ ⁄©ŸÜÿØÿü',\n",
              "  'reference': 'ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿ¥€åŸàŸáŸî ÿ∂ÿØ ÿÆÿ¥ŸàŸÜÿ™ ŸÜÿßŸÅÿ±ŸÖÿßŸÜ€å ŸÖÿØŸÜ€å',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÖŸáÿßŸÜÿØÿßÿ≥ ⁄©ÿßÿ±ÿßŸÖ⁄ÜÿßŸÜÿØ ⁄ØÿßŸÜÿØ€å ÿßŸÖÿ±Ÿàÿ≤ ÿ®ÿß ⁄ÜŸá ÿßÿ≥ŸÖ€å ÿ¥ŸÜÿßÿÆÿ™Ÿá ÿ¥ÿØŸá ÿßÿ≥ÿ™ÿü',\n",
              "  'reference': 'ŸÖŸáÿßÿ™ŸÖÿß ⁄ØÿßŸÜÿØ€å',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÜŸÑÿ≥ŸàŸÜ ŸÖÿßŸÜÿØŸÑÿß ⁄ÜŸá ÿ™ÿßÿ´€åÿ±€å ÿ±Ÿà€å ⁄ØÿßŸÜÿØ€å ⁄Øÿ∞ÿßÿ¥ÿ™ÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ¨ŸÜÿ®ÿ¥\\u200cŸáÿß€å ŸÖŸÇÿßŸàŸÖÿ™ ÿ®ÿØŸàŸÜ ÿÆÿ¥ŸàŸÜÿ™ ÿØÿ± ÿ¨ŸáÿßŸÜ ÿßÿ≤ ⁄ÜŸá ÿ≥ÿßŸÑ€å ÿ¥ÿ±Ÿàÿπ ÿ¥ÿØŸÜÿØÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄ÜŸá ⁄©ÿ≥€å ÿ™ŸàÿßŸÜÿ≥ÿ™ ÿßÿ≥ÿ™ŸÇŸÑÿßŸÑ ÿ®ÿ±€åÿ™ÿßŸÜ€åÿß ÿ±ÿß ÿßÿ≤ ŸáŸÜÿØ ÿ®⁄Ø€åÿ±ÿØÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÅÿ±ÿßŸàÿßŸÜ ÿ™ÿ±€åŸÜ ÿØŸàÿ≤€åÿ≥ÿ™ ÿØÿ± ÿØŸÜ€åÿß ⁄Ü€åŸáÿü',\n",
              "  'reference': 'ŸÇŸàÿ±ÿ®ÿßÿ∫Ÿá\\u200cŸáÿß Ÿà Ÿàÿ≤ÿ∫\\u200cŸáÿß',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ≤ÿ®ÿßŸÜ ÿØÿ±ÿßÿ≤ ŸÇŸàÿ±ÿ®ÿßÿ∫Ÿá ⁄ÜŸá ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿß€å ÿØÿßÿ±ÿØÿü',\n",
              "  'reference': '⁄Øÿ±ŸÅÿ™ŸÜ ÿ∑ÿπŸÖŸá',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÅÿ±ŸÇ ŸÇŸàÿ±ÿ®ÿßÿ∫Ÿá Ÿà Ÿàÿ≤ÿ∫\\u200c ⁄Ü€åÿ≥ÿ™ÿü',\n",
              "  'reference': 'ŸÇŸàÿ±ÿ®ÿßÿ∫Ÿá\\u200cŸáÿß ÿ®ÿØŸÜ ŸÜÿ±ŸÖ Ÿà ŸÖÿ±ÿ∑Ÿàÿ® ÿØÿßÿ±ŸÜÿØ Ÿà ÿØÿ± ŸÜÿ≤ÿØ€å⁄©€å ÿ¢ÿ®\\u200cŸáÿß ÿ≤ŸÜÿØ⁄Ø€å ŸÖ€å\\u200c⁄©ŸÜŸÜÿØ. Ÿàÿ≤ÿ∫Ÿáÿß ÿßŸÖÿß ŸæŸàÿ≥ÿ™ ÿÆÿ¥⁄© Ÿà ÿ≤⁄Ø€åŸÑ ŸÖÿßŸÜŸÜÿØ ÿØÿßÿ±ŸÜÿØ Ÿà ÿπŸÖÿØÿ™ÿßŸã ÿ±Ÿà€å ÿÆÿ¥⁄©€å ÿ≤ŸÜÿØ⁄Ø€å ŸÖ€å\\u200c⁄©ŸÜŸÜÿØ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÖÿ≠ŸÑ ÿ≤ŸÜÿØ⁄Ø€å ŸÇŸàÿ±ÿ®ÿßÿ∫Ÿá ⁄©ÿ¨ÿßÿ≥ÿ™ÿü',\n",
              "  'reference': 'ÿØÿ± ŸÜÿ≤ÿØ€å⁄©€å ÿ¢ÿ®\\u200cŸáÿß',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸæŸàÿ≥ÿ™ Ÿàÿ≤ÿ∫ Ÿáÿß ÿ®Ÿá ⁄ÜŸá ÿµŸàÿ±ÿ™ ÿßÿ≥ÿ™ÿü',\n",
              "  'reference': 'ÿÆÿ¥⁄© Ÿà ÿ≤⁄Ø€åŸÑ ŸÖÿßŸÜŸÜÿØ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿØÿ± ⁄©ÿ¨ÿßŸáÿß€å ÿØŸÜ€åÿß ŸÇŸàÿ±ÿ®ÿßÿ∫Ÿá\\u200c ŸÜÿØÿßÿ±€åŸÖÿü',\n",
              "  'reference': 'ŸÇÿ∑ÿ® ÿ¨ŸÜŸàÿ® Ÿà Ÿà ÿØÿ± ÿ®ÿ≥€åÿßÿ±€å ÿßÿ≤ ÿ¨ÿ≤ÿß€åÿ± ÿßŸÇ€åÿßŸÜŸàÿ≥€å',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄Üÿ±ÿß ŸÇŸàÿ±ÿ®ÿßÿ∫Ÿá Ÿáÿß ÿØÿ± ŸÖŸÜÿßÿ∑ŸÇ ⁄Øÿ±ŸÖÿ≥€åÿ±€å ÿ™ŸÜŸàÿπ ÿ®€åÿ¥ÿ™ÿ±€å ÿØÿßÿ±ŸÜÿØÿü',\n",
              "  'reference': 'ÿ®ÿß ÿ™Ÿàÿ¨Ÿá ÿ®Ÿá ÿ≥ÿßÿÆÿ™ÿßÿ± Ÿà ŸÜ€åÿßÿ≤ ŸæŸàÿ≥ÿ™ ŸÇŸàÿ±ÿ®ÿßÿ∫Ÿá\\u200cŸáÿß',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿßÿ≤ ÿ∂ÿØ€åÿÆ ŸÇŸàÿ±ÿ®ÿßÿ∫Ÿá Ÿáÿß ⁄ÜŸá ÿßÿ≥ÿ™ŸÅÿßÿØŸá Ÿáÿß€å ÿµŸÜÿπÿ™€å ŸÖ€å ÿ™ŸàÿßŸÜ ⁄©ÿ±ÿØÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÖÿ≠ŸÑ ÿ≤ŸÜÿØ⁄Ø€å ŸÇŸàÿ±ÿ®ÿßÿ∫Ÿá ⁄ÜŸá ÿ¨ÿßŸáÿß€å ŸÜŸÖ€å ÿ™ŸàÿßŸÜÿØ ÿ®ÿßÿ¥ÿØÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÅÿ±ÿßŸàÿßŸÜ ÿ™ÿ±€åŸÜ ÿ™⁄© ÿ≤€åÿ≥ÿ™ ÿØÿ± ÿ¨ŸáÿßŸÜ ⁄Ü€åÿ≥ÿ™ÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿßŸÜÿ¨€åŸÑ Ÿáÿß€å ÿßÿµŸÑ€å ⁄ÜŸá ŸÜÿßŸÖ ÿØÿßÿ±ŸÜÿØÿü',\n",
              "  'reference': 'ÿßŸÜÿ¨€åŸÑ ŸÖÿ™€åÿå ŸÖÿ±ŸÇÿ≥ÿå ŸÑŸàŸÇÿß Ÿà €åŸàÿ≠ŸÜÿß',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄©ÿ™ÿßÿ® ÿßŸÜÿ¨€åŸÑ ⁄Ü€åÿ≥ÿ™ÿü',\n",
              "  'reference': 'ÿ¥ÿ±ÿ≠€å ÿßÿ≤ ÿ≤ŸÜÿØ⁄Ø€å Ÿà ÿ¢ŸÖŸàÿ≤Ÿá\\u200cŸáÿß€å ÿπ€åÿ≥€å',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿßŸÜÿ¨€åŸÑ\\u200cŸáÿß€å ÿπŸáÿØ ÿ¨ÿØ€åÿØ ÿØÿ± ⁄ÜŸá ÿ≥ÿßŸÑ€å ÿß€åÿ¨ÿßÿØ ÿ¥ÿØŸá ÿßŸÜÿØÿü',\n",
              "  'reference': 'ÿßÿ≠ÿ™ŸÖÿßŸÑÿßŸã ÿ®€åŸÜ ÿ≥ÿßŸÑ\\u200cŸáÿß€å €∂€∂ ÿ™ÿß €±€±€∞ ŸÖ€åŸÑÿßÿØ€å',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÜŸà€åÿ≥ŸÜÿØŸá Ÿáÿß€å ⁄ÜŸáÿßÿ± ÿßŸÜÿ¨€åŸÑ ÿßÿµŸÑ€å ⁄ÜŸá ⁄©ÿ≥ÿßŸÜ€å Ÿáÿ≥ÿ™ŸÜÿØÿü',\n",
              "  'reference': 'ŸÖÿ¥ÿÆÿµ ŸÜ€åÿ≥ÿ™',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿßÿ≥ŸÖ ÿπŸáÿØ ÿ¨ÿØ€åÿØ ÿØÿ± ⁄©ÿ™ÿßÿ® ÿßŸÜÿ¨€åŸÑ ŸÜÿ¥ÿßŸÜ ÿØŸáŸÜÿØŸá ⁄Ü€åÿ≥ÿ™ÿü',\n",
              "  'reference': 'ÿ®Ÿá Ÿæ€åŸÖÿßŸÜ€å ÿßÿ¥ÿßÿ±Ÿá ÿØÿßÿ±ÿØ ⁄©Ÿá ÿ¢ÿ∫ÿßÿ≤⁄Øÿ± ÿØŸàÿ±ŸáŸî ÿ¨ÿØ€åÿØ€å ÿßÿ≤ ÿßÿ±ÿ™ÿ®ÿßÿ∑ ÿÆÿØÿßŸàŸÜÿØ ÿ®ÿß ÿßŸÜÿ≥ÿßŸÜ ÿßÿ≥ÿ™',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿØÿ± ÿßŸÜÿ¨€åŸÑ ÿπŸáÿØ ÿ¨ÿØ€åÿØ ÿ¥ÿ±ÿ∑ ÿ±ÿ≥ÿ™⁄Øÿßÿ±€å ÿßŸÜÿ≥ÿßŸÜ ⁄Ü€åÿ≥ÿ™ÿü',\n",
              "  'reference': 'ÿß€åŸÖÿßŸÜ ÿ®Ÿá ŸÖÿ≥€åÿ≠',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿπŸáÿØ ÿ¨ÿØ€åÿØ ÿ®Ÿá ÿ¨ÿ≤ ⁄ÜŸáÿßÿ± ⁄©ÿ™ÿßÿ® ÿßÿµŸÑ€å ÿ¥ÿßŸÖŸÑ ⁄ÜŸá ⁄Ü€åÿ≤Ÿáÿß€å ÿØ€å⁄Øÿ±€å ŸÖ€å ÿ¥ŸàÿØ',\n",
              "  'reference': '⁄©ÿ™ÿßÿ® ÿßÿπŸÖÿßŸÑ ÿ±ÿ≥ŸàŸÑÿßŸÜÿå ŸÜÿßŸÖŸá\\u200cŸáÿß€å ÿ±ÿ≥ŸàŸÑÿßŸÜ ŸÖÿ≥€åÿ≠ Ÿà ⁄©ÿ™ÿßÿ® ŸÖ⁄©ÿßÿ¥ŸÅŸá',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄Üÿ±ÿß ŸÜÿßŸÖ ŸÜŸà€åÿ≥ŸÜÿØŸá Ÿáÿß€å ⁄ÜŸáÿßÿ± ⁄©ÿ™ÿßÿ® ÿßÿµŸÑ€å ÿπŸáÿØ ÿ¨ÿØ€åÿØ ŸÖÿ¥ÿÆÿµ ŸÜ€åÿ≥ÿ™ÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÜÿßŸÖ ÿØŸà ⁄©ÿ™ÿßÿ® ÿßÿµŸÑ€å ÿπŸáÿØ ŸÇÿØ€åŸÖ ÿ±ÿß ÿ®ŸÜŸà€åÿ≥€åÿØ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ¢ŸÖŸàÿ≤Ÿá\\u200cŸáÿß€å ÿπ€åÿ≥€å ÿ®Ÿá ⁄ÜŸá ÿµŸàÿ±ÿ™ ÿØÿ± ⁄©ÿ™ÿßÿ® Ÿáÿß€å ÿπŸáÿØ ÿ¨ÿØ€åÿØ ÿ¢Ÿàÿ±ÿØŸá ÿ¥ÿØŸáÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿßÿÆÿ™ŸÑÿßŸÅ ÿ¥ŸÖÿßŸÑ ŸÖÿ∫ŸÜÿßÿ∑€åÿ≥€å Ÿà ÿ¥ŸÖÿßŸÑ ÿ≠ŸÇ€åŸÇ€å ÿ±Ÿà ⁄Ü€å ŸÖ€å ⁄ØŸÜÿü',\n",
              "  'reference': 'ŸÖ€åŸÑ ŸÖÿ∫ŸÜÿßÿ∑€åÿ≥€å',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿß⁄©ÿ≥€åÿØ ŸÖÿ∫ŸÜÿßÿ∑€åÿ≥€å ÿ¢ŸáŸÜ ⁄Ü€åŸáÿü',\n",
              "  'reference': 'ŸÜŸàÿπ€å ⁄©ÿßŸÜ€å ÿ¢ŸáŸÜ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÇÿ∑ÿ® ŸÜŸÖÿß ÿ®ÿ±ÿß€å ⁄Ü€å ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å ÿ¥Ÿáÿü',\n",
              "  'reference': 'ŸÇŸèÿ∑ÿ®\\u200cŸÜŸÖÿß Ÿàÿ≥€åŸÑŸá\\u200cÿß€å ÿ®ÿ±ÿß€å ÿ™ÿπ€å€åŸÜ ÿ¨Ÿáÿ™ (ÿ¨Ÿáÿ™\\u200c€åÿßÿ®€å)',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÇÿ∑ÿ® ŸÜŸÖÿß ⁄ÜŸá ⁄©ÿßÿ±ÿ®ÿ±ÿØŸáÿß€å€å ÿØÿßÿ±Ÿáÿü',\n",
              "  'reference': 'ÿ®ÿ±ÿß€å ÿ™ÿπ€å€åŸÜ ÿ¨Ÿáÿ™ (ÿ¨Ÿáÿ™\\u200c€åÿßÿ®€å)',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿß⁄©ÿ≥€åÿØ ŸÖÿ∫ŸÜÿßÿ∑€åÿ≥€å ÿ¢ŸáŸÜ ⁄ÜŸá ŸÜŸàÿπ ŸÖÿßÿØŸá ÿß€å ÿßÿ≥ÿ™ÿü',\n",
              "  'reference': 'ÿ∑ÿ®€åÿπ€å',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÇÿ∑ÿ® ŸÜŸÖÿß Ÿáÿß€å ÿ¨ÿØ€åÿØ ÿßÿ≥ŸÖÿ¥ŸàŸÜ ⁄Ü€åŸáÿü',\n",
              "  'reference': '⁄ò€åÿ±Ÿàÿ≥⁄©ŸàŸæ€å',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÇÿ∑ÿ® ŸÜŸÖÿß ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ⁄ÜŸá ⁄Ü€åÿ≤€å ÿ¨Ÿáÿ™ ÿ±Ÿà ŸÜÿ¥ŸàŸÜ ŸÖ€å ÿØŸáÿü',\n",
              "  'reference': 'ŸÜ€åÿ±Ÿà€å ÿ¢ŸáŸÜÿ±ÿ®ÿß€å€å ÿ≤ŸÖ€åŸÜ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÇÿ∑ÿ® ŸÜŸÖÿß ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ⁄ÜŸá ⁄Ü€åÿ≤€å ÿ¨Ÿáÿ™ ÿ±Ÿà ŸÜÿ¥ŸàŸÜ ŸÜŸÖ€å ÿØŸáÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄Üÿ¨Ÿàÿ±€å ŸÖ€å ÿ¥Ÿá ŸÇÿ∑ÿ® ŸÜŸÖÿß ÿ≥ÿßÿÆÿ™ÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿØŸÇ€åŸÇ ÿ™ÿ±€åŸÜ ŸÇÿ∑ÿ® ŸÜŸÖÿß ŸÖŸàÿ¨ŸàÿØ ⁄Ü€å ŸÜÿßŸÖ ÿØÿßÿ±ÿØÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ¨ÿπÿ®Ÿá ÿ≥€åÿßŸá ÿ®ÿ±ÿß€å ⁄Ü€å ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å ÿ¥Ÿáÿü',\n",
              "  'reference': 'ÿ∞ÿÆ€åÿ±Ÿá Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß€å ÿÆÿßÿµ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ¨ÿπÿ®Ÿá ÿ≥€åÿßŸá ⁄ÜŸá ÿ±ŸÜ⁄Ø€åŸáÿü',\n",
              "  'reference': 'ŸÜÿßÿ±ŸÜÿ¨€å ŸÅÿ≥ŸÅÿ±€å',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ¨ÿπÿ®Ÿá ÿ≥€åÿßŸá ÿ¥ÿßŸÖŸÑ ⁄Ü€åŸáÿü',\n",
              "  'reference': 'ÿØÿ≥ÿ™⁄ØÿßŸá ÿ´ÿ®ÿ™ ÿßÿ∑ŸÑÿßÿπÿßÿ™ ŸÅŸÜ€å Ÿæÿ±Ÿàÿßÿ≤ Ÿà ÿØÿ≥ÿ™⁄ØÿßŸá ÿ´ÿ®ÿ™ ÿµÿØÿßŸáÿß€å ⁄©ÿßÿ®€åŸÜ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ¨ÿπÿ®Ÿá ÿ≥€åÿßŸá ÿ®Ÿá ÿ∫€åÿ± ÿßÿ≤ ŸáŸàÿßŸæ€åŸÖÿß ÿ™Ÿà ⁄Ü€å Ÿáÿ≥ÿ™ÿü',\n",
              "  'reference': '⁄©ÿ¥ÿ™€åÿå ÿ®ÿßŸÑ⁄Øÿ±ÿØ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ±ŸÜ⁄Ø ÿ¨ÿπÿ®Ÿá ÿ≥€åÿßŸá ⁄©ÿ¨ÿß ŸÖŸàÿ´ÿ±Ÿáÿü',\n",
              "  'reference': 'ÿØÿ± Ÿæ€åÿØÿß ⁄©ÿ±ÿØŸÜ ÿ¨ÿπÿ®Ÿá ÿ≥€åÿßŸá',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄©€å ÿßŸàŸÑ€åŸÜ ÿ®ÿßÿ± ÿßÿ≤ ÿ¨ÿπÿ®Ÿá ÿ≥€åÿßŸá ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ÿ±ÿØÿü',\n",
              "  'reference': 'ÿ®ÿ±ÿßÿØÿ±ÿßŸÜ ÿ±ÿß€åÿ™',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ®ÿ±ÿßÿØÿ±ÿßŸÜ ÿ±ÿß€åÿ™ ÿ®ÿ±ÿß€å ⁄Ü€å ÿßÿ≤ ÿ¨ÿπÿ®Ÿá ÿ≥€åÿßŸá ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ÿ±ÿØŸÜÿü',\n",
              "  'reference': 'ÿ®ÿ±ÿß€å ÿ∂ÿ®ÿ∑ ⁄Ü⁄ØŸàŸÜ⁄Ø€å ⁄Üÿ±ÿÆÿ¥ Ÿæÿ±Ÿá\\u200cŸáÿß€å ŸÖŸÑÿÆ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ¨ÿπÿ®Ÿá ÿ≥€åÿßŸá ÿ±Ÿà ⁄©€å ÿ≥ÿßÿÆÿ™ÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ®ÿ≤ÿ±⁄Øÿ™ÿ±€åŸÜ ÿ≥ÿßÿ≤ŸÜÿØŸá ÿ¨ÿπÿ®Ÿá ÿ≥€åÿßŸá ⁄©€åŸáÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ¨ÿπÿ®Ÿá ÿ≥€åÿßŸá ⁄ÜŸÇÿØÿ± ŸÖŸÇÿßŸàŸÖÿ™ ÿØÿßÿ±Ÿáÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿØÿ± ⁄Øÿ∞ÿ¥ÿ™Ÿá ÿßŸÜÿ≥ÿßŸÜ ÿ®ÿ±ÿß€å ÿ∞Ÿàÿ® ÿ¢ŸáŸÜ ÿßÿ≤ ⁄Ü€å ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å ⁄©ÿ±ÿØÿü',\n",
              "  'reference': 'ÿ≤ÿ∫ÿßŸÑ ⁄ÜŸàÿ® Ÿà ŸÖÿ¥ÿ™ŸÇÿßÿ™ ⁄ÜŸàÿ®',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ≥ŸàÿÆÿ™ ⁄Üÿ¨Ÿàÿ±€å ÿßŸÜÿ±⁄ò€å ŸÇÿßÿ®ŸÑ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿ™ŸàŸÑ€åÿØ ŸÖ€å ⁄©ŸÜŸáÿü',\n",
              "  'reference': 'ÿØÿ± ÿßÿ´ÿ± ÿ™ÿ∫€å€åÿ±ÿßÿ™ (ŸÖÿπŸÖŸàŸÑÿßŸã ÿ¥€åŸÖ€åÿßÿ¶€å)',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ®€åÿ¥ÿ™ÿ±€åŸÜ ŸÖŸÜÿ®ÿπ ÿ≥ŸàÿÆÿ™€å ⁄©Ÿá ÿßŸÜÿ≥ÿßŸÜ ŸÖÿµÿ±ŸÅ ŸÖ€å ⁄©ŸÜŸá ⁄Ü€åŸáÿü',\n",
              "  'reference': 'Ÿá€åÿØÿ±Ÿà⁄©ÿ±ÿ®ŸÜ\\u200cŸáÿß',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ®€åÿ¥ÿ™ÿ± ÿ≥ŸàÿÆÿ™€å ŸÖŸàÿ±ÿØ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßŸÜÿ≥ÿßŸÜ ÿßÿ≤ ⁄Ü€å ÿ®ÿØÿ≥ÿ™ ŸÖ€åÿßÿØÿü',\n",
              "  'reference': '⁄Ø€åÿßŸáÿßŸÜ Ÿà €åÿß ⁄Üÿ±ÿ®€å ÿ≠€åŸàÿßŸÜÿßÿ™',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿßŸÜÿ±⁄ò€å ⁄©Ÿá ÿßÿ≤ ŸÖŸàÿßÿØ ÿ≥ŸàÿÆÿ™ŸÜ€å ÿ®ÿØÿ≥ÿ™ ŸÖ€åÿßÿØ ÿ®Ÿá ⁄ÜŸá ÿßŸÜÿ±⁄ò€å ŸÖ€å ÿ™ŸàŸÜŸá ÿ™ÿ®ÿØ€åŸÑ ÿ¥Ÿáÿü',\n",
              "  'reference': 'ÿßŸÜÿ±⁄ò€å ŸÖ⁄©ÿßŸÜ€å⁄©€å',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿßŸàŸÑ€åŸÜ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿ®ÿ¥ÿ± ÿßÿ≤ ÿ≥ŸàÿÆÿ™ ⁄Ü€å ÿ®ŸàÿØÿü',\n",
              "  'reference': 'ÿßÿ≠ÿ™ÿ±ÿßŸÇ Ÿà ÿ≥Ÿàÿ≤ÿßŸÜÿØŸÜ ÿ™⁄©Ÿá Ÿáÿß€å ⁄ÜŸàÿ®',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄ÜŸá ŸÅÿ±ÿß€åŸÜÿØ€å ÿ≥ŸàÿÆÿ™ ÿ±Ÿà ÿ®Ÿá ÿßŸÜÿ±⁄ò€å ÿ™ÿ®ÿØ€åŸÑ ŸÖ€å ⁄©ŸÜŸáÿü',\n",
              "  'reference': 'ÿß⁄©ŸÜÿ¥\\u200cŸáÿß€å ÿ¥€åŸÖ€åÿß€å€å ŸÖÿÆÿ™ŸÑŸÅ Ÿà ⁄Øÿ±ŸÖÿßÿ≤ÿß',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ®€åÿ¥ÿ™ÿ±€åŸÜ ŸÖŸÜÿ®ÿπ ÿ≥ŸàÿÆÿ™ ⁄©ÿ¨ÿßÿ≥ÿ™ÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿßÿ≤ ⁄ÜŸá ÿ≥ŸàÿÆÿ™€å ÿ®ÿ±ÿß€å ÿ≠ÿ±⁄©ÿ™ ÿÆŸàÿØÿ±Ÿà ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å ÿ¥Ÿáÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄©ÿØŸàŸÖ ŸÖÿßÿØŸá ÿ≥ŸàÿÆÿ™ŸÜ€å ÿ®€åÿ¥ÿ™ÿ±€åŸÜ ÿßŸÜÿ±⁄ò€å ÿ±Ÿà ÿ™ŸàŸÑ€åÿØ ŸÖ€å ⁄©ŸÜŸáÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿØÿ± ⁄©ÿ¨ÿß€å ⁄©ÿ™ÿßÿ® ÿ≥ŸÅÿ± Ÿæ€åÿØÿß€åÿ¥ ÿ®Ÿá ŸÑŸàÿ∑ ÿ™Ÿàÿ¨Ÿá ÿ¥ÿØŸáÿü',\n",
              "  'reference': 'ÿ®ÿßÿ® €±€±‚Äì€±€¥ ÿ™ÿß €±€π',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿßÿ≥ŸÖ ŸæÿØÿ± ŸÑŸàÿ∑ ⁄ÜŸá ÿ®ŸàÿØÿü',\n",
              "  'reference': 'Ÿáÿßÿ±ÿßŸÜ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÑŸàÿ∑ ⁄ÜŸá ŸÜÿ≥ÿ®ÿ™€å ÿ®ÿß ÿßÿ®ÿ±ÿßŸá€åŸÖ ÿØÿßÿ±ÿØÿü',\n",
              "  'reference': 'ÿ®ÿ±ÿßÿØÿ±ÿ≤ÿßÿØŸáŸî ÿßÿ®ÿ±ÿßŸá€åŸÖ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÿ®ÿπÿØ ÿßÿ≤ ŸÖÿ±⁄Ø ŸæÿØÿ± ŸÑŸàÿ∑ ⁄ÜŸá ÿ®ŸÑÿß€å€å ÿ≥ÿ±ÿ¥ ÿ¢ŸÖÿØÿü',\n",
              "  'reference': 'ŸæÿØÿ±ÿ®ÿ≤ÿ±⁄Ø ŸÑŸàÿ∑ÿå ÿ™ÿßÿ±ÿ≠ÿå ÿßŸà ÿ±ÿß ÿ®Ÿá ÿ≥ÿ±Ÿæÿ±ÿ≥ÿ™€å ⁄Øÿ±ŸÅÿ™',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄Üÿ±ÿß ŸÑŸàÿ∑ Ÿà ÿßÿ®ÿ±ÿßŸá€åŸÖ ÿßÿ≤ ŸáŸÖ ÿ¨ÿØÿß ÿ¥ÿØŸÜÿØÿü',\n",
              "  'reference': '⁄©ŸÖÿ®ŸàÿØ ⁄Üÿ±ÿß⁄ØÿßŸá ŸÖ€åÿßŸÜÿ¥ÿßŸÜ ÿßÿÆÿ™ŸÑÿßŸÅ€å ŸæÿØ€åÿØ ÿ¢ŸÖÿØ Ÿà ÿ®ÿ±ÿß€å ÿ¨ŸÑŸà⁄Ø€åÿ±€å ÿßÿ≤ ÿØÿ±⁄Ø€åÿ±€å ÿ®€åŸÜ ÿÆŸà€åÿ¥ÿßŸÜÿØÿßŸÜ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÑŸàÿ∑ ÿ®ÿπÿØ ÿßÿ≤ ÿ¨ÿØÿß ÿ¥ÿØŸÜ ÿßÿ≤ ÿßÿ®ÿ±ÿßŸá€åŸÖ ⁄©ÿ¨ÿß ÿ±ŸÅÿ™ÿü',\n",
              "  'reference': 'ÿ®Ÿá ÿ≥ŸÖÿ™ ÿ≥ÿØŸàŸÖ ÿØÿ± ÿØÿ±Ÿá ÿßÿ±ÿØŸÜ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄Üÿ±ÿß ÿ≥ÿß⁄©ŸÜÿßŸÜ ÿ≥ÿØŸàŸÖ ÿÆÿßŸÜŸá ŸÑŸàÿ∑ ÿ±ÿß ŸÖÿ≠ÿßÿµÿ±Ÿá ⁄©ÿ±ÿØŸá ÿ®ŸàÿØŸÜÿØÿü',\n",
              "  'reference': 'ŸÇÿµÿØ ÿ™ÿ¨ÿßŸàÿ≤ ÿ®Ÿá ŸÖŸáŸÖÿßŸÜÿßŸÜ ŸÑŸàÿ∑ ÿ±ÿß ÿØÿßÿ¥ÿ™ŸÜÿØ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄Üÿ±ÿß ŸÑŸàÿ∑ Ÿæ€åÿ¥ Ÿæÿ≥ÿ±ÿ¥ ÿßÿ®ÿ±ÿßŸá€åŸÖ ŸÜŸÖÿßŸÜÿØÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ŸÑŸàÿ∑ ÿØÿ± ⁄ÜŸá ÿ≥ÿßŸÑ€å ÿ≤ŸÜÿØ⁄Ø€å ŸÖ€å ⁄©ÿ±ÿØŸáÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': '⁄©ÿ™ÿßÿ® ÿ≥ŸÅÿ± Ÿæ€åÿØÿß€åÿ¥ ÿ±ÿßÿ¨ÿ® ⁄Ü€åÿ≥ÿ™ÿü',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0}]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "dataset_test = load_dataset(\"SajjadAyoubi/persian_qa\", split = \"validation\")\n",
        "dataset_test = dataset_test.select(range(100))\n",
        "results = []\n",
        "for item in tqdm(dataset_test, desc=\"Evaluating\"):\n",
        "      question = item[\"question\"]\n",
        "      if \"answers\" in item and \"text\" in item[\"answers\"] and len(item[\"answers\"][\"text\"]) > 0:\n",
        "        reference = item[\"answers\"][\"text\"][0]  # Assuming a list of answers\n",
        "      else:\n",
        "          reference = \"\"\n",
        "      context = item.get(\"context\", None)\n",
        "      prompt = format_prompt(question, context)\n",
        "      prediction = generate_answer(model, tokenizer, prompt)\n",
        "      f1_score = evaluate_f1_token(prediction, reference)\n",
        "      em_score = evaluate_exact_match(prediction, reference)\n",
        "      bert_score = evaluate_bert_score(prediction, reference)\n",
        "      results.append({\n",
        "        \"question\": question,\n",
        "        \"reference\": reference,\n",
        "        \"prediction\": prediction,\n",
        "        \"f1_score\": f1_score,\n",
        "        \"exact_match\": em_score,\n",
        "        \"bert_score\": bert_score\n",
        "      })\n",
        "results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V9mk_5yhoJH",
        "outputId": "b8ba5d67-7748-441c-c8f6-c64d9e8b03e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 Score: 0.0000\n",
            "Average Exact Match: 0.3000\n",
            "Average BERT Score: 0.0000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "avg_f1 = np.mean([result[\"f1_score\"] for result in results])\n",
        "avg_em = np.mean([result[\"exact_match\"] for result in results])\n",
        "avg_bert = np.mean([result[\"bert_score\"] for result in results])\n",
        "print(f\"Average F1 Score: {avg_f1:.4f}\")\n",
        "print(f\"Average Exact Match: {avg_em:.4f}\")\n",
        "print(f\"Average BERT Score: {avg_bert:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKX_XKs_BNZR"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    from unsloth import FastLanguageModel\n",
        "\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name=\"lora_model\",  # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length=max_seq_length,\n",
        "        dtype=dtype,\n",
        "        load_in_4bit=load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n",
        "\n",
        "# alpaca_prompt = You MUST copy from above!\n",
        "\n",
        "inputs = tokenizer(\n",
        "    [\n",
        "        alpaca_prompt.format(\n",
        "            \"What is a famous tall tower in Paris?\",  # instruction\n",
        "            \"\",  # input\n",
        "            \"\",  # output - leave this blank for generation!\n",
        "        )\n",
        "    ],\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMjaNrjsU5_"
      },
      "source": [
        "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFfaXG0WsQuE"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    # I highly do NOT suggest - use Unsloth if possible\n",
        "    from peft import AutoPeftModelForCausalLM\n",
        "    from transformers import AutoTokenizer\n",
        "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ab5c5043d8244679d6e985c45aaf94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b36d079b4f64d24bfa6a97d60423edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c79cd4bf6da4fed8c461138bbeb7520": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10169a2c15f2428ab6803a2820cc8c65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1061e8b4991048f7a981a665d87f4fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11091850396a44bba5a04727fa57470a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd92faf02f5847648ce94f95915ffe12",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_affa13203281457b8373ff6003f6e2f6",
            "value": "‚Äá16.0M/?‚Äá[00:00&lt;00:00,‚Äá52.3MB/s]"
          }
        },
        "1285896f5b874909b8f2e2cb762ca033": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12bbd0219b1f4e078d2d2240d4eec486": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13778ee9448c45aab93b08eba085c1d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "158c186cdd9b48e2b07a013abd7b7a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10169a2c15f2428ab6803a2820cc8c65",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1f9efc99625d497689e2ca55b36089be",
            "value": "‚Äá1/1‚Äá[00:05&lt;00:00,‚Äá‚Äá5.48s/it]"
          }
        },
        "17fe36d10b024205a711741b4aaf8cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ae3e1179efe426bb5cc5f401be97c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_907deca0fe2b47c4a9cd24fc8ce7533e",
              "IPY_MODEL_1ca7bf5538d3485ca4d9c1ffb77d8756",
              "IPY_MODEL_3ac1325106b14741b81038fa79361bd5"
            ],
            "layout": "IPY_MODEL_ebac52b9cf0f47479d6eacc4b3d1214f"
          }
        },
        "1ca7bf5538d3485ca4d9c1ffb77d8756": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fab2f0843ba459da42e8c3daa37e3fa",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a38f77856ffa4c98be9cbd023cf40fd5",
            "value": 2
          }
        },
        "1ced9679ab9947e3b778626b574abc44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9efc99625d497689e2ca55b36089be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fab2f0843ba459da42e8c3daa37e3fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25bb2faf4fa146df9a71ae6c3c6b4604": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca55a3978e994541a0f2e890272ee54d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c91f3d90122c4ec19c79342fb62babf7",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "2733c3d8322f4f5d9db036a737e1c7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aa451cb830b42878747a15411e7ed59",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b9aad5dc41104e91b5642b21f3bf647e",
            "value": "‚Äá575/575‚Äá[00:00&lt;00:00,‚Äá61.8kB/s]"
          }
        },
        "2d00f2ba25f14c4f892b58eb7fcf587b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d9d62f0a7364ac0b40e1da1b78ac10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25bb2faf4fa146df9a71ae6c3c6b4604",
              "IPY_MODEL_436c48d27ff1454eba0c38c97b774869",
              "IPY_MODEL_5ffbb9bba9114150badd4c0c5162782b"
            ],
            "layout": "IPY_MODEL_d4c0e0a75fbd481ea6848f8e1ae02d34"
          }
        },
        "35889ba2cf394ff990a4dc4852608d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "361c01b66c824ed59c297727820ea5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1285896f5b874909b8f2e2cb762ca033",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_521c4538cb8b44338f39f8ac872c4d93",
            "value": "‚Äá464M/?‚Äá[00:05&lt;00:00,‚Äá96.5MB/s]"
          }
        },
        "375e6e53751f48cb864448ec390571d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ac1325106b14741b81038fa79361bd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72da54debc634cdba81b9fc97fa9afa6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_49ce160cf5e0461fb20e6e63721c9b8b",
            "value": "‚Äá2/2‚Äá[00:06&lt;00:00,‚Äá‚Äá3.32s/it]"
          }
        },
        "3cfc822d63a948a3820ae71283e33746": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43044c9f547a495090a58148db1bf60c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0480e4a196e45b0acb0fb9284c4bce8",
              "IPY_MODEL_8fbb7e2cb8624651911397cc0d556806",
              "IPY_MODEL_460a8f5665df40f18c4d066c88f07e08"
            ],
            "layout": "IPY_MODEL_f62c43a078e54c96b80f581f977835ae"
          }
        },
        "436c48d27ff1454eba0c38c97b774869": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc729da6499f4293b76989e3ab5279d7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_668606025e4743d2bf1791f029190e0a",
            "value": 2
          }
        },
        "460a8f5665df40f18c4d066c88f07e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ced9679ab9947e3b778626b574abc44",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f0a2d28c719d4b79bf067e5be4c9c581",
            "value": "‚Äá2/2‚Äá[00:02&lt;00:00,‚Äá‚Äá1.06s/it]"
          }
        },
        "4917b0fc680345c297a0c9bc0371db0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49ce160cf5e0461fb20e6e63721c9b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4afa549de0a64312bf964a10567e39d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bcf868feb614558b776334c5f792ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12bbd0219b1f4e078d2d2240d4eec486",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_76163832d5a948b7b440ba5b4d027701",
            "value": "tokenizer.model:‚Äá"
          }
        },
        "4d846ab6a7fb43ecbe157a5e4dfc6ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ff4458dcd8240bfaa60a8e1bbe52f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "521c4538cb8b44338f39f8ac872c4d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59b948620f8347d1be13af37fd78e2e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c147e3d90154497887bfdf26c7c75bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ffbb9bba9114150badd4c0c5162782b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13778ee9448c45aab93b08eba085c1d2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4ff4458dcd8240bfaa60a8e1bbe52f5a",
            "value": "‚Äá2/2‚Äá[00:06&lt;00:00,‚Äá‚Äá3.26s/it]"
          }
        },
        "61453f5ff35d445f8570ef1692423224": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a584d55ffe4e99a5068ef0055b2cca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61fe6e7dca64435786a4aeb795c36648": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "668606025e4743d2bf1791f029190e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c8a1d47ef9244b88568baeb13b6add9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bcf868feb614558b776334c5f792ebc",
              "IPY_MODEL_d005ceec96574da9be57cd0a91168a01",
              "IPY_MODEL_11091850396a44bba5a04727fa57470a"
            ],
            "layout": "IPY_MODEL_dd9436e158db47e2a1fc96e35c428092"
          }
        },
        "72da54debc634cdba81b9fc97fa9afa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "740c00974eca4dd3b198e4e88c29df80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dedb39f2d6bb48b7830cb00a7e94cf1a",
            "max": 34362873,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e42a1958313043de9f3b1f70b88e20b4",
            "value": 34362873
          }
        },
        "75e60310dc474864b353a4a6a286281b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76163832d5a948b7b440ba5b4d027701": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77db02d6b4e640c797064bfec1412be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7ef5b86365a469499ce8fb761fbbfaf",
              "IPY_MODEL_740c00974eca4dd3b198e4e88c29df80",
              "IPY_MODEL_bb4c5073c68143608ccab403c451ed4e"
            ],
            "layout": "IPY_MODEL_78f93cc2a57548b7aa3069945ac6df52"
          }
        },
        "78f93cc2a57548b7aa3069945ac6df52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "792ce938302841e3b3218e84546e05cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e758be310de44e997ca38a52213d675",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61fe6e7dca64435786a4aeb795c36648",
            "value": 1
          }
        },
        "793f1509f09840e5bab348a0cd01aa44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c4c5af53f0b4e9e9c02a63ca341f7e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82877abdcec240f5b7e31441cb56224d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82cc8530ac004692a0189b1d677c93a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61a584d55ffe4e99a5068ef0055b2cca",
            "max": 575,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c79cd4bf6da4fed8c461138bbeb7520",
            "value": 575
          }
        },
        "83dfae177c234ee98e0652ad2d461a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aa451cb830b42878747a15411e7ed59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e758be310de44e997ca38a52213d675": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fbb7e2cb8624651911397cc0d556806": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c4c5af53f0b4e9e9c02a63ca341f7e2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3d634abf142465d9e21d85d1f62f108",
            "value": 2
          }
        },
        "907deca0fe2b47c4a9cd24fc8ce7533e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_793f1509f09840e5bab348a0cd01aa44",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4afa549de0a64312bf964a10567e39d1",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "a38f77856ffa4c98be9cbd023cf40fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "affa13203281457b8373ff6003f6e2f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5c49c409bc24535a1f86f16e2d8752b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9aad5dc41104e91b5642b21f3bf647e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bad661e3c0524b46aa2815b216c00036": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec44a47e266b40e4b5e1a72dabcf8e94",
              "IPY_MODEL_cf0ee4d68cc5437abc21b5b5a93ee91f",
              "IPY_MODEL_361c01b66c824ed59c297727820ea5b6"
            ],
            "layout": "IPY_MODEL_1061e8b4991048f7a981a665d87f4fdb"
          }
        },
        "bb4c5073c68143608ccab403c451ed4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4917b0fc680345c297a0c9bc0371db0d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0ab5c5043d8244679d6e985c45aaf94a",
            "value": "‚Äá48.0M/?‚Äá[00:00&lt;00:00,‚Äá57.3MB/s]"
          }
        },
        "bbd07c7ed04148ccbabeb1c270d2b1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0480e4a196e45b0acb0fb9284c4bce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb8f98359c62471b8ec20bbf9ae62789",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_375e6e53751f48cb864448ec390571d8",
            "value": "100%"
          }
        },
        "c7ef5b86365a469499ce8fb761fbbfaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75e60310dc474864b353a4a6a286281b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5c147e3d90154497887bfdf26c7c75bc",
            "value": "tokenizer.json:‚Äá"
          }
        },
        "c91f3d90122c4ec19c79342fb62babf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca55a3978e994541a0f2e890272ee54d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb8f98359c62471b8ec20bbf9ae62789": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc729da6499f4293b76989e3ab5279d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf0ee4d68cc5437abc21b5b5a93ee91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59b948620f8347d1be13af37fd78e2e1",
            "max": 456807328,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b36d079b4f64d24bfa6a97d60423edd",
            "value": 456807328
          }
        },
        "d005ceec96574da9be57cd0a91168a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d846ab6a7fb43ecbe157a5e4dfc6ba2",
            "max": 4241003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbd07c7ed04148ccbabeb1c270d2b1f6",
            "value": 4241003
          }
        },
        "d3d634abf142465d9e21d85d1f62f108": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d43b95c3fc254361abac8d0817d3b833": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7041dc9a8374b89bf750c3aeca6b322",
              "IPY_MODEL_792ce938302841e3b3218e84546e05cb",
              "IPY_MODEL_158c186cdd9b48e2b07a013abd7b7a28"
            ],
            "layout": "IPY_MODEL_b5c49c409bc24535a1f86f16e2d8752b"
          }
        },
        "d4c0e0a75fbd481ea6848f8e1ae02d34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd9436e158db47e2a1fc96e35c428092": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dedb39f2d6bb48b7830cb00a7e94cf1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e42a1958313043de9f3b1f70b88e20b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6b53e073e8c4ba28ab19bf4611bce9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f75076bcb82f4f6d8aabc5c21666f3f7",
              "IPY_MODEL_82cc8530ac004692a0189b1d677c93a3",
              "IPY_MODEL_2733c3d8322f4f5d9db036a737e1c7d6"
            ],
            "layout": "IPY_MODEL_61453f5ff35d445f8570ef1692423224"
          }
        },
        "e7041dc9a8374b89bf750c3aeca6b322": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83dfae177c234ee98e0652ad2d461a8f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_35889ba2cf394ff990a4dc4852608d1e",
            "value": "100%"
          }
        },
        "ebac52b9cf0f47479d6eacc4b3d1214f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec44a47e266b40e4b5e1a72dabcf8e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d00f2ba25f14c4f892b58eb7fcf587b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3cfc822d63a948a3820ae71283e33746",
            "value": "adapter_model.safetensors:‚Äá"
          }
        },
        "f0a2d28c719d4b79bf067e5be4c9c581": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f62c43a078e54c96b80f581f977835ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f75076bcb82f4f6d8aabc5c21666f3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82877abdcec240f5b7e31441cb56224d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_17fe36d10b024205a711741b4aaf8cfe",
            "value": "README.md:‚Äá100%"
          }
        },
        "fd92faf02f5847648ce94f95915ffe12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
