{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZBY_8Cm1Tm0"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + â­ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> â­\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8daoUhh51Tm7"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv_-ohpC1Tm7"
      },
      "source": [
        "**Read our [blog post](https://unsloth.ai/blog/r1-reasoning) for guidance on how to train reasoning models.**\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L79rwk421Tm8"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RsdmVOGk1Tm9"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab and Kaggle notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n",
        "    !pip install --no-deps cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZD3_CCC1Tm-"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267,
          "referenced_widgets": [
            "2d9d62f0a7364ac0b40e1da1b78ac10c",
            "25bb2faf4fa146df9a71ae6c3c6b4604",
            "436c48d27ff1454eba0c38c97b774869",
            "5ffbb9bba9114150badd4c0c5162782b",
            "d4c0e0a75fbd481ea6848f8e1ae02d34",
            "ca55a3978e994541a0f2e890272ee54d",
            "c91f3d90122c4ec19c79342fb62babf7",
            "cc729da6499f4293b76989e3ab5279d7",
            "668606025e4743d2bf1791f029190e0a",
            "13778ee9448c45aab93b08eba085c1d2",
            "4ff4458dcd8240bfaa60a8e1bbe52f5a"
          ]
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "a351a51b-ff8e-4480-f1fc-a9ff3534eb94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "Unsloth: If you want to finetune Gemma 2, install flash-attn to make it faster!\n",
            "To install flash-attn, do the below:\n",
            "\n",
            "pip install --no-deps --upgrade \"flash-attn>=2.6.3\"\n",
            "==((====))==  Unsloth 2025.3.18: Fast Gemma2 patching. Transformers: 4.49.0.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d9d62f0a7364ac0b40e1da1b78ac10c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = (\n",
        "    None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        ")\n",
        "load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",  # Llama-3.1 15 trillion tokens model 2x faster!\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",  # We also uploaded 4bit for 405b!\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\",  # New Mistral 12b 2x faster!\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",  # Mistral v3 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",  # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",  # Gemma 2x faster!\n",
        "]  # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/gemma-2-27b-bnb-4bit\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "068c90ff-61f3-411d-93d0-2eb4f2fb713a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.3.18 patched 46 layers with 46 QKV layers, 46 O layers and 46 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the Alpaca dataset from [yahma](https://huggingface.co/datasets/yahma/alpaca-cleaned), which is a filtered version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html). You can replace this code section with your own data prep.\n",
        "\n",
        "**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n",
        "\n",
        "**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!\n",
        "\n",
        "If you want to use the `llama-3` template for ShareGPT datasets, try our conversational [notebook](https://colab.research.google.com/drive/1XamvWYinY6FOSX9GLvnqSjjsNflxdhNc?usp=sharing).\n",
        "\n",
        "For text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p0cehDqwcAFT"
      },
      "outputs": [],
      "source": [
        "# alpaca_prompt = \"\"\"Below is an instruction that describes a response, paired with a context field that provides further context. Write a response that appropriately answers the request.\n",
        "\n",
        "# ### Question:\n",
        "# {}\n",
        "\n",
        "# ### Context:\n",
        "# {}\n",
        "\n",
        "# ### Answer:\n",
        "# {}\"\"\"\n",
        "\n",
        "# EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "# def formatting_prompts_func(examples):\n",
        "#     instructions = examples[\"question\"]\n",
        "#     inputs       = examples[\"context\"]\n",
        "#     outputs      = examples[\"answers\"]\n",
        "#     texts = []\n",
        "#     for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "#         text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "#         texts.append(text)\n",
        "#     return {\"text\": texts}\n",
        "\n",
        "\n",
        "# from datasets import load_dataset\n",
        "# dataset = load_dataset(\"SajjadAyoubi/persian_qa\", split = \"train\")\n",
        "# train_test_dataset = dataset.train_test_split(test_size=0.2) #splits the train split into train and test.\n",
        "\n",
        "# train_dataset = train_test_dataset[\"train\"]\n",
        "# test_dataset = train_test_dataset[\"test\"]\n",
        "# train_dataset = train_dataset.map(formatting_prompts_func, batched = True,)\n",
        "# test_dataset = test_dataset.map(formatting_prompts_func, batched = True,)\n",
        "\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a response,\n",
        "paired with a context field that provides further context.\n",
        "Write a response that appropriately answers the request.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Context:\n",
        "{}\n",
        "\n",
        "### Answer:\n",
        "{}\"\"\"\n",
        "\n",
        "# if \"answers\" in item and \"text\" in item[\"answers\"] and len(item[\"answers\"][\"text\"]) > 0:\n",
        "#         reference = item[\"answers\"][\"text\"][0]  # Assuming a list of answers\n",
        "#       else:\n",
        "#           reference = \"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"question\"]\n",
        "    inputs       = examples[\"context\"]\n",
        "    outputs      = examples[\"answers\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        answer_text = output['text'][0] if output.get('text', []) else ''\n",
        "        text = alpaca_prompt.format(instruction, input, answer_text) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return {\"text\": texts}\n",
        "pass\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset_train = load_dataset(\"SajjadAyoubi/persian_qa\", split = \"train\")\n",
        "dataset_test = load_dataset(\"SajjadAyoubi/persian_qa\", split = \"validation\")\n",
        "dataset = dataset_train.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SNEgZxGthas",
        "outputId": "cd2b22c4-6e86-4a89-e8ff-63d5bac8f4e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': 51, 'title': 'Ú©ØªØ§Ø¨', 'context': 'Ú©ØªØ§Ø¨ (ÙˆØ§Ù…\\u200cÙˆØ§Ú˜Ù‡ Ø§Ø² Ø²Ø¨Ø§Ù† Ø¹Ø±Ø¨ÛŒØŒ Ø¬Ù…Ø¹: Ú©ÙØªÙØ¨) Ù…Ø¬Ù…ÙˆØ¹Ù‡\\u200cØ§ÛŒ Ø§Ø² ØµÙØ­Ø§ØªÙ Ù†ÙˆØ´ØªÙ‡\\u200cØ´Ø¯Ù‡ØŒ Ù…ØµÙˆÙ‘Ø±ØŒ Ú†Ø§Ù¾\\u200cØ´Ø¯Ù‡ ÛŒØ§ ØµÙØ­Ø§Øª Ø®Ø§Ù„ÛŒ (ØµÙØ­Ù‡ Ø³ÙÛŒØ¯ Ùˆ Ù†Ø§Ù†ÙˆØ´ØªÙ‡)Ø› Ø³Ø§Ø®ØªÙ‡\\u200cØ´Ø¯Ù‡ Ø§Ø³Øª. Ø§Ø² Ù„ÙˆØ­\\u200cÙ‡Ø§ÛŒ Ú¯ÙÙ„ÛŒØŒ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡Ù” Ø¨ÛŒÙ†\\u200cØ§Ù„Ù†Ù‡Ø±ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù†ÙˆØ´ØªÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒ\\u200cØ´Ø¯. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ† Ø±ÙˆØ´ Ø¯Ø± Û²ÛµÛ°Û° Ø³Ø§Ù„ Ù‚Ø¨Ù„ Ø§Ø² Ù…ÛŒÙ„Ø§Ø¯ØŒ ØªÙˆØ³Ø· ØªÙ…Ø¯Ù† Ø³ÙˆÙ…Ø± Ø§Ø¨Ø¯Ø§Ø¹ Ø´Ø¯ Ùˆ Ø¨Ù‡ ØªÚ©Ø§Ù…Ù„ Ø±Ø³ÛŒØ¯. Ø§Ù…Ø§ Ø¨Ø§ Ú¯Ø°Ø´Øª Ø²Ù…Ø§Ù†ØŒ Ø¨Ø§Ø¨Ù„ÛŒ\\u200cÙ‡Ø§ Ùˆ Ø¢Ø´ÙˆØ±ÛŒ\\u200cÙ‡Ø§ Ù†ÛŒØ² Ù‡Ù…ÛŒÙ† Ø±ÙˆØ´ Ø±Ø§ Ø¨Ù‡\\u200cÚ©Ø§Ø± Ú¯Ø±ÙØªÙ†Ø¯. Ø§ÛŒÙ† Ù„ÙˆØ­\\u200cÙ‡Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø®Ø§Ú©Ù Ø±Ø³ Ùˆ Ø¢Ø¨ Ø³Ø§Ø®ØªÙ‡ Ù…ÛŒ\\u200cØ´Ø¯Ù†Ø¯ Ùˆ Ù‚Ø¨Ù„ Ø§Ø² Ø®Ø´Ú© Ø´Ø¯Ù†ØŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù†ÙˆÚ©\\u200cØªÛŒØ² Ø¨Ø± Ø±ÙˆÛŒ Ø¢Ù†\\u200cÙ‡Ø§ Ù†ÙˆØ´ØªÙ‡ Ù…ÛŒ\\u200cØ´Ø¯. Ù†ÙˆØ´ØªÙ‡\\u200cÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ± Ø§ÛŒÙ† Ù„ÙˆØ­\\u200cÙ‡Ø§ØŒ Ø¨ÛŒØ´ØªØ± Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø§Ù…Ø± Ø¨Ø§Ø²Ø±Ú¯Ø§Ù†ÛŒØŒ Ø§Ø¯Ø§Ø±ÛŒ Ùˆ Ø­Ú©ÙˆÙ…ØªÛŒ Ø¨ÙˆØ¯.[Û³] Ú©Ø¯Ú©Ø³ Ø´Ú©Ù„ Ø§Ù…Ø±ÙˆØ²ÛŒ Ú©ØªØ§Ø¨ Ø§Ø³ØªØ› ÛŒØ¹Ù†ÛŒ ØµÙØ­Ø§Øª Ù¾ÙˆØ³ØªØŒ Ù¾Ø§Ù¾ÛŒØ±ÙˆØ³ Ùˆ ØºÛŒØ±Ù‡ Ú©Ù‡ ØªØ§ Ø®ÙˆØ±Ø¯Ù‡ Ùˆ Ø§Ø² ÛŒÚ© Ù…Ø­Ù„ Ø¨Ù‡ ÛŒÚ©Ø¯ÛŒÚ¯Ø± Ø¯ÙˆØ®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ù†Ø¯. Ù¾ÛŒØ¯Ø§ÛŒØ´ Ú©Ø¯Ú©Ø³ Ø¨Ù‡ Ù‚Ø±Ù†Ù Ø¯ÙˆÙ… Ù…ÛŒÙ„Ø§Ø¯ÛŒ Ø¨Ø± Ù…ÛŒ\\u200cÚ¯Ø±Ø¯Ø¯ Ú©Ù‡ Ù…Ø³ÛŒØ­ÛŒØ§Ù† Ø§Ø² Ø¢Ù† Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ø§Ø±Ø´ Ù…ØªÙˆÙ† Ù…Ø°Ù‡Ø¨ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒ\\u200cÚ©Ø±Ø¯Ù†Ø¯. Ø§ÛŒÙ† ÙØ±Ù… Ø§Ø² Ú©ØªØ§Ø¨Ù’ Ø¨Ù‡\\u200cØ¯Ù„ÛŒÙ„ Ù…Ø²ÛŒØª\\u200cÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø§Ø´ØªØŒ Ø§Ø² Ù‚Ø±Ù† Ú†Ù‡Ø§Ø±Ù… Ù…ÛŒÙ„Ø§Ø¯ÛŒ Ø±ÙˆØ§Ø¬ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯.', 'question': 'Ú©ØªØ§Ø¨ Ú†ÛŒÙ‡ØŸ', 'answers': {'text': ['Ù…Ø¬Ù…ÙˆØ¹Ù‡\\u200cØ§ÛŒ Ø§Ø² ØµÙØ­Ø§ØªÙ Ù†ÙˆØ´ØªÙ‡\\u200cØ´Ø¯Ù‡ØŒ Ù…ØµÙˆÙ‘Ø±ØŒ Ú†Ø§Ù¾\\u200cØ´Ø¯Ù‡ ÛŒØ§ ØµÙØ­Ø§Øª Ø®Ø§Ù„ÛŒ (ØµÙØ­Ù‡ Ø³ÙÛŒØ¯ Ùˆ Ù†Ø§Ù†ÙˆØ´ØªÙ‡)Ø› Ø³Ø§Ø®ØªÙ‡\\u200cØ´Ø¯Ù‡'], 'answer_start': [41]}, 'text': 'Below is an instruction that describes a response, \\npaired with a context field that provides further context.\\nWrite a response that appropriately answers the request.\\n\\n### Question:\\nÚ©ØªØ§Ø¨ Ú†ÛŒÙ‡ØŸ\\n\\n### Context:\\nÚ©ØªØ§Ø¨ (ÙˆØ§Ù…\\u200cÙˆØ§Ú˜Ù‡ Ø§Ø² Ø²Ø¨Ø§Ù† Ø¹Ø±Ø¨ÛŒØŒ Ø¬Ù…Ø¹: Ú©ÙØªÙØ¨) Ù…Ø¬Ù…ÙˆØ¹Ù‡\\u200cØ§ÛŒ Ø§Ø² ØµÙØ­Ø§ØªÙ Ù†ÙˆØ´ØªÙ‡\\u200cØ´Ø¯Ù‡ØŒ Ù…ØµÙˆÙ‘Ø±ØŒ Ú†Ø§Ù¾\\u200cØ´Ø¯Ù‡ ÛŒØ§ ØµÙØ­Ø§Øª Ø®Ø§Ù„ÛŒ (ØµÙØ­Ù‡ Ø³ÙÛŒØ¯ Ùˆ Ù†Ø§Ù†ÙˆØ´ØªÙ‡)Ø› Ø³Ø§Ø®ØªÙ‡\\u200cØ´Ø¯Ù‡ Ø§Ø³Øª. Ø§Ø² Ù„ÙˆØ­\\u200cÙ‡Ø§ÛŒ Ú¯ÙÙ„ÛŒØŒ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡Ù” Ø¨ÛŒÙ†\\u200cØ§Ù„Ù†Ù‡Ø±ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù†ÙˆØ´ØªÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒ\\u200cØ´Ø¯. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ† Ø±ÙˆØ´ Ø¯Ø± Û²ÛµÛ°Û° Ø³Ø§Ù„ Ù‚Ø¨Ù„ Ø§Ø² Ù…ÛŒÙ„Ø§Ø¯ØŒ ØªÙˆØ³Ø· ØªÙ…Ø¯Ù† Ø³ÙˆÙ…Ø± Ø§Ø¨Ø¯Ø§Ø¹ Ø´Ø¯ Ùˆ Ø¨Ù‡ ØªÚ©Ø§Ù…Ù„ Ø±Ø³ÛŒØ¯. Ø§Ù…Ø§ Ø¨Ø§ Ú¯Ø°Ø´Øª Ø²Ù…Ø§Ù†ØŒ Ø¨Ø§Ø¨Ù„ÛŒ\\u200cÙ‡Ø§ Ùˆ Ø¢Ø´ÙˆØ±ÛŒ\\u200cÙ‡Ø§ Ù†ÛŒØ² Ù‡Ù…ÛŒÙ† Ø±ÙˆØ´ Ø±Ø§ Ø¨Ù‡\\u200cÚ©Ø§Ø± Ú¯Ø±ÙØªÙ†Ø¯. Ø§ÛŒÙ† Ù„ÙˆØ­\\u200cÙ‡Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø®Ø§Ú©Ù Ø±Ø³ Ùˆ Ø¢Ø¨ Ø³Ø§Ø®ØªÙ‡ Ù…ÛŒ\\u200cØ´Ø¯Ù†Ø¯ Ùˆ Ù‚Ø¨Ù„ Ø§Ø² Ø®Ø´Ú© Ø´Ø¯Ù†ØŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù†ÙˆÚ©\\u200cØªÛŒØ² Ø¨Ø± Ø±ÙˆÛŒ Ø¢Ù†\\u200cÙ‡Ø§ Ù†ÙˆØ´ØªÙ‡ Ù…ÛŒ\\u200cØ´Ø¯. Ù†ÙˆØ´ØªÙ‡\\u200cÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ± Ø§ÛŒÙ† Ù„ÙˆØ­\\u200cÙ‡Ø§ØŒ Ø¨ÛŒØ´ØªØ± Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø§Ù…Ø± Ø¨Ø§Ø²Ø±Ú¯Ø§Ù†ÛŒØŒ Ø§Ø¯Ø§Ø±ÛŒ Ùˆ Ø­Ú©ÙˆÙ…ØªÛŒ Ø¨ÙˆØ¯.[Û³] Ú©Ø¯Ú©Ø³ Ø´Ú©Ù„ Ø§Ù…Ø±ÙˆØ²ÛŒ Ú©ØªØ§Ø¨ Ø§Ø³ØªØ› ÛŒØ¹Ù†ÛŒ ØµÙØ­Ø§Øª Ù¾ÙˆØ³ØªØŒ Ù¾Ø§Ù¾ÛŒØ±ÙˆØ³ Ùˆ ØºÛŒØ±Ù‡ Ú©Ù‡ ØªØ§ Ø®ÙˆØ±Ø¯Ù‡ Ùˆ Ø§Ø² ÛŒÚ© Ù…Ø­Ù„ Ø¨Ù‡ ÛŒÚ©Ø¯ÛŒÚ¯Ø± Ø¯ÙˆØ®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ù†Ø¯. Ù¾ÛŒØ¯Ø§ÛŒØ´ Ú©Ø¯Ú©Ø³ Ø¨Ù‡ Ù‚Ø±Ù†Ù Ø¯ÙˆÙ… Ù…ÛŒÙ„Ø§Ø¯ÛŒ Ø¨Ø± Ù…ÛŒ\\u200cÚ¯Ø±Ø¯Ø¯ Ú©Ù‡ Ù…Ø³ÛŒØ­ÛŒØ§Ù† Ø§Ø² Ø¢Ù† Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ø§Ø±Ø´ Ù…ØªÙˆÙ† Ù…Ø°Ù‡Ø¨ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒ\\u200cÚ©Ø±Ø¯Ù†Ø¯. Ø§ÛŒÙ† ÙØ±Ù… Ø§Ø² Ú©ØªØ§Ø¨Ù’ Ø¨Ù‡\\u200cØ¯Ù„ÛŒÙ„ Ù…Ø²ÛŒØª\\u200cÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø§Ø´ØªØŒ Ø§Ø² Ù‚Ø±Ù† Ú†Ù‡Ø§Ø±Ù… Ù…ÛŒÙ„Ø§Ø¯ÛŒ Ø±ÙˆØ§Ø¬ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯.\\n\\n### Answer:\\nÙ…Ø¬Ù…ÙˆØ¹Ù‡\\u200cØ§ÛŒ Ø§Ø² ØµÙØ­Ø§ØªÙ Ù†ÙˆØ´ØªÙ‡\\u200cØ´Ø¯Ù‡ØŒ Ù…ØµÙˆÙ‘Ø±ØŒ Ú†Ø§Ù¾\\u200cØ´Ø¯Ù‡ ÛŒØ§ ØµÙØ­Ø§Øª Ø®Ø§Ù„ÛŒ (ØµÙØ­Ù‡ Ø³ÙÛŒØ¯ Ùˆ Ù†Ø§Ù†ÙˆØ´ØªÙ‡)Ø› Ø³Ø§Ø®ØªÙ‡\\u200cØ´Ø¯Ù‡<eos>'}\n"
          ]
        }
      ],
      "source": [
        "print(dataset[40])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q-MoYlJcrPnL"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 8,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 90,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"qw\",\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "8ba8ab9c-f12a-403a-c039-f7239aee2160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "11.684 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "c67324ec-b3c0-48b4-ae87-d590c42248ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 9,008 | Num Epochs = 1 | Total steps = 90\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n",
            " \"-____-\"     Trainable parameters = 114,180,096/27,000,000,000 (0.42% trained)\n",
            "AUTOTUNE bmm(256x456x128, 256x128x456)\n",
            "  bmm 0.2253 ms 100.0% \n",
            "  triton_bmm_14 0.4219 ms 53.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_10 0.4690 ms 48.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_5 0.4844 ms 46.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_13 0.4946 ms 45.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_6 0.5325 ms 42.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_18 0.5499 ms 41.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_3 0.5519 ms 40.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_15 0.5540 ms 40.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=8\n",
            "  triton_bmm_9 0.6103 ms 36.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "SingleProcess AUTOTUNE benchmarking takes 2.5631 seconds and 0.0089 seconds precompiling\n",
            "AUTOTUNE bmm(256x456x456, 256x456x128)\n",
            "  bmm 0.1464 ms 100.0% \n",
            "  triton_bmm_33 0.3328 ms 44.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_29 0.3840 ms 38.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_32 0.3963 ms 37.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_37 0.4127 ms 35.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_24 0.4178 ms 35.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_25 0.4291 ms 34.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_34 0.4424 ms 33.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=8\n",
            "  triton_bmm_22 0.4639 ms 31.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_28 0.5028 ms 29.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "SingleProcess AUTOTUNE benchmarking takes 2.5335 seconds and 0.0024 seconds precompiling\n",
            "AUTOTUNE bmm(256x456x456, 256x456x128)\n",
            "  bmm 0.1454 ms 100.0% \n",
            "  triton_bmm_81 0.3645 ms 39.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_78 0.4659 ms 31.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_79 0.4925 ms 29.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_76 0.4956 ms 29.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=2\n",
            "  triton_bmm_82 0.5612 ms 25.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_85 0.6308 ms 23.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_89 0.6461 ms 22.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_92 0.7127 ms 20.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_83 0.7322 ms 19.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=8\n",
            "SingleProcess AUTOTUNE benchmarking takes 2.5871 seconds and 0.0024 seconds precompiling\n",
            "AUTOTUNE bmm(256x456x128, 256x128x456)\n",
            "  bmm 0.1843 ms 100.0% \n",
            "  triton_bmm_105 0.3820 ms 48.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_108 0.3901 ms 47.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_104 0.3942 ms 46.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_100 0.4147 ms 44.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_101 0.4219 ms 43.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_109 0.4239 ms 43.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_110 0.4495 ms 41.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=8\n",
            "  triton_bmm_113 0.5243 ms 35.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_95 0.5560 ms 33.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=2\n",
            "SingleProcess AUTOTUNE benchmarking takes 2.5326 seconds and 0.0025 seconds precompiling\n",
            "AUTOTUNE bmm(256x128x456, 256x456x456)\n",
            "  bmm 0.1464 ms 100.0% \n",
            "  triton_bmm_119 0.3676 ms 39.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_117 0.4741 ms 30.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_116 0.5038 ms 29.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_114 0.5069 ms 28.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=2\n",
            "  triton_bmm_120 0.5857 ms 25.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_123 0.6431 ms 22.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_127 0.6461 ms 22.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_128 0.7465 ms 19.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_124 0.7578 ms 19.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "SingleProcess AUTOTUNE benchmarking takes 2.5833 seconds and 0.0026 seconds precompiling\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [90/90 21:55, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.957700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.031700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.103200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.961700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.891400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.848300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.769400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.606900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.679700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.662000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.602800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.664000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.660900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.618200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.560400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.591400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.523600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.532200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.530300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.590700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.438000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.541500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.455900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.501800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.614000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.539600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.569900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.489300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.536200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.582800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.503100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.489800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.577200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.523400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.541000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.516000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.482400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.389200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.487100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.493200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.426000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.465900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.397200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.494200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.476400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.421900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.386600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.353600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.421500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.423000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.421900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.369600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.410100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.469400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.389600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.512700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.439100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.409800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.386800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>1.315300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.379200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>1.295400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.410300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1.376600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1.391900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>1.357300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.324800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1.449600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.366300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>1.307800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.285600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>1.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>1.310500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.312300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.354400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>1.322300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>1.329000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>1.248600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.252700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>1.298200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>1.441600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>1.283100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>1.307100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>1.298400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>1.285200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>1.330900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>1.374600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>1.335400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.335200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCqnaKmlO1U9"
      },
      "outputs": [],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "07a06471-4fd5-4e7f-8128-ad9cba47dbac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "AUTOTUNE bmm(16x55x256, 16x256x55)\n",
            "  triton_bmm_153 0.0133 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_166 0.0143 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_155 0.0154 ms 86.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_159 0.0154 ms 86.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=8\n",
            "  triton_bmm_158 0.0164 ms 81.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_161 0.0164 ms 81.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  bmm 0.0174 ms 76.5% \n",
            "  triton_bmm_154 0.0174 ms 76.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_163 0.0174 ms 76.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "  triton_bmm_162 0.0195 ms 68.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "SingleProcess AUTOTUNE benchmarking takes 1.8075 seconds and 0.0086 seconds precompiling for 16 choices\n",
            "AUTOTUNE bmm(16x55x55, 16x55x256)\n",
            "  bmm 0.0102 ms 100.0% \n",
            "  triton_bmm_168 0.0102 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_169 0.0102 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_170 0.0102 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8\n",
            "  triton_bmm_174 0.0102 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=8\n",
            "  triton_bmm_181 0.0102 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8\n",
            "  triton_bmm_171 0.0113 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=32, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4\n",
            "  triton_bmm_173 0.0113 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4\n",
            "  triton_bmm_175 0.0113 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4\n",
            "  triton_bmm_180 0.0113 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, B_PROLOGUE_CAST_TYPE=None, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4\n",
            "SingleProcess AUTOTUNE benchmarking takes 2.0411 seconds and 0.0023 seconds precompiling for 18 choices\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['<bos>Below is an instruction that describes a response,\\npaired with a context field that provides further context.\\nWrite a response that appropriately answers the request.\\n\\n### Question:\\nfdsfsdfdsfØŸ\\n\\n### Context:\\nddsddsØŸ\\n\\n### Answer:\\n<eos>']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"fdsfsdfdsfØŸ\", # instruction\n",
        "        \"ddsddsØŸ\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2pEuRb1r2Vg",
        "outputId": "d507298f-93f9-4e70-8d9e-689280975ce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bos>Below is an instruction that describes a response,\n",
            "paired with a context field that provides further context.\n",
            "Write a response that appropriately answers the request.\n",
            "\n",
            "### Question:\n",
            "ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®ØªØ§Ù† Ø³ÛŒØ¨ Ú©Ø´Ù Ø´Ø¯Ù‡ØŸ\n",
            "\n",
            "### Context:\n",
            "\n",
            "\n",
            "### Answer:\n",
            "ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®ØªØ§Ù† Ø³ÛŒØ¨ Ú©Ø´Ù Ø´Ø¯Ù‡: 10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n"
          ]
        }
      ],
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®ØªØ§Ù† Ø³ÛŒØ¨ Ú©Ø´Ù Ø´Ø¯Ù‡ØŸ\", # instruction\n",
        "        \"\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upcOlWe7A1vc"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"lora_model\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WGctFj4tFRxj"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login #writing to huggingface\n",
        "login(token=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227,
          "referenced_widgets": [
            "e6b53e073e8c4ba28ab19bf4611bce9d",
            "f75076bcb82f4f6d8aabc5c21666f3f7",
            "82cc8530ac004692a0189b1d677c93a3",
            "2733c3d8322f4f5d9db036a737e1c7d6",
            "61453f5ff35d445f8570ef1692423224",
            "82877abdcec240f5b7e31441cb56224d",
            "17fe36d10b024205a711741b4aaf8cfe",
            "61a584d55ffe4e99a5068ef0055b2cca",
            "0c79cd4bf6da4fed8c461138bbeb7520",
            "8aa451cb830b42878747a15411e7ed59",
            "b9aad5dc41104e91b5642b21f3bf647e",
            "d43b95c3fc254361abac8d0817d3b833",
            "e7041dc9a8374b89bf750c3aeca6b322",
            "792ce938302841e3b3218e84546e05cb",
            "158c186cdd9b48e2b07a013abd7b7a28",
            "b5c49c409bc24535a1f86f16e2d8752b",
            "83dfae177c234ee98e0652ad2d461a8f",
            "35889ba2cf394ff990a4dc4852608d1e",
            "8e758be310de44e997ca38a52213d675",
            "61fe6e7dca64435786a4aeb795c36648",
            "10169a2c15f2428ab6803a2820cc8c65",
            "1f9efc99625d497689e2ca55b36089be",
            "bad661e3c0524b46aa2815b216c00036",
            "ec44a47e266b40e4b5e1a72dabcf8e94",
            "cf0ee4d68cc5437abc21b5b5a93ee91f",
            "361c01b66c824ed59c297727820ea5b6",
            "1061e8b4991048f7a981a665d87f4fdb",
            "2d00f2ba25f14c4f892b58eb7fcf587b",
            "3cfc822d63a948a3820ae71283e33746",
            "59b948620f8347d1be13af37fd78e2e1",
            "0b36d079b4f64d24bfa6a97d60423edd",
            "1285896f5b874909b8f2e2cb762ca033",
            "521c4538cb8b44338f39f8ac872c4d93",
            "43044c9f547a495090a58148db1bf60c",
            "c0480e4a196e45b0acb0fb9284c4bce8",
            "8fbb7e2cb8624651911397cc0d556806",
            "460a8f5665df40f18c4d066c88f07e08",
            "f62c43a078e54c96b80f581f977835ae",
            "cb8f98359c62471b8ec20bbf9ae62789",
            "375e6e53751f48cb864448ec390571d8",
            "7c4c5af53f0b4e9e9c02a63ca341f7e2",
            "d3d634abf142465d9e21d85d1f62f108",
            "1ced9679ab9947e3b778626b574abc44",
            "f0a2d28c719d4b79bf067e5be4c9c581",
            "6c8a1d47ef9244b88568baeb13b6add9",
            "4bcf868feb614558b776334c5f792ebc",
            "d005ceec96574da9be57cd0a91168a01",
            "11091850396a44bba5a04727fa57470a",
            "dd9436e158db47e2a1fc96e35c428092",
            "12bbd0219b1f4e078d2d2240d4eec486",
            "76163832d5a948b7b440ba5b4d027701",
            "4d846ab6a7fb43ecbe157a5e4dfc6ba2",
            "bbd07c7ed04148ccbabeb1c270d2b1f6",
            "fd92faf02f5847648ce94f95915ffe12",
            "affa13203281457b8373ff6003f6e2f6",
            "77db02d6b4e640c797064bfec1412be1",
            "c7ef5b86365a469499ce8fb761fbbfaf",
            "740c00974eca4dd3b198e4e88c29df80",
            "bb4c5073c68143608ccab403c451ed4e",
            "78f93cc2a57548b7aa3069945ac6df52",
            "75e60310dc474864b353a4a6a286281b",
            "5c147e3d90154497887bfdf26c7c75bc",
            "dedb39f2d6bb48b7830cb00a7e94cf1a",
            "e42a1958313043de9f3b1f70b88e20b4",
            "4917b0fc680345c297a0c9bc0371db0d",
            "0ab5c5043d8244679d6e985c45aaf94a"
          ]
        },
        "id": "enVXWEqbL65b",
        "outputId": "24ff9e11-ab39-4eba-f32d-d96520d46843"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6b53e073e8c4ba28ab19bf4611bce9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/575 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d43b95c3fc254361abac8d0817d3b833",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bad661e3c0524b46aa2815b216c00036",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/457M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model to https://huggingface.co/regd/gemma227b90step2e-4\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43044c9f547a495090a58148db1bf60c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c8a1d47ef9244b88568baeb13b6add9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77db02d6b4e640c797064bfec1412be1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.push_to_hub(\"regd/gemma227b90step2e-4\")\n",
        "trainer.create_model_card(\"regd/gemma227b90step2e-4\")\n",
        "tokenizer.push_to_hub(\"regd/gemma227b90step2e-4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rwbWiXSX0Sz8"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login #reading from huggingface\n",
        "login(token=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKivnsvP5e1v"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zi82gbFK0YQE"
      },
      "outputs": [],
      "source": [
        "%pip install -U bitsandbytes --quiet\n",
        "%pip install datasets --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GQ3T7rMILQz_"
      },
      "outputs": [],
      "source": [
        "%pip install tqdm --quiet\n",
        "%pip install unsloth --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vExX6xerfTVS"
      },
      "outputs": [],
      "source": [
        "%pip install bert-score --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "1ae3e1179efe426bb5cc5f401be97c7f",
            "907deca0fe2b47c4a9cd24fc8ce7533e",
            "1ca7bf5538d3485ca4d9c1ffb77d8756",
            "3ac1325106b14741b81038fa79361bd5",
            "ebac52b9cf0f47479d6eacc4b3d1214f",
            "793f1509f09840e5bab348a0cd01aa44",
            "4afa549de0a64312bf964a10567e39d1",
            "1fab2f0843ba459da42e8c3daa37e3fa",
            "a38f77856ffa4c98be9cbd023cf40fd5",
            "72da54debc634cdba81b9fc97fa9afa6",
            "49ce160cf5e0461fb20e6e63721c9b8b"
          ]
        },
        "id": "12TyVMgEDm4x",
        "outputId": "f2bb82a1-6e7a-4246-9875-1ef1cd01d5d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ae3e1179efe426bb5cc5f401be97c7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM  # Import the AutoModel class\n",
        "model_name = \"regd/gemma227b90step2e-4\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name) # Now AutoModel should be defined\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JKrT3Osc5ySq"
      },
      "outputs": [],
      "source": [
        "# dataset_test\n",
        "def format_prompt(question, context=None):\n",
        "         if context:\n",
        "             prompt = f\"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
        "         else:\n",
        "             prompt = f\"Question: {question}\\n\\nAnswer:\"\n",
        "         return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TR32FbWU6UKF"
      },
      "outputs": [],
      "source": [
        "def generate_answer(model, tokenizer, prompt, max_new_tokens=20, max_seq_length=2048):\n",
        "         inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "         with torch.no_grad():\n",
        "             outputs = model.generate(\n",
        "                 **inputs,\n",
        "                 max_new_tokens=max_new_tokens,\n",
        "                 temperature=0.7, # Adjust as needed\n",
        "                 top_p=0.9,      # Adjust as needed\n",
        "                 do_sample=False,\n",
        "                 max_length = 20,\n",
        "                 eos_token_id=tokenizer.eos_token_id,\n",
        "                 use_cache=False,\n",
        "                #  num_beams=5,\n",
        "                #  early_stopping=True\n",
        "             )\n",
        "         answer = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
        "         return answer.strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TIo9Xjt-6t76"
      },
      "outputs": [],
      "source": [
        "def evaluate_f1_token(prediction, reference):\n",
        "          pred_tokens = prediction.lower().split()\n",
        "          ref_tokens = reference.lower().split()\n",
        "          common = set(pred_tokens) & set(ref_tokens)\n",
        "          if len(pred_tokens) == 0 or len(ref_tokens) == 0:\n",
        "              return 0.0\n",
        "          precision = len(common) / len(pred_tokens)\n",
        "          recall = len(common) / len(ref_tokens)\n",
        "          if precision + recall == 0:\n",
        "              return 0.0\n",
        "          f1 = 2 * precision * recall / (precision + recall)\n",
        "          return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yXKEar5QZf_Z"
      },
      "outputs": [],
      "source": [
        "def evaluate_exact_match(prediction, reference):\n",
        "    \"\"\"\n",
        "    Calculates the Exact Match (EM) score between a prediction and a reference.\n",
        "\n",
        "    Args:\n",
        "        prediction (str): The predicted answer.\n",
        "        reference (str): The reference answer.\n",
        "\n",
        "    Returns:\n",
        "        float: 1.0 if the prediction exactly matches the reference, 0.0 otherwise.\n",
        "    \"\"\"\n",
        "    if prediction.strip().lower() == reference.strip().lower():\n",
        "        return 1.0\n",
        "    else:\n",
        "        return 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8MH0Q97Be3Wz"
      },
      "outputs": [],
      "source": [
        "from bert_score import score\n",
        "\n",
        "def evaluate_bert_score(prediction, reference, lang=\"en\", model_type=None, num_layers=None, verbose=False):\n",
        "    \"\"\"\n",
        "    Calculates BERTScore for a single prediction and reference.\n",
        "\n",
        "    Args:\n",
        "        prediction (str): The predicted sentence.\n",
        "        reference (str): The reference sentence.\n",
        "        lang (str): Language of the sentences (e.g., \"en\", \"es\").\n",
        "        model_type (str, optional): BERT model to use (e.g., \"bert-base-uncased\"). If None, it will be automatically inferred from lang.\n",
        "        num_layers (int, optional): Number of BERT layers to use.\n",
        "        verbose (bool, optional): Print progress.\n",
        "\n",
        "    Returns:\n",
        "        float: The F1-score from BERTScore, or 0.0 if there is an error.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        P, R, F1 = score([prediction], [reference], lang=lang, model_type=model_type, num_layers=num_layers, verbose=verbose)\n",
        "        return F1.item()  # Return the F1 score as a float\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating BERTScore: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "# Example usage (replace your existing evaluate_f1_token calls):\n",
        "# ... (your existing code) ...\n",
        "\n",
        "# Replace calls to evaluate_f1_token with evaluate_bert_score\n",
        "# f1_score = evaluate_f1_token(prediction, reference)\n",
        "# f1_score = evaluate_bert_score(prediction, reference)\n",
        "\n",
        "# ... (rest of your code) ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGE-nfSKX73q",
        "outputId": "b9c32df7-09f5-4ecb-8942-1228717c5862"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.\n",
            "Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:   1%|          | 1/100 [00:08<14:11,  8.60s/it]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:   2%|â–         | 2/100 [00:15<11:59,  7.34s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:   3%|â–         | 3/100 [00:21<11:11,  6.92s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:   4%|â–         | 4/100 [00:27<10:43,  6.70s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:   5%|â–Œ         | 5/100 [00:34<10:25,  6.59s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:   6%|â–Œ         | 6/100 [00:40<10:14,  6.54s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:   7%|â–‹         | 7/100 [00:47<10:07,  6.53s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:   8%|â–Š         | 8/100 [00:53<10:07,  6.60s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:   9%|â–‰         | 9/100 [01:00<09:56,  6.55s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  10%|â–ˆ         | 10/100 [01:06<09:47,  6.53s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  11%|â–ˆ         | 11/100 [01:13<09:33,  6.45s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  12%|â–ˆâ–        | 12/100 [01:19<09:30,  6.48s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  13%|â–ˆâ–        | 13/100 [01:26<09:42,  6.70s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  14%|â–ˆâ–        | 14/100 [01:33<09:25,  6.57s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  15%|â–ˆâ–Œ        | 15/100 [01:39<09:13,  6.51s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  16%|â–ˆâ–Œ        | 16/100 [01:45<09:02,  6.45s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  17%|â–ˆâ–‹        | 17/100 [01:54<10:00,  7.23s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  18%|â–ˆâ–Š        | 18/100 [02:01<09:30,  6.96s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  19%|â–ˆâ–‰        | 19/100 [02:07<09:10,  6.80s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  20%|â–ˆâ–ˆ        | 20/100 [02:13<08:52,  6.65s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  21%|â–ˆâ–ˆ        | 21/100 [02:20<08:54,  6.76s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  22%|â–ˆâ–ˆâ–       | 22/100 [02:27<08:36,  6.62s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  23%|â–ˆâ–ˆâ–       | 23/100 [02:33<08:21,  6.52s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  24%|â–ˆâ–ˆâ–       | 24/100 [02:39<08:09,  6.44s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 25/100 [02:46<08:01,  6.42s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  26%|â–ˆâ–ˆâ–Œ       | 26/100 [02:52<08:00,  6.49s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  27%|â–ˆâ–ˆâ–‹       | 27/100 [02:59<07:49,  6.42s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  28%|â–ˆâ–ˆâ–Š       | 28/100 [03:05<07:39,  6.38s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  29%|â–ˆâ–ˆâ–‰       | 29/100 [03:11<07:31,  6.35s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  30%|â–ˆâ–ˆâ–ˆ       | 30/100 [03:17<07:21,  6.31s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [03:24<07:17,  6.34s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [03:30<07:12,  6.36s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  33%|â–ˆâ–ˆâ–ˆâ–      | 33/100 [03:37<07:08,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [03:43<07:05,  6.44s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [03:50<06:58,  6.44s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [03:56<06:55,  6.49s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [04:03<06:50,  6.52s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [04:09<06:42,  6.49s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [04:16<06:35,  6.48s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [04:22<06:28,  6.47s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [04:29<06:24,  6.52s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [04:35<06:15,  6.47s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/100 [04:42<06:06,  6.44s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [04:48<05:59,  6.42s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [04:54<05:52,  6.40s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [05:01<05:45,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [05:07<05:38,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [05:14<05:34,  6.44s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [05:20<05:27,  6.41s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [05:26<05:19,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [05:33<05:11,  6.35s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [05:39<05:03,  6.32s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/100 [05:45<04:56,  6.31s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [05:51<04:49,  6.30s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [05:58<04:43,  6.30s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [06:04<04:42,  6.42s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [06:11<04:35,  6.41s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [06:17<04:27,  6.38s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [06:23<04:20,  6.35s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [06:30<04:14,  6.36s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [06:37<04:14,  6.52s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [06:47<04:49,  7.63s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 63/100 [06:54<04:34,  7.43s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [07:00<04:17,  7.16s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [07:07<04:04,  6.99s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [07:13<03:52,  6.84s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [07:20<03:44,  6.80s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [07:27<03:41,  6.92s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [07:34<03:30,  6.79s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [07:40<03:20,  6.70s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [07:47<03:10,  6.57s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [07:53<03:01,  6.49s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 73/100 [07:59<02:53,  6.43s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [08:07<03:01,  6.97s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [08:14<02:50,  6.82s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [08:20<02:39,  6.65s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [08:26<02:30,  6.54s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [08:33<02:21,  6.45s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [08:39<02:14,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [08:45<02:06,  6.35s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [08:51<02:00,  6.33s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [08:58<01:53,  6.31s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 83/100 [09:04<01:48,  6.37s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [09:10<01:41,  6.34s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [09:17<01:35,  6.33s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [09:23<01:28,  6.31s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [09:30<01:23,  6.42s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [09:36<01:16,  6.36s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [09:42<01:09,  6.33s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [09:48<01:03,  6.31s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [09:55<00:56,  6.33s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [10:01<00:50,  6.36s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 93/100 [10:08<00:45,  6.45s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [10:14<00:38,  6.42s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [10:21<00:32,  6.41s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [10:27<00:25,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Evaluating:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [10:33<00:19,  6.38s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [10:40<00:12,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [10:46<00:06,  6.39s/it]Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:53<00:00,  6.53s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'question': 'Ù¾Ø§ÛŒØªØ®Øª Ø§Ø³Ù¾Ø§Ù†ÛŒØ§ Ú©Ø¬Ø§Ø³ØªØŸ',\n",
              "  'reference': 'Ù…Ø§Ø¯Ø±ÛŒØ¯',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¨Ø± Ú†Ù‡ Ø§Ø³Ø§Ø³ÛŒ Ø±Ø¦Ø§Ù„ Ù…ÙˆÙÙ‚ ØªØ±ÛŒÙ† ØªÛŒÙ… Ø¯Ø± ØªØ§Ø±ÛŒØ® ÙÙˆØªØ¨Ø§Ù„ Ø§Ø±ÙˆÙ¾Ø§ Ø§Ø³ØªØŸ',\n",
              "  'reference': 'ÙÛŒÙØ§',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø±Ø¦Ø§Ù„ Ù…Ø§Ø¯Ø±ÛŒØ¯ Ú†Ù†Ø¯ Ø¨Ø§Ø± Ø¯Ø± Ù„ÛŒÚ¯ Ù‚Ù‡Ø±Ù…Ø§Ù†Ø§Ù† Ø§Ø±ÙˆÙ¾Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù‚Ù‡Ø±Ù…Ø§Ù†ÛŒ Ø±Ø³ÛŒØ¯Ù‡ØŸ',\n",
              "  'reference': 'Û±Û³',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù…Ø¹Ù†ÛŒ ÙˆØ§Ú˜Ù‡ Ø±Ø¦Ø§Ù„ Ø¨Ù‡ Ø§Ø³Ù¾Ø§Ù†ÛŒØ§ÛŒÛŒ Ú†ÛŒØ³ØªØŸ',\n",
              "  'reference': 'Ø³Ù„Ø·Ù†ØªÛŒ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ØªÛŒÙ… Ø±Ø¦Ø§Ù„ Ù…Ø§Ø¯Ø±ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ú©Ø¬Ø§Ø³ØªØŸ',\n",
              "  'reference': 'Ù…Ø§Ø¯Ø±ÛŒØ¯ØŒ Ù¾Ø§ÛŒØªØ®Øª Ø§Ø³Ù¾Ø§Ù†ÛŒØ§',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù„Ù‚Ø¨ Ø¨Ø§Ø´Ú¯Ø§Ù‡ Ø±Ø¦Ø§Ù„ Ù…Ø§Ø¯Ø±ÛŒØ¯ Ø§Ø² Ú©Ø¬Ø§ Ù…ÛŒØ§Ø¯ØŸ',\n",
              "  'reference': 'Ø´Ø§Ù‡ Ø¢Ù„ÙÙˆÙ†Ø³Ùˆ Ø³ÛŒØ²Ø¯Ù‡Ù… Ø¯Ø± Ø³Ø§Ù„ Û±Û¹Û²Û° Ø¨Ø± Ø§ÛŒÙ† ØªÛŒÙ… Ù†Ù‡Ø§Ø¯',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¯Ø´Ù…Ù† Ø§ØµÙ„ÛŒ Ø¨Ø§Ø´Ú¯Ø§Ù‡ ÙÙˆØªØ¨Ø§Ù„ Ø±Ø¦Ø§Ù„ Ù…Ø§Ø¯Ø±ÛŒØ¯ Ú©Ø¯Ø§Ù… ØªÛŒÙ… Ø§Ø³ØªØŸ',\n",
              "  'reference': 'Ø±Ù‚ÛŒØ¨ Ø§ØµÙ„ÛŒ Ø§ÛŒÙ† ØªÛŒÙ… Ù†ÛŒØ²ØŒ Ø¨Ø§Ø±Ø³Ù„ÙˆÙ†Ø§ Ø§Ø³Øª',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¨Ø§Ø±Ø³Ù„ÙˆÙ†Ø§ Ú†Ù†Ø¯ Ø¨Ø§Ø± Ù‚Ù‡Ø±Ù…Ø§Ù† Ù„ÛŒÚ¯ Ù‚Ù‡Ø±Ù…Ø§Ù†Ø§Ù† Ø§Ø±ÙˆÙ¾Ø§ Ø´Ø¯Ù‡ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¨Ø§Ø´Ú¯Ø§Ù‡ ÙÙˆØªØ¨Ø§Ù„ Ø±Ø¦Ø§Ù„ Ù…Ø§Ø¯Ø±ÛŒØ¯ Ø¯Ø± Ú†Ù‡ Ø³Ø§Ù„ÛŒ ØªØ§Ø³ÛŒØ³ Ø´Ø¯Ù‡ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø±Ú©ÙˆØ±Ø¯Ø¯Ø§Ø± Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù‚Ù‡Ø±Ù…Ø§Ù†ÛŒ Ø¯Ø± Ù„ÛŒÚ¯ Ù‚Ù‡Ø±Ù…Ø§Ù†Ø§Ù† Ø¢Ø³ÛŒØ§ Ú©Ø¯Ø§Ù… ØªÛŒÙ… Ø§Ø³ØªØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¨Ø§Ø±Ø³Ø§ Ù…Ø®ÙÙ Ú†ÛŒÙ‡ØŸ',\n",
              "  'reference': 'Ø¨Ø§Ø±Ø³Ù„ÙˆÙ†Ø§',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ØªÛŒÙ… Ø¨Ø§Ø±Ø³Ù„ÙˆÙ†Ø§ Ø¨Ø±Ø§ÛŒ Ú©Ø¯Ø§Ù… Ú©Ø´ÙˆØ± Ø§Ø³ØªØŸ',\n",
              "  'reference': 'Ø§Ø³Ù¾Ø§Ù†ÛŒØ§',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø´Ù‡Ø± Ø¨Ø§Ø±Ø³Ù„ÙˆÙ† Ø¯Ø± Ú©Ø¬Ø§ÛŒ Ú©Ø´ÙˆØ± Ø§Ø³Ù¾Ø§Ù†ÛŒØ§ ÙˆØ§Ù‚Ø¹ Ø´Ø¯Ù‡ØŸ',\n",
              "  'reference': 'Ù…Ù†Ø·Ù‚Ù‡Ù” Ú©Ø§ØªØ§Ù„ÙˆÙ†ÛŒØ§ÛŒ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú†Ø±Ø§ Ø´Ø¹Ø§Ø± ØªÛŒÙ… Ø¨Ø§Ø±Ø³Ø§ ÙØ±Ø§ØªØ± Ø§Ø² ÛŒÚ© Ø¨Ø§Ø´Ú¯Ø§Ù‡ Ø§Ø³ØªØŸ',\n",
              "  'reference': 'Ø¨Ù‡ Ù†ÙˆØ¹ÛŒØŒ Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ±ÙˆÛŒØ¬ ÙØ±Ù‡Ù†Ú¯ Ú©Ø§ØªØ§Ù„Ø§Ù† Ùˆ Ú©Ø§ØªØ§Ù„Ø§Ù†ÛŒØ³Ù…',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¢Ù‡Ù†Ú¯ Ø±Ø³Ù…ÛŒ ØªÛŒÙ… Ø¨Ø§Ø±Ø³Ø§ Ø±Ø§ Ú†Ù‡ Ú©Ø³ÛŒ Ø³Ø§Ø®ØªÙ‡ØŸ',\n",
              "  'reference': 'Ø¬ÙˆØ²Ù¾ Ù…Ø§Ø±ÛŒØ§ Ø§Ø³Ù¾ÛŒÙ†Ø§Ø³',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ØªÛŒÙ… Ø¨Ø§Ø±Ø³Ø§ Ø¨Ù‡ Ú†Ù‡ ØµÙˆØ±Øª Ø§Ø¯Ø§Ø±Ù‡ Ù…ÛŒ Ø´ÙˆØ¯ØŸ',\n",
              "  'reference': 'ØªÙˆØ³Ø· Ù‡ÙˆØ§Ø¯Ø§Ø±Ø§Ù†Ø´',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¹Ù…Ø¯Ù‡ Ø¹Ù„Øª Ø´Ù‡Ø±Øª ØªÛŒÙ… Ø¨Ø§Ø±Ø³Ø§ Ø¨Ø±Ø§ÛŒ Ú†ÛŒØ³ØªØŸ',\n",
              "  'reference': 'Ø´ÛŒÙˆÙ‡ Ø­Ù…Ù„Ù‡\\u200cØ§ÛŒ Ù…Ø§Ù‡Ø±Ø§Ù†Ù‡ Ùˆ Ø¬Ø°Ø§Ø¨Ø´',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ØªÛŒÙ… Ø¨Ø§Ø±Ø³Ø§ Ø¯Ø± Ú†Ù‡ Ø³Ø§Ù„ÛŒ Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø± Ù‚Ù‡Ø±Ù…Ø§Ù† Ù„Ø§Ù„ÛŒÚ¯Ø§ Ø´Ø¯ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø´Ú¯Ø§Ù‡ Ø«Ø±ÙˆØªÙ…Ù†Ø¯ Ø¯Ù†ÛŒØ§',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú†Ù‡ Ú©Ø³ÛŒ Ù„Ù‚Ø¨ Ø¨Ø§Ø±Ø³Ø§ Ø±Ø§ ÙØ±Ø§ØªØ± Ø§Ø² ÛŒÚ© Ø¨Ø§Ø´Ú¯Ø§Ù‡ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÙØ±Ù‡Ø§Ø¯ Ù…Ø¬ÛŒØ¯ÛŒ Ø¯Ø± Ù„ÛŒÚ¯ Ø§Ù…Ø§Ø±Ø§Øª Ø¨Ø±Ø§ÛŒ Ú†Ù‡ Ø¨Ø§Ø´Ú¯Ø§Ù‡ Ù‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒ Ú©Ø±Ø¯Ù‡ØŸ',\n",
              "  'reference': 'Ø§Ù„ÙˆØµÙ„ØŒ Ø§Ù„Ø¹ÛŒÙ†ØŒ Ø§Ù„Ø§Ù‡Ù„ÛŒ Ùˆ Ø§Ù„Ù†ØµØ±',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù…Ø¬ÛŒØ¯ÛŒ ÙˆÙ‚ØªÛŒ Ø§Ø² ÙÙˆØªØ¨Ø§Ù„ Ø®Ø¯Ø§Ø­Ø§ÙØ¸ÛŒ  Ú©Ø±Ø¯ Ø¯Ø± Ú†Ù‡ ØªÛŒÙ…ÛŒ Ø¨ÙˆØ¯ØŸ',\n",
              "  'reference': 'Ø¨Ø§Ø´Ú¯Ø§Ù‡ Ø§Ø³ØªÙ‚Ù„Ø§Ù„ ØªÙ‡Ø±Ø§Ù†',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÙØ±Ù‡Ø§Ø¯ Ù…Ø¬ÛŒØ¯ÛŒ Ú†Ù†Ø¯ Ú¯Ù„ Ù…Ù„ÛŒ Ø¯Ø± Ú©Ø§Ø±Ù†Ø§Ù…Ù‡ Ø¯Ø§Ø±Ø¯ØŸ',\n",
              "  'reference': 'Û±Û° Ú¯Ù„',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÙØ±Ù‡Ø§Ø¯ Ù…Ø¬ÛŒØ¯ÛŒ Ø¯Ø± Ú©Ø¬Ø§ Ø¨Ù‡ Ø¯Ù†ÛŒØ§ Ø¢Ù…Ø¯Ù‡ Ø§Ø³ØªØŸ',\n",
              "  'reference': 'ØªÙ‡Ø±Ø§Ù†',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¯Ø± Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡ Ù…Ø¬ÛŒØ¯ÛŒ Ø¨Ù‡ Ø¬Ø² ÙØ±Ù‡Ø§Ø¯ Ú†Ù‡ Ú©Ø³ÛŒ ÙÙˆØªØ¨Ø§Ù„ÛŒØ³Øª Ø¨ÙˆØ¯Ù‡ØŸ',\n",
              "  'reference': 'Ø¨Ø±Ø§Ø¯Ø±Ø´ ÙØ±Ø²Ø§Ø¯',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§Ø³Ù… Ø¨Ú†Ù‡ Ù‡Ø§ÛŒ ÙØ±Ù‡Ø§Ø¯ Ù…Ø¬ÛŒØ¯ÛŒ Ú†ÛŒÙ‡ØŸ',\n",
              "  'reference': 'ØªÛŒØ§Ù… Ùˆ Ø§Ù…ÛŒØ± Ø¨Ø±Ø¯ÛŒØ§',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÙØ±Ù‡Ø§Ø¯ Ù…Ø¬ÛŒØ¯ÛŒ Ø¨Ø¹Ø¯ Ø§Ø² Ø¨Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬ÙˆØ§Ù†Ø§Ù† Ú©Ø´Ø§ÙˆØ±Ø² Ø¨Ù‡ Ú†Ù‡ ØªÛŒÙ…ÛŒ Ø±ÙØªØŸ',\n",
              "  'reference': 'Ø¬ÙˆØ§Ù†Ø§Ù† Ø¨Ù‡Ù…Ù†',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§Ø³Ù… Ù…Ø§Ø¯Ø± ÙØ±Ù‡Ø§Ø¯ Ù…Ø¬ÛŒØ¯ÛŒ Ú†ÛŒØ³ØªØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÙØ±Ø²Ø§Ø¯ Ù…Ø¬ÛŒØ¯ÛŒ Ø¯Ø± Ú†Ù‡ ØªÛŒÙ… Ù‡Ø§ÛŒ Ø¨Ø§Ø²ÛŒ Ú©Ø±Ø¯Ù‡ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÙØ±Ù‡Ø§Ø¯ Ù…Ø¬ÛŒØ¯ÛŒ Ú†Ù†Ø¯ Ø³Ø§Ù„Ø´ Ø§Ø³ØªØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú¯Ø§Ù†Ø¯ÛŒ Ú†Ù‡ Ú©Ø³ÛŒ Ø¨ÙˆØ¯ØŸ',\n",
              "  'reference': 'Ø±Ù‡Ø¨Ø± Ø³ÛŒØ§Ø³ÛŒ Ùˆ Ù…Ø¹Ù†ÙˆÛŒ Ù‡Ù†Ø¯ÛŒ\\u200cÙ‡Ø§',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø³Ø§ØªÛŒØ§Ú¯Ø±Ø§Ù‡Ø§ Ø§Ø´Ø§Ø±Ù‡ Ø¨Ù‡ Ú†Ù‡ Ú†ÛŒØ²ÛŒ Ø¯Ø§Ø±Ø¯ØŸ',\n",
              "  'reference': 'ÙÙ„Ø³ÙÙ‡Ù” Ø¨ÛŒ\\u200cØ®Ø´ÙˆÙ†ØªÛŒ Ú¯Ø§Ù†Ø¯ÛŒ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ú¯Ø§Ù†Ø¯ÛŒ Ø±Ù‡Ø¨Ø± Ù…Ø¨Ø§Ø±Ø²Ù‡ Ø¨Ø±Ø§ÛŒ Ø¢Ø²Ø§Ø¯ÛŒ Ù‡Ù†Ø¯ Ø´Ø¯ Ù…Ø±Ø¯Ù… Ø¨Ù‡ Ø§Ùˆ Ú†Ù‡ Ù…ÛŒ Ú¯ÙØªÙ†Ø¯ØŸ',\n",
              "  'reference': 'Ù…Ù‡Ø§ØªÙ…Ø§ ÛŒØ§ Ø±ÙˆØ­ Ø¨Ø²Ø±Ú¯',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§Ø² Ú†Ù‡ Ø³Ø§Ù„ÛŒ Ú¯Ø§Ù†Ø¯ÛŒ Ø¨Ø§ Ù„Ù‚Ø¨ Ù…Ù‡Ø§ØªÙ…Ø§ Ø´Ù†Ø§Ø®ØªÙ‡ Ø´Ø¯ØŸ',\n",
              "  'reference': 'Ø¯Ø± Ø³Ø§Ù„ Û±Û¹Û±Û¸',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÙÙ„Ø³ÙÙ‡Ù” Ø¨ÛŒ Ø®Ø´ÙˆÙ†ØªÛŒ Ú¯Ø§Ù†Ø¯ÛŒ Ø±ÙˆÛŒ Ú†Ù‡ Ø§ÙØ±Ø§Ø¯ Ø¢Ø²Ø§Ø¯ÛŒ Ø®ÙˆØ§Ù‡ÛŒ Ø§Ø«Ø± Ú¯Ø°Ø§Ø´ØªÙ‡ Ø¨ÙˆØ¯ØŸ',\n",
              "  'reference': 'Ø¯Ú©ØªØ± Ù…Ø§Ø±ØªÛŒÙ† Ù„ÙˆØªØ±Ú©ÛŒÙ†Ú¯ØŒ ØªÙ†Ø²ÛŒÙ† Ú¯ÛŒØ§ØªØ³ÙˆØŒ Ù„Ø® ÙˆØ§Ù„Ø³Ø§ØŒ Ø§Ø³ØªÙØ§Ù† Ø¨ÛŒÚ©ÙˆØŒ Ø¢Ù†Ú¯ Ø³Ø§Ù† Ø³Ùˆ Ú†ÛŒ Ùˆ Ù†Ù„Ø³ÙˆÙ† Ù…Ø§Ù†Ø¯Ù„Ø§',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú¯Ø§Ù†Ø¯ÛŒ Ú†Ú¯ÙˆÙ†Ù‡ ØªÙˆØ§Ù†Ø³Øª Ø§Ù…Ù¾Ø±Ø§ØªÙˆØ±ÛŒ Ø¨Ø±ÛŒØªØ§Ù†ÛŒØ§ Ø±Ø§ Ø§Ø² Ù‡Ù†Ø¯ Ø¨ÛŒØ±ÙˆÙ† Ú©Ù†Ø¯ØŸ',\n",
              "  'reference': 'Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø´ÛŒÙˆÙ‡Ù” Ø¶Ø¯ Ø®Ø´ÙˆÙ†Øª Ù†Ø§ÙØ±Ù…Ø§Ù†ÛŒ Ù…Ø¯Ù†ÛŒ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù…Ù‡Ø§Ù†Ø¯Ø§Ø³ Ú©Ø§Ø±Ø§Ù…Ú†Ø§Ù†Ø¯ Ú¯Ø§Ù†Ø¯ÛŒ Ø§Ù…Ø±ÙˆØ² Ø¨Ø§ Ú†Ù‡ Ø§Ø³Ù…ÛŒ Ø´Ù†Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³ØªØŸ',\n",
              "  'reference': 'Ù…Ù‡Ø§ØªÙ…Ø§ Ú¯Ø§Ù†Ø¯ÛŒ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù†Ù„Ø³ÙˆÙ† Ù…Ø§Ù†Ø¯Ù„Ø§ Ú†Ù‡ ØªØ§Ø«ÛŒØ±ÛŒ Ø±ÙˆÛŒ Ú¯Ø§Ù†Ø¯ÛŒ Ú¯Ø°Ø§Ø´ØªØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¬Ù†Ø¨Ø´\\u200cÙ‡Ø§ÛŒ Ù…Ù‚Ø§ÙˆÙ…Øª Ø¨Ø¯ÙˆÙ† Ø®Ø´ÙˆÙ†Øª Ø¯Ø± Ø¬Ù‡Ø§Ù† Ø§Ø² Ú†Ù‡ Ø³Ø§Ù„ÛŒ Ø´Ø±ÙˆØ¹ Ø´Ø¯Ù†Ø¯ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú†Ù‡ Ú©Ø³ÛŒ ØªÙˆØ§Ù†Ø³Øª Ø§Ø³ØªÙ‚Ù„Ø§Ù„ Ø¨Ø±ÛŒØªØ§Ù†ÛŒØ§ Ø±Ø§ Ø§Ø² Ù‡Ù†Ø¯ Ø¨Ú¯ÛŒØ±Ø¯ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÙØ±Ø§ÙˆØ§Ù† ØªØ±ÛŒÙ† Ø¯ÙˆØ²ÛŒØ³Øª Ø¯Ø± Ø¯Ù†ÛŒØ§ Ú†ÛŒÙ‡ØŸ',\n",
              "  'reference': 'Ù‚ÙˆØ±Ø¨Ø§ØºÙ‡\\u200cÙ‡Ø§ Ùˆ ÙˆØ²Øº\\u200cÙ‡Ø§',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø²Ø¨Ø§Ù† Ø¯Ø±Ø§Ø² Ù‚ÙˆØ±Ø¨Ø§ØºÙ‡ Ú†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§ÛŒ Ø¯Ø§Ø±Ø¯ØŸ',\n",
              "  'reference': 'Ú¯Ø±ÙØªÙ† Ø·Ø¹Ù…Ù‡',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÙØ±Ù‚ Ù‚ÙˆØ±Ø¨Ø§ØºÙ‡ Ùˆ ÙˆØ²Øº\\u200c Ú†ÛŒØ³ØªØŸ',\n",
              "  'reference': 'Ù‚ÙˆØ±Ø¨Ø§ØºÙ‡\\u200cÙ‡Ø§ Ø¨Ø¯Ù† Ù†Ø±Ù… Ùˆ Ù…Ø±Ø·ÙˆØ¨ Ø¯Ø§Ø±Ù†Ø¯ Ùˆ Ø¯Ø± Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ø¢Ø¨\\u200cÙ‡Ø§ Ø²Ù†Ø¯Ú¯ÛŒ Ù…ÛŒ\\u200cÚ©Ù†Ù†Ø¯. ÙˆØ²ØºÙ‡Ø§ Ø§Ù…Ø§ Ù¾ÙˆØ³Øª Ø®Ø´Ú© Ùˆ Ø²Ú¯ÛŒÙ„ Ù…Ø§Ù†Ù†Ø¯ Ø¯Ø§Ø±Ù†Ø¯ Ùˆ Ø¹Ù…Ø¯ØªØ§Ù‹ Ø±ÙˆÛŒ Ø®Ø´Ú©ÛŒ Ø²Ù†Ø¯Ú¯ÛŒ Ù…ÛŒ\\u200cÚ©Ù†Ù†Ø¯',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù…Ø­Ù„ Ø²Ù†Ø¯Ú¯ÛŒ Ù‚ÙˆØ±Ø¨Ø§ØºÙ‡ Ú©Ø¬Ø§Ø³ØªØŸ',\n",
              "  'reference': 'Ø¯Ø± Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ø¢Ø¨\\u200cÙ‡Ø§',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù¾ÙˆØ³Øª ÙˆØ²Øº Ù‡Ø§ Ø¨Ù‡ Ú†Ù‡ ØµÙˆØ±Øª Ø§Ø³ØªØŸ',\n",
              "  'reference': 'Ø®Ø´Ú© Ùˆ Ø²Ú¯ÛŒÙ„ Ù…Ø§Ù†Ù†Ø¯',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¯Ø± Ú©Ø¬Ø§Ù‡Ø§ÛŒ Ø¯Ù†ÛŒØ§ Ù‚ÙˆØ±Ø¨Ø§ØºÙ‡\\u200c Ù†Ø¯Ø§Ø±ÛŒÙ…ØŸ',\n",
              "  'reference': 'Ù‚Ø·Ø¨ Ø¬Ù†ÙˆØ¨ Ùˆ Ùˆ Ø¯Ø± Ø¨Ø³ÛŒØ§Ø±ÛŒ Ø§Ø² Ø¬Ø²Ø§ÛŒØ± Ø§Ù‚ÛŒØ§Ù†ÙˆØ³ÛŒ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú†Ø±Ø§ Ù‚ÙˆØ±Ø¨Ø§ØºÙ‡ Ù‡Ø§ Ø¯Ø± Ù…Ù†Ø§Ø·Ù‚ Ú¯Ø±Ù…Ø³ÛŒØ±ÛŒ ØªÙ†ÙˆØ¹ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯ØŸ',\n",
              "  'reference': 'Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø³Ø§Ø®ØªØ§Ø± Ùˆ Ù†ÛŒØ§Ø² Ù¾ÙˆØ³Øª Ù‚ÙˆØ±Ø¨Ø§ØºÙ‡\\u200cÙ‡Ø§',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§Ø² Ø¶Ø¯ÛŒØ® Ù‚ÙˆØ±Ø¨Ø§ØºÙ‡ Ù‡Ø§ Ú†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù‡Ø§ÛŒ ØµÙ†Ø¹ØªÛŒ Ù…ÛŒ ØªÙˆØ§Ù† Ú©Ø±Ø¯ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù…Ø­Ù„ Ø²Ù†Ø¯Ú¯ÛŒ Ù‚ÙˆØ±Ø¨Ø§ØºÙ‡ Ú†Ù‡ Ø¬Ø§Ù‡Ø§ÛŒ Ù†Ù…ÛŒ ØªÙˆØ§Ù†Ø¯ Ø¨Ø§Ø´Ø¯ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'ÙØ±Ø§ÙˆØ§Ù† ØªØ±ÛŒÙ† ØªÚ© Ø²ÛŒØ³Øª Ø¯Ø± Ø¬Ù‡Ø§Ù† Ú†ÛŒØ³ØªØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§Ù†Ø¬ÛŒÙ„ Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ú†Ù‡ Ù†Ø§Ù… Ø¯Ø§Ø±Ù†Ø¯ØŸ',\n",
              "  'reference': 'Ø§Ù†Ø¬ÛŒÙ„ Ù…ØªÛŒØŒ Ù…Ø±Ù‚Ø³ØŒ Ù„ÙˆÙ‚Ø§ Ùˆ ÛŒÙˆØ­Ù†Ø§',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú©ØªØ§Ø¨ Ø§Ù†Ø¬ÛŒÙ„ Ú†ÛŒØ³ØªØŸ',\n",
              "  'reference': 'Ø´Ø±Ø­ÛŒ Ø§Ø² Ø²Ù†Ø¯Ú¯ÛŒ Ùˆ Ø¢Ù…ÙˆØ²Ù‡\\u200cÙ‡Ø§ÛŒ Ø¹ÛŒØ³ÛŒ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§Ù†Ø¬ÛŒÙ„\\u200cÙ‡Ø§ÛŒ Ø¹Ù‡Ø¯ Ø¬Ø¯ÛŒØ¯ Ø¯Ø± Ú†Ù‡ Ø³Ø§Ù„ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡ Ø§Ù†Ø¯ØŸ',\n",
              "  'reference': 'Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨ÛŒÙ† Ø³Ø§Ù„\\u200cÙ‡Ø§ÛŒ Û¶Û¶ ØªØ§ Û±Û±Û° Ù…ÛŒÙ„Ø§Ø¯ÛŒ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ù‡Ø§ÛŒ Ú†Ù‡Ø§Ø± Ø§Ù†Ø¬ÛŒÙ„ Ø§ØµÙ„ÛŒ Ú†Ù‡ Ú©Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÙ†Ø¯ØŸ',\n",
              "  'reference': 'Ù…Ø´Ø®Øµ Ù†ÛŒØ³Øª',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§Ø³Ù… Ø¹Ù‡Ø¯ Ø¬Ø¯ÛŒØ¯ Ø¯Ø± Ú©ØªØ§Ø¨ Ø§Ù†Ø¬ÛŒÙ„ Ù†Ø´Ø§Ù† Ø¯Ù‡Ù†Ø¯Ù‡ Ú†ÛŒØ³ØªØŸ',\n",
              "  'reference': 'Ø¨Ù‡ Ù¾ÛŒÙ…Ø§Ù†ÛŒ Ø§Ø´Ø§Ø±Ù‡ Ø¯Ø§Ø±Ø¯ Ú©Ù‡ Ø¢ØºØ§Ø²Ú¯Ø± Ø¯ÙˆØ±Ù‡Ù” Ø¬Ø¯ÛŒØ¯ÛŒ Ø§Ø² Ø§Ø±ØªØ¨Ø§Ø· Ø®Ø¯Ø§ÙˆÙ†Ø¯ Ø¨Ø§ Ø§Ù†Ø³Ø§Ù† Ø§Ø³Øª',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¯Ø± Ø§Ù†Ø¬ÛŒÙ„ Ø¹Ù‡Ø¯ Ø¬Ø¯ÛŒØ¯ Ø´Ø±Ø· Ø±Ø³ØªÚ¯Ø§Ø±ÛŒ Ø§Ù†Ø³Ø§Ù† Ú†ÛŒØ³ØªØŸ',\n",
              "  'reference': 'Ø§ÛŒÙ…Ø§Ù† Ø¨Ù‡ Ù…Ø³ÛŒØ­',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¹Ù‡Ø¯ Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ø¬Ø² Ú†Ù‡Ø§Ø± Ú©ØªØ§Ø¨ Ø§ØµÙ„ÛŒ Ø´Ø§Ù…Ù„ Ú†Ù‡ Ú†ÛŒØ²Ù‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±ÛŒ Ù…ÛŒ Ø´ÙˆØ¯',\n",
              "  'reference': 'Ú©ØªØ§Ø¨ Ø§Ø¹Ù…Ø§Ù„ Ø±Ø³ÙˆÙ„Ø§Ù†ØŒ Ù†Ø§Ù…Ù‡\\u200cÙ‡Ø§ÛŒ Ø±Ø³ÙˆÙ„Ø§Ù† Ù…Ø³ÛŒØ­ Ùˆ Ú©ØªØ§Ø¨ Ù…Ú©Ø§Ø´ÙÙ‡',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú†Ø±Ø§ Ù†Ø§Ù… Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ù‡Ø§ÛŒ Ú†Ù‡Ø§Ø± Ú©ØªØ§Ø¨ Ø§ØµÙ„ÛŒ Ø¹Ù‡Ø¯ Ø¬Ø¯ÛŒØ¯ Ù…Ø´Ø®Øµ Ù†ÛŒØ³ØªØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù†Ø§Ù… Ø¯Ùˆ Ú©ØªØ§Ø¨ Ø§ØµÙ„ÛŒ Ø¹Ù‡Ø¯ Ù‚Ø¯ÛŒÙ… Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¢Ù…ÙˆØ²Ù‡\\u200cÙ‡Ø§ÛŒ Ø¹ÛŒØ³ÛŒ Ø¨Ù‡ Ú†Ù‡ ØµÙˆØ±Øª Ø¯Ø± Ú©ØªØ§Ø¨ Ù‡Ø§ÛŒ Ø¹Ù‡Ø¯ Ø¬Ø¯ÛŒØ¯ Ø¢ÙˆØ±Ø¯Ù‡ Ø´Ø¯Ù‡ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§Ø®ØªÙ„Ø§Ù Ø´Ù…Ø§Ù„ Ù…ØºÙ†Ø§Ø·ÛŒØ³ÛŒ Ùˆ Ø´Ù…Ø§Ù„ Ø­Ù‚ÛŒÙ‚ÛŒ Ø±Ùˆ Ú†ÛŒ Ù…ÛŒ Ú¯Ù†ØŸ',\n",
              "  'reference': 'Ù…ÛŒÙ„ Ù…ØºÙ†Ø§Ø·ÛŒØ³ÛŒ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§Ú©Ø³ÛŒØ¯ Ù…ØºÙ†Ø§Ø·ÛŒØ³ÛŒ Ø¢Ù‡Ù† Ú†ÛŒÙ‡ØŸ',\n",
              "  'reference': 'Ù†ÙˆØ¹ÛŒ Ú©Ø§Ù†ÛŒ Ø¢Ù‡Ù†',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù‚Ø·Ø¨ Ù†Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ú†ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒ Ø´Ù‡ØŸ',\n",
              "  'reference': 'Ù‚ÙØ·Ø¨\\u200cÙ†Ù…Ø§ ÙˆØ³ÛŒÙ„Ù‡\\u200cØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¹ÛŒÛŒÙ† Ø¬Ù‡Øª (Ø¬Ù‡Øª\\u200cÛŒØ§Ø¨ÛŒ)',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù‚Ø·Ø¨ Ù†Ù…Ø§ Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒÛŒ Ø¯Ø§Ø±Ù‡ØŸ',\n",
              "  'reference': 'Ø¨Ø±Ø§ÛŒ ØªØ¹ÛŒÛŒÙ† Ø¬Ù‡Øª (Ø¬Ù‡Øª\\u200cÛŒØ§Ø¨ÛŒ)',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§Ú©Ø³ÛŒØ¯ Ù…ØºÙ†Ø§Ø·ÛŒØ³ÛŒ Ø¢Ù‡Ù† Ú†Ù‡ Ù†ÙˆØ¹ Ù…Ø§Ø¯Ù‡ Ø§ÛŒ Ø§Ø³ØªØŸ',\n",
              "  'reference': 'Ø·Ø¨ÛŒØ¹ÛŒ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù‚Ø·Ø¨ Ù†Ù…Ø§ Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø§Ø³Ù…Ø´ÙˆÙ† Ú†ÛŒÙ‡ØŸ',\n",
              "  'reference': 'Ú˜ÛŒØ±ÙˆØ³Ú©ÙˆÙ¾ÛŒ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù‚Ø·Ø¨ Ù†Ù…Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú†Ù‡ Ú†ÛŒØ²ÛŒ Ø¬Ù‡Øª Ø±Ùˆ Ù†Ø´ÙˆÙ† Ù…ÛŒ Ø¯Ù‡ØŸ',\n",
              "  'reference': 'Ù†ÛŒØ±ÙˆÛŒ Ø¢Ù‡Ù†Ø±Ø¨Ø§ÛŒÛŒ Ø²Ù…ÛŒÙ†',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù‚Ø·Ø¨ Ù†Ù…Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú†Ù‡ Ú†ÛŒØ²ÛŒ Ø¬Ù‡Øª Ø±Ùˆ Ù†Ø´ÙˆÙ† Ù†Ù…ÛŒ Ø¯Ù‡ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú†Ø¬ÙˆØ±ÛŒ Ù…ÛŒ Ø´Ù‡ Ù‚Ø·Ø¨ Ù†Ù…Ø§ Ø³Ø§Ø®ØªØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¯Ù‚ÛŒÙ‚ ØªØ±ÛŒÙ† Ù‚Ø·Ø¨ Ù†Ù…Ø§ Ù…ÙˆØ¬ÙˆØ¯ Ú†ÛŒ Ù†Ø§Ù… Ø¯Ø§Ø±Ø¯ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¬Ø¹Ø¨Ù‡ Ø³ÛŒØ§Ù‡ Ø¨Ø±Ø§ÛŒ Ú†ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒ Ø´Ù‡ØŸ',\n",
              "  'reference': 'Ø°Ø®ÛŒØ±Ù‡ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø®Ø§Øµ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¬Ø¹Ø¨Ù‡ Ø³ÛŒØ§Ù‡ Ú†Ù‡ Ø±Ù†Ú¯ÛŒÙ‡ØŸ',\n",
              "  'reference': 'Ù†Ø§Ø±Ù†Ø¬ÛŒ ÙØ³ÙØ±ÛŒ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¬Ø¹Ø¨Ù‡ Ø³ÛŒØ§Ù‡ Ø´Ø§Ù…Ù„ Ú†ÛŒÙ‡ØŸ',\n",
              "  'reference': 'Ø¯Ø³ØªÚ¯Ø§Ù‡ Ø«Ø¨Øª Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙÙ†ÛŒ Ù¾Ø±ÙˆØ§Ø² Ùˆ Ø¯Ø³ØªÚ¯Ø§Ù‡ Ø«Ø¨Øª ØµØ¯Ø§Ù‡Ø§ÛŒ Ú©Ø§Ø¨ÛŒÙ†',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¬Ø¹Ø¨Ù‡ Ø³ÛŒØ§Ù‡ Ø¨Ù‡ ØºÛŒØ± Ø§Ø² Ù‡ÙˆØ§Ù¾ÛŒÙ…Ø§ ØªÙˆ Ú†ÛŒ Ù‡Ø³ØªØŸ',\n",
              "  'reference': 'Ú©Ø´ØªÛŒØŒ Ø¨Ø§Ù„Ú¯Ø±Ø¯',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø±Ù†Ú¯ Ø¬Ø¹Ø¨Ù‡ Ø³ÛŒØ§Ù‡ Ú©Ø¬Ø§ Ù…ÙˆØ«Ø±Ù‡ØŸ',\n",
              "  'reference': 'Ø¯Ø± Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¬Ø¹Ø¨Ù‡ Ø³ÛŒØ§Ù‡',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú©ÛŒ Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø± Ø§Ø² Ø¬Ø¹Ø¨Ù‡ Ø³ÛŒØ§Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯ØŸ',\n",
              "  'reference': 'Ø¨Ø±Ø§Ø¯Ø±Ø§Ù† Ø±Ø§ÛŒØª',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¨Ø±Ø§Ø¯Ø±Ø§Ù† Ø±Ø§ÛŒØª Ø¨Ø±Ø§ÛŒ Ú†ÛŒ Ø§Ø² Ø¬Ø¹Ø¨Ù‡ Ø³ÛŒØ§Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯Ù†ØŸ',\n",
              "  'reference': 'Ø¨Ø±Ø§ÛŒ Ø¶Ø¨Ø· Ú†Ú¯ÙˆÙ†Ú¯ÛŒ Ú†Ø±Ø®Ø´ Ù¾Ø±Ù‡\\u200cÙ‡Ø§ÛŒ Ù…Ù„Ø®',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¬Ø¹Ø¨Ù‡ Ø³ÛŒØ§Ù‡ Ø±Ùˆ Ú©ÛŒ Ø³Ø§Ø®ØªØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¨Ø²Ø±Ú¯ØªØ±ÛŒÙ† Ø³Ø§Ø²Ù†Ø¯Ù‡ Ø¬Ø¹Ø¨Ù‡ Ø³ÛŒØ§Ù‡ Ú©ÛŒÙ‡ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¬Ø¹Ø¨Ù‡ Ø³ÛŒØ§Ù‡ Ú†Ù‚Ø¯Ø± Ù…Ù‚Ø§ÙˆÙ…Øª Ø¯Ø§Ø±Ù‡ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¯Ø± Ú¯Ø°Ø´ØªÙ‡ Ø§Ù†Ø³Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø°ÙˆØ¨ Ø¢Ù‡Ù† Ø§Ø² Ú†ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒ Ú©Ø±Ø¯ØŸ',\n",
              "  'reference': 'Ø²ØºØ§Ù„ Ú†ÙˆØ¨ Ùˆ Ù…Ø´ØªÙ‚Ø§Øª Ú†ÙˆØ¨',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø³ÙˆØ®Øª Ú†Ø¬ÙˆØ±ÛŒ Ø§Ù†Ø±Ú˜ÛŒ Ù‚Ø§Ø¨Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒ Ú©Ù†Ù‡ØŸ',\n",
              "  'reference': 'Ø¯Ø± Ø§Ø«Ø± ØªØºÛŒÛŒØ±Ø§Øª (Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø´ÛŒÙ…ÛŒØ§Ø¦ÛŒ)',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù…Ù†Ø¨Ø¹ Ø³ÙˆØ®ØªÛŒ Ú©Ù‡ Ø§Ù†Ø³Ø§Ù† Ù…ØµØ±Ù Ù…ÛŒ Ú©Ù†Ù‡ Ú†ÛŒÙ‡ØŸ',\n",
              "  'reference': 'Ù‡ÛŒØ¯Ø±ÙˆÚ©Ø±Ø¨Ù†\\u200cÙ‡Ø§',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¨ÛŒØ´ØªØ± Ø³ÙˆØ®ØªÛŒ Ù…ÙˆØ±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ù†Ø³Ø§Ù† Ø§Ø² Ú†ÛŒ Ø¨Ø¯Ø³Øª Ù…ÛŒØ§Ø¯ØŸ',\n",
              "  'reference': 'Ú¯ÛŒØ§Ù‡Ø§Ù† Ùˆ ÛŒØ§ Ú†Ø±Ø¨ÛŒ Ø­ÛŒÙˆØ§Ù†Ø§Øª',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§Ù†Ø±Ú˜ÛŒ Ú©Ù‡ Ø§Ø² Ù…ÙˆØ§Ø¯ Ø³ÙˆØ®ØªÙ†ÛŒ Ø¨Ø¯Ø³Øª Ù…ÛŒØ§Ø¯ Ø¨Ù‡ Ú†Ù‡ Ø§Ù†Ø±Ú˜ÛŒ Ù…ÛŒ ØªÙˆÙ†Ù‡ ØªØ¨Ø¯ÛŒÙ„ Ø´Ù‡ØŸ',\n",
              "  'reference': 'Ø§Ù†Ø±Ú˜ÛŒ Ù…Ú©Ø§Ù†ÛŒÚ©ÛŒ',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§ÙˆÙ„ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø´Ø± Ø§Ø² Ø³ÙˆØ®Øª Ú†ÛŒ Ø¨ÙˆØ¯ØŸ',\n",
              "  'reference': 'Ø§Ø­ØªØ±Ø§Ù‚ Ùˆ Ø³ÙˆØ²Ø§Ù†Ø¯Ù† ØªÚ©Ù‡ Ù‡Ø§ÛŒ Ú†ÙˆØ¨',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú†Ù‡ ÙØ±Ø§ÛŒÙ†Ø¯ÛŒ Ø³ÙˆØ®Øª Ø±Ùˆ Ø¨Ù‡ Ø§Ù†Ø±Ú˜ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒ Ú©Ù†Ù‡ØŸ',\n",
              "  'reference': 'Ø§Ú©Ù†Ø´\\u200cÙ‡Ø§ÛŒ Ø´ÛŒÙ…ÛŒØ§ÛŒÛŒ Ù…Ø®ØªÙ„Ù Ùˆ Ú¯Ø±Ù…Ø§Ø²Ø§',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù…Ù†Ø¨Ø¹ Ø³ÙˆØ®Øª Ú©Ø¬Ø§Ø³ØªØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§Ø² Ú†Ù‡ Ø³ÙˆØ®ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø­Ø±Ú©Øª Ø®ÙˆØ¯Ø±Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒ Ø´Ù‡ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú©Ø¯ÙˆÙ… Ù…Ø§Ø¯Ù‡ Ø³ÙˆØ®ØªÙ†ÛŒ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø§Ù†Ø±Ú˜ÛŒ Ø±Ùˆ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒ Ú©Ù†Ù‡ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¯Ø± Ú©Ø¬Ø§ÛŒ Ú©ØªØ§Ø¨ Ø³ÙØ± Ù¾ÛŒØ¯Ø§ÛŒØ´ Ø¨Ù‡ Ù„ÙˆØ· ØªÙˆØ¬Ù‡ Ø´Ø¯Ù‡ØŸ',\n",
              "  'reference': 'Ø¨Ø§Ø¨ Û±Û±â€“Û±Û´ ØªØ§ Û±Û¹',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø§Ø³Ù… Ù¾Ø¯Ø± Ù„ÙˆØ· Ú†Ù‡ Ø¨ÙˆØ¯ØŸ',\n",
              "  'reference': 'Ù‡Ø§Ø±Ø§Ù†',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù„ÙˆØ· Ú†Ù‡ Ù†Ø³Ø¨ØªÛŒ Ø¨Ø§ Ø§Ø¨Ø±Ø§Ù‡ÛŒÙ… Ø¯Ø§Ø±Ø¯ØŸ',\n",
              "  'reference': 'Ø¨Ø±Ø§Ø¯Ø±Ø²Ø§Ø¯Ù‡Ù” Ø§Ø¨Ø±Ø§Ù‡ÛŒÙ…',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ø¨Ø¹Ø¯ Ø§Ø² Ù…Ø±Ú¯ Ù¾Ø¯Ø± Ù„ÙˆØ· Ú†Ù‡ Ø¨Ù„Ø§ÛŒÛŒ Ø³Ø±Ø´ Ø¢Ù…Ø¯ØŸ',\n",
              "  'reference': 'Ù¾Ø¯Ø±Ø¨Ø²Ø±Ú¯ Ù„ÙˆØ·ØŒ ØªØ§Ø±Ø­ØŒ Ø§Ùˆ Ø±Ø§ Ø¨Ù‡ Ø³Ø±Ù¾Ø±Ø³ØªÛŒ Ú¯Ø±ÙØª',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú†Ø±Ø§ Ù„ÙˆØ· Ùˆ Ø§Ø¨Ø±Ø§Ù‡ÛŒÙ… Ø§Ø² Ù‡Ù… Ø¬Ø¯Ø§ Ø´Ø¯Ù†Ø¯ØŸ',\n",
              "  'reference': 'Ú©Ù…Ø¨ÙˆØ¯ Ú†Ø±Ø§Ú¯Ø§Ù‡ Ù…ÛŒØ§Ù†Ø´Ø§Ù† Ø§Ø®ØªÙ„Ø§ÙÛŒ Ù¾Ø¯ÛŒØ¯ Ø¢Ù…Ø¯ Ùˆ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø±Ú¯ÛŒØ±ÛŒ Ø¨ÛŒÙ† Ø®ÙˆÛŒØ´Ø§Ù†Ø¯Ø§Ù†',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù„ÙˆØ· Ø¨Ø¹Ø¯ Ø§Ø² Ø¬Ø¯Ø§ Ø´Ø¯Ù† Ø§Ø² Ø§Ø¨Ø±Ø§Ù‡ÛŒÙ… Ú©Ø¬Ø§ Ø±ÙØªØŸ',\n",
              "  'reference': 'Ø¨Ù‡ Ø³Ù…Øª Ø³Ø¯ÙˆÙ… Ø¯Ø± Ø¯Ø±Ù‡ Ø§Ø±Ø¯Ù†',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú†Ø±Ø§ Ø³Ø§Ú©Ù†Ø§Ù† Ø³Ø¯ÙˆÙ… Ø®Ø§Ù†Ù‡ Ù„ÙˆØ· Ø±Ø§ Ù…Ø­Ø§ØµØ±Ù‡ Ú©Ø±Ø¯Ù‡ Ø¨ÙˆØ¯Ù†Ø¯ØŸ',\n",
              "  'reference': 'Ù‚ØµØ¯ ØªØ¬Ø§ÙˆØ² Ø¨Ù‡ Ù…Ù‡Ù…Ø§Ù†Ø§Ù† Ù„ÙˆØ· Ø±Ø§ Ø¯Ø§Ø´ØªÙ†Ø¯',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 0.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú†Ø±Ø§ Ù„ÙˆØ· Ù¾ÛŒØ´ Ù¾Ø³Ø±Ø´ Ø§Ø¨Ø±Ø§Ù‡ÛŒÙ… Ù†Ù…Ø§Ù†Ø¯ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ù„ÙˆØ· Ø¯Ø± Ú†Ù‡ Ø³Ø§Ù„ÛŒ Ø²Ù†Ø¯Ú¯ÛŒ Ù…ÛŒ Ú©Ø±Ø¯Ù‡ØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0},\n",
              " {'question': 'Ú©ØªØ§Ø¨ Ø³ÙØ± Ù¾ÛŒØ¯Ø§ÛŒØ´ Ø±Ø§Ø¬Ø¨ Ú†ÛŒØ³ØªØŸ',\n",
              "  'reference': '',\n",
              "  'prediction': '',\n",
              "  'f1_score': 0.0,\n",
              "  'exact_match': 1.0,\n",
              "  'bert_score': 0.0}]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "dataset_test = load_dataset(\"SajjadAyoubi/persian_qa\", split = \"validation\")\n",
        "dataset_test = dataset_test.select(range(100))\n",
        "results = []\n",
        "for item in tqdm(dataset_test, desc=\"Evaluating\"):\n",
        "      question = item[\"question\"]\n",
        "      if \"answers\" in item and \"text\" in item[\"answers\"] and len(item[\"answers\"][\"text\"]) > 0:\n",
        "        reference = item[\"answers\"][\"text\"][0]  # Assuming a list of answers\n",
        "      else:\n",
        "          reference = \"\"\n",
        "      context = item.get(\"context\", None)\n",
        "      prompt = format_prompt(question, context)\n",
        "      prediction = generate_answer(model, tokenizer, prompt)\n",
        "      f1_score = evaluate_f1_token(prediction, reference)\n",
        "      em_score = evaluate_exact_match(prediction, reference)\n",
        "      bert_score = evaluate_bert_score(prediction, reference)\n",
        "      results.append({\n",
        "        \"question\": question,\n",
        "        \"reference\": reference,\n",
        "        \"prediction\": prediction,\n",
        "        \"f1_score\": f1_score,\n",
        "        \"exact_match\": em_score,\n",
        "        \"bert_score\": bert_score\n",
        "      })\n",
        "results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V9mk_5yhoJH",
        "outputId": "b8ba5d67-7748-441c-c8f6-c64d9e8b03e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average F1 Score: 0.0000\n",
            "Average Exact Match: 0.3000\n",
            "Average BERT Score: 0.0000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "avg_f1 = np.mean([result[\"f1_score\"] for result in results])\n",
        "avg_em = np.mean([result[\"exact_match\"] for result in results])\n",
        "avg_bert = np.mean([result[\"bert_score\"] for result in results])\n",
        "print(f\"Average F1 Score: {avg_f1:.4f}\")\n",
        "print(f\"Average Exact Match: {avg_em:.4f}\")\n",
        "print(f\"Average BERT Score: {avg_bert:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKX_XKs_BNZR"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    from unsloth import FastLanguageModel\n",
        "\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name=\"lora_model\",  # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length=max_seq_length,\n",
        "        dtype=dtype,\n",
        "        load_in_4bit=load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n",
        "\n",
        "# alpaca_prompt = You MUST copy from above!\n",
        "\n",
        "inputs = tokenizer(\n",
        "    [\n",
        "        alpaca_prompt.format(\n",
        "            \"What is a famous tall tower in Paris?\",  # instruction\n",
        "            \"\",  # input\n",
        "            \"\",  # output - leave this blank for generation!\n",
        "        )\n",
        "    ],\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMjaNrjsU5_"
      },
      "source": [
        "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFfaXG0WsQuE"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    # I highly do NOT suggest - use Unsloth if possible\n",
        "    from peft import AutoPeftModelForCausalLM\n",
        "    from transformers import AutoTokenizer\n",
        "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ab5c5043d8244679d6e985c45aaf94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b36d079b4f64d24bfa6a97d60423edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c79cd4bf6da4fed8c461138bbeb7520": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10169a2c15f2428ab6803a2820cc8c65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1061e8b4991048f7a981a665d87f4fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11091850396a44bba5a04727fa57470a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd92faf02f5847648ce94f95915ffe12",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_affa13203281457b8373ff6003f6e2f6",
            "value": "â€‡16.0M/?â€‡[00:00&lt;00:00,â€‡52.3MB/s]"
          }
        },
        "1285896f5b874909b8f2e2cb762ca033": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12bbd0219b1f4e078d2d2240d4eec486": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13778ee9448c45aab93b08eba085c1d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "158c186cdd9b48e2b07a013abd7b7a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10169a2c15f2428ab6803a2820cc8c65",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1f9efc99625d497689e2ca55b36089be",
            "value": "â€‡1/1â€‡[00:05&lt;00:00,â€‡â€‡5.48s/it]"
          }
        },
        "17fe36d10b024205a711741b4aaf8cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ae3e1179efe426bb5cc5f401be97c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_907deca0fe2b47c4a9cd24fc8ce7533e",
              "IPY_MODEL_1ca7bf5538d3485ca4d9c1ffb77d8756",
              "IPY_MODEL_3ac1325106b14741b81038fa79361bd5"
            ],
            "layout": "IPY_MODEL_ebac52b9cf0f47479d6eacc4b3d1214f"
          }
        },
        "1ca7bf5538d3485ca4d9c1ffb77d8756": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fab2f0843ba459da42e8c3daa37e3fa",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a38f77856ffa4c98be9cbd023cf40fd5",
            "value": 2
          }
        },
        "1ced9679ab9947e3b778626b574abc44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9efc99625d497689e2ca55b36089be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fab2f0843ba459da42e8c3daa37e3fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25bb2faf4fa146df9a71ae6c3c6b4604": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca55a3978e994541a0f2e890272ee54d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c91f3d90122c4ec19c79342fb62babf7",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "2733c3d8322f4f5d9db036a737e1c7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aa451cb830b42878747a15411e7ed59",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b9aad5dc41104e91b5642b21f3bf647e",
            "value": "â€‡575/575â€‡[00:00&lt;00:00,â€‡61.8kB/s]"
          }
        },
        "2d00f2ba25f14c4f892b58eb7fcf587b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d9d62f0a7364ac0b40e1da1b78ac10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25bb2faf4fa146df9a71ae6c3c6b4604",
              "IPY_MODEL_436c48d27ff1454eba0c38c97b774869",
              "IPY_MODEL_5ffbb9bba9114150badd4c0c5162782b"
            ],
            "layout": "IPY_MODEL_d4c0e0a75fbd481ea6848f8e1ae02d34"
          }
        },
        "35889ba2cf394ff990a4dc4852608d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "361c01b66c824ed59c297727820ea5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1285896f5b874909b8f2e2cb762ca033",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_521c4538cb8b44338f39f8ac872c4d93",
            "value": "â€‡464M/?â€‡[00:05&lt;00:00,â€‡96.5MB/s]"
          }
        },
        "375e6e53751f48cb864448ec390571d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ac1325106b14741b81038fa79361bd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72da54debc634cdba81b9fc97fa9afa6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_49ce160cf5e0461fb20e6e63721c9b8b",
            "value": "â€‡2/2â€‡[00:06&lt;00:00,â€‡â€‡3.32s/it]"
          }
        },
        "3cfc822d63a948a3820ae71283e33746": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43044c9f547a495090a58148db1bf60c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0480e4a196e45b0acb0fb9284c4bce8",
              "IPY_MODEL_8fbb7e2cb8624651911397cc0d556806",
              "IPY_MODEL_460a8f5665df40f18c4d066c88f07e08"
            ],
            "layout": "IPY_MODEL_f62c43a078e54c96b80f581f977835ae"
          }
        },
        "436c48d27ff1454eba0c38c97b774869": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc729da6499f4293b76989e3ab5279d7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_668606025e4743d2bf1791f029190e0a",
            "value": 2
          }
        },
        "460a8f5665df40f18c4d066c88f07e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ced9679ab9947e3b778626b574abc44",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f0a2d28c719d4b79bf067e5be4c9c581",
            "value": "â€‡2/2â€‡[00:02&lt;00:00,â€‡â€‡1.06s/it]"
          }
        },
        "4917b0fc680345c297a0c9bc0371db0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49ce160cf5e0461fb20e6e63721c9b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4afa549de0a64312bf964a10567e39d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bcf868feb614558b776334c5f792ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12bbd0219b1f4e078d2d2240d4eec486",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_76163832d5a948b7b440ba5b4d027701",
            "value": "tokenizer.model:â€‡"
          }
        },
        "4d846ab6a7fb43ecbe157a5e4dfc6ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ff4458dcd8240bfaa60a8e1bbe52f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "521c4538cb8b44338f39f8ac872c4d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59b948620f8347d1be13af37fd78e2e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c147e3d90154497887bfdf26c7c75bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ffbb9bba9114150badd4c0c5162782b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13778ee9448c45aab93b08eba085c1d2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4ff4458dcd8240bfaa60a8e1bbe52f5a",
            "value": "â€‡2/2â€‡[00:06&lt;00:00,â€‡â€‡3.26s/it]"
          }
        },
        "61453f5ff35d445f8570ef1692423224": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a584d55ffe4e99a5068ef0055b2cca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61fe6e7dca64435786a4aeb795c36648": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "668606025e4743d2bf1791f029190e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c8a1d47ef9244b88568baeb13b6add9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bcf868feb614558b776334c5f792ebc",
              "IPY_MODEL_d005ceec96574da9be57cd0a91168a01",
              "IPY_MODEL_11091850396a44bba5a04727fa57470a"
            ],
            "layout": "IPY_MODEL_dd9436e158db47e2a1fc96e35c428092"
          }
        },
        "72da54debc634cdba81b9fc97fa9afa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "740c00974eca4dd3b198e4e88c29df80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dedb39f2d6bb48b7830cb00a7e94cf1a",
            "max": 34362873,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e42a1958313043de9f3b1f70b88e20b4",
            "value": 34362873
          }
        },
        "75e60310dc474864b353a4a6a286281b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76163832d5a948b7b440ba5b4d027701": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77db02d6b4e640c797064bfec1412be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7ef5b86365a469499ce8fb761fbbfaf",
              "IPY_MODEL_740c00974eca4dd3b198e4e88c29df80",
              "IPY_MODEL_bb4c5073c68143608ccab403c451ed4e"
            ],
            "layout": "IPY_MODEL_78f93cc2a57548b7aa3069945ac6df52"
          }
        },
        "78f93cc2a57548b7aa3069945ac6df52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "792ce938302841e3b3218e84546e05cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e758be310de44e997ca38a52213d675",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61fe6e7dca64435786a4aeb795c36648",
            "value": 1
          }
        },
        "793f1509f09840e5bab348a0cd01aa44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c4c5af53f0b4e9e9c02a63ca341f7e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82877abdcec240f5b7e31441cb56224d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82cc8530ac004692a0189b1d677c93a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61a584d55ffe4e99a5068ef0055b2cca",
            "max": 575,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c79cd4bf6da4fed8c461138bbeb7520",
            "value": 575
          }
        },
        "83dfae177c234ee98e0652ad2d461a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aa451cb830b42878747a15411e7ed59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e758be310de44e997ca38a52213d675": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fbb7e2cb8624651911397cc0d556806": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c4c5af53f0b4e9e9c02a63ca341f7e2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3d634abf142465d9e21d85d1f62f108",
            "value": 2
          }
        },
        "907deca0fe2b47c4a9cd24fc8ce7533e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_793f1509f09840e5bab348a0cd01aa44",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4afa549de0a64312bf964a10567e39d1",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "a38f77856ffa4c98be9cbd023cf40fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "affa13203281457b8373ff6003f6e2f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5c49c409bc24535a1f86f16e2d8752b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9aad5dc41104e91b5642b21f3bf647e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bad661e3c0524b46aa2815b216c00036": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec44a47e266b40e4b5e1a72dabcf8e94",
              "IPY_MODEL_cf0ee4d68cc5437abc21b5b5a93ee91f",
              "IPY_MODEL_361c01b66c824ed59c297727820ea5b6"
            ],
            "layout": "IPY_MODEL_1061e8b4991048f7a981a665d87f4fdb"
          }
        },
        "bb4c5073c68143608ccab403c451ed4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4917b0fc680345c297a0c9bc0371db0d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0ab5c5043d8244679d6e985c45aaf94a",
            "value": "â€‡48.0M/?â€‡[00:00&lt;00:00,â€‡57.3MB/s]"
          }
        },
        "bbd07c7ed04148ccbabeb1c270d2b1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0480e4a196e45b0acb0fb9284c4bce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb8f98359c62471b8ec20bbf9ae62789",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_375e6e53751f48cb864448ec390571d8",
            "value": "100%"
          }
        },
        "c7ef5b86365a469499ce8fb761fbbfaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75e60310dc474864b353a4a6a286281b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5c147e3d90154497887bfdf26c7c75bc",
            "value": "tokenizer.json:â€‡"
          }
        },
        "c91f3d90122c4ec19c79342fb62babf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca55a3978e994541a0f2e890272ee54d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb8f98359c62471b8ec20bbf9ae62789": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc729da6499f4293b76989e3ab5279d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf0ee4d68cc5437abc21b5b5a93ee91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59b948620f8347d1be13af37fd78e2e1",
            "max": 456807328,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b36d079b4f64d24bfa6a97d60423edd",
            "value": 456807328
          }
        },
        "d005ceec96574da9be57cd0a91168a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d846ab6a7fb43ecbe157a5e4dfc6ba2",
            "max": 4241003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbd07c7ed04148ccbabeb1c270d2b1f6",
            "value": 4241003
          }
        },
        "d3d634abf142465d9e21d85d1f62f108": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d43b95c3fc254361abac8d0817d3b833": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7041dc9a8374b89bf750c3aeca6b322",
              "IPY_MODEL_792ce938302841e3b3218e84546e05cb",
              "IPY_MODEL_158c186cdd9b48e2b07a013abd7b7a28"
            ],
            "layout": "IPY_MODEL_b5c49c409bc24535a1f86f16e2d8752b"
          }
        },
        "d4c0e0a75fbd481ea6848f8e1ae02d34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd9436e158db47e2a1fc96e35c428092": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dedb39f2d6bb48b7830cb00a7e94cf1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e42a1958313043de9f3b1f70b88e20b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6b53e073e8c4ba28ab19bf4611bce9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f75076bcb82f4f6d8aabc5c21666f3f7",
              "IPY_MODEL_82cc8530ac004692a0189b1d677c93a3",
              "IPY_MODEL_2733c3d8322f4f5d9db036a737e1c7d6"
            ],
            "layout": "IPY_MODEL_61453f5ff35d445f8570ef1692423224"
          }
        },
        "e7041dc9a8374b89bf750c3aeca6b322": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83dfae177c234ee98e0652ad2d461a8f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_35889ba2cf394ff990a4dc4852608d1e",
            "value": "100%"
          }
        },
        "ebac52b9cf0f47479d6eacc4b3d1214f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec44a47e266b40e4b5e1a72dabcf8e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d00f2ba25f14c4f892b58eb7fcf587b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3cfc822d63a948a3820ae71283e33746",
            "value": "adapter_model.safetensors:â€‡"
          }
        },
        "f0a2d28c719d4b79bf067e5be4c9c581": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f62c43a078e54c96b80f581f977835ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f75076bcb82f4f6d8aabc5c21666f3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82877abdcec240f5b7e31441cb56224d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_17fe36d10b024205a711741b4aaf8cfe",
            "value": "README.md:â€‡100%"
          }
        },
        "fd92faf02f5847648ce94f95915ffe12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
